{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/auth-create/DDfiles/blob/main/engenharia_reversa_videos_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SISTEMA MODULAR DE ENGENHARIA REVERSA DE VÍDEOS - VERSÃO FINAL OTIMIZADA\n",
        "\n",
        "Este notebook foi aprimorado para oferecer uma experiência mais intuitiva, organizada e robusta para a engenharia reversa de vídeos. Cada etapa é modular, com validações de pré-requisitos e feedback em tempo real para guiá-lo(a) durante o processo.\n",
        "\n",
        "## COMO USAR:\n",
        "1.  **Execute as células em ordem, de cima para baixo.** Cada célula foi projetada para ser executada sequencialmente.\n",
        "2.  **Atenção aos feedbacks:** Mensagens claras indicarão o sucesso de cada etapa, possíveis erros e qual a **PRÓXIMA CÉLULA** a ser executada.\n",
        "3.  **Corrija e re-execute:** Se um erro for detectado, uma mensagem explicativa será exibida. Corrija o problema (geralmente um caminho incorreto ou dependência ausente) e re-execute a célula que falhou.\n",
        "4.  **Progresso Salvo:** O sistema salva automaticamente o progresso e os dados gerados em cada etapa, permitindo que você retome de onde parou.\n",
        "\n",
        "## ESTRUTURA DO PROCESSO (Layers e Sublayers):\n",
        "Este sistema é organizado em camadas lógicas para facilitar o entendimento e a execução:\n",
        "\n",
        "### LAYER 1: CONFIGURAÇÃO E PREPARAÇÃO\n",
        "*   **CÉLULA 1.1: SETUP INICIAL E INSTALAÇÃO DE DEPENDÊNCIAS**\n",
        "*   **CÉLULA 1.2: CONFIGURAÇÃO INICIAL E VALIDAÇÃO DA PASTA DE TRABALHO**\n",
        "\n",
        "### LAYER 2: DESCOBERTA E EXTRAÇÃO DE DADOS BRUTOS\n",
        "*   **CÉLULA 2.1: DESCOBERTA E CATALOGAÇÃO DE VÍDEOS**\n",
        "*   **CÉLULA 2.2: EXTRAÇÃO DE METADADOS DOS VÍDEOS**\n",
        "*   **CÉLULA 2.3: DECOMPOSIÇÃO DE VÍDEOS (FRAMES, ÁUDIO, TEXTO)**\n",
        "\n",
        "### LAYER 3: ANÁLISE E PROCESSAMENTO DE DADOS\n",
        "*   **CÉLULA 3.1: ANÁLISE DE PADRÕES (TEMPORAIS, VISUAIS, TEXTO, ÁUDIO)**\n",
        "*   **CÉLULA 3.2: ANÁLISE PSICOLÓGICA E GATILHOS DE ENGAJAMENTO**\n",
        "\n",
        "### LAYER 4: GERAÇÃO DE RELATÓRIOS E BLUEPRINT ESTRATÉGICO\n",
        "*   **CÉLULA 4.1: GERAÇÃO DE RELATÓRIOS HUMANIZADOS (ÁUDIO, VISUAL, TEXTO, PSICOLÓGICO)**\n",
        "*   **CÉLULA 4.2: GERAÇÃO DO BLUEPRINT FINAL E DASHBOARD**\n",
        "\n",
        "---\n",
        "\n",
        "*Lembre-se: Este sistema foi projetado para ser executado no Google Colab. Certifique-se de que seu ambiente está configurado corretamente.*"
      ],
      "metadata": {
        "id": "zx8sEBm8_yKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LAYER 1: CONFIGURAÇÃO E PREPARAÇÃO\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# CÉLULA 1.1: SETUP INICIAL E INSTALAÇÃO DE DEPENDÊNCIAS\n",
        "# ============================================================================\n",
        "\n",
        "# Instalar dependências necessárias\n",
        "!pip install -q moviepy librosa pytesseract opencv-python pandas openpyxl matplotlib seaborn pillow SpeechRecognition pydub fpdf\n",
        "!apt-get update -qq && apt-get install -y -qq tesseract-ocr tesseract-ocr-por ffmpeg\n",
        "\n",
        "# Imports necessários\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import logging\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "import librosa\n",
        "from moviepy.editor import VideoFileClip\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import speech_recognition as sr # Adicionado import para SpeechRecognition\n",
        "# Montar Google Drive\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"✅ Google Drive montado com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERRO ao montar Google Drive: {e}. Por favor, verifique sua conexão ou permissões.\")\n",
        "\n",
        "print(\n",
        "\"✅ SETUP INICIAL CONCLUÍDO!\")\n",
        "print(\"Todas as dependências foram instaladas e o Google Drive foi montado.\")\n",
        "print(\"➡️ PRÓXIMA CÉLULA: 1.2 - CONFIGURAÇÃO INICIAL E VALIDAÇÃO DA PASTA DE TRABALHO\")"
      ],
      "metadata": {
        "id": "setup_inicial",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a270c125-2f7c-45c1-b1be-3a426e2bcf8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Google Drive montado com sucesso!\n",
            "✅ SETUP INICIAL CONCLUÍDO!\n",
            "Todas as dependências foram instaladas e o Google Drive foi montado.\n",
            "➡️ PRÓXIMA CÉLULA: 1.2 - CONFIGURAÇÃO INICIAL E VALIDAÇÃO DA PASTA DE TRABALHO\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CÉLULA 1.2: CONFIGURAÇÃO INICIAL E VALIDAÇÃO DA PASTA DE TRABALHO\n",
        "# ============================================================================\n",
        "\n",
        "# ⚠️ **ATENÇÃO:** CONFIGURE SEU CAMINHO AQUI!\n",
        "# Substitua o caminho abaixo pela pasta onde seus vídeos estão localizados no Google Drive.\n",
        "# Exemplo: \"/content/drive/MyDrive/Meus Videos de Marketing\"\n",
        "CAMINHO_PASTA_VIDEOS = \"/content/drive/MyDrive/Videos Dona Done\" # ⬅️ **ALTERE AQUI**\n",
        "\n",
        "class ConfiguradorProjeto:\n",
        "    def __init__(self, caminho_pasta):\n",
        "        self.pasta_videos = self._validar_caminho(caminho_pasta)\n",
        "        self.pasta_trabalho = os.path.join(self.pasta_videos, \"_engenharia_reversa\")\n",
        "        self._criar_estrutura()\n",
        "        self._configurar_logging()\n",
        "\n",
        "    def _validar_caminho(self, caminho):\n",
        "        if caminho == \"/content/drive/MyDrive/Videos Dona Done\" and not os.path.exists(caminho):\n",
        "            raise ValueError(\"❌ ERRO: Você precisa alterar CAMINHO_PASTA_VIDEOS com o caminho real da sua pasta de vídeos no Google Drive. O caminho padrão não foi encontrado.\")\n",
        "\n",
        "        if not os.path.exists(caminho):\n",
        "            raise ValueError(f\"❌ ERRO: Pasta não encontrada: {caminho}. Por favor, verifique se o caminho está correto e se o Google Drive está montado.\")\n",
        "\n",
        "        return caminho\n",
        "\n",
        "    def _criar_estrutura(self):\n",
        "        # Estrutura de pastas conforme o anexo e requisitos do usuário\n",
        "        estrutura = [\n",
        "            \"config\", \"logs\", \"dados\", \"frames_extraidos\",\n",
        "            \"analise_texto\", \"analise_audio\", \"capturas\",\n",
        "            \"blueprint\", \"temp\", \"dashboard\", \"analise_psicologica\", \"analise_visual\"\n",
        "        ]\n",
        "\n",
        "        os.makedirs(self.pasta_trabalho, exist_ok=True)\n",
        "        for pasta in estrutura:\n",
        "            os.makedirs(os.path.join(self.pasta_trabalho, pasta), exist_ok=True)\n",
        "\n",
        "        # Criar subpastas para frames_extraidos (ex: vid_001_Nome_Do_Video/)\n",
        "        # Esta lógica será implementada na célula de decomposição de vídeos (CÉLULA 2.3)\n",
        "\n",
        "    def _configurar_logging(self):\n",
        "        log_file = os.path.join(self.pasta_trabalho, \"logs\", f\"sistema_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        "            handlers=[logging.FileHandler(log_file, encoding='utf-8')]\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def salvar_configuracao(self):\n",
        "        config = {\n",
        "            \"projeto\": {\n",
        "                \"pasta_videos\": self.pasta_videos,\n",
        "                \"pasta_trabalho\": self.pasta_trabalho,\n",
        "                \"criado_em\": datetime.now().isoformat(),\n",
        "                \"versao\": \"modular_v2.0_otimizado\"\n",
        "            },\n",
        "            \"status_etapas\": {\n",
        "                \"configuracao\": True,\n",
        "                \"descoberta_videos\": False,\n",
        "                \"metadados\": False,\n",
        "                \"decomposicao\": False,\n",
        "                \"analise_padroes\": False,\n",
        "                \"analise_psicologica\": False,\n",
        "                \"relatorios_humanizados\": False,\n",
        "                \"blueprint\": False\n",
        "            }\n",
        "        }\n",
        "\n",
        "        config_path = os.path.join(self.pasta_trabalho, \"config\", \"config.json\")\n",
        "        with open(config_path, \"w\", encoding='utf-8') as f:\n",
        "            json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        return config_path\n",
        "\n",
        "# Executar configuração\n",
        "try:\n",
        "    configurador = ConfiguradorProjeto(CAMINHO_PASTA_VIDEOS)\n",
        "    config_path = configurador.salvar_configuracao()\n",
        "\n",
        "    print(\"\"\"\n",
        "✅ CONFIGURAÇÃO CONCLUÍDA!\"\"\")\n",
        "    print(f\"Pasta de trabalho criada: {configurador.pasta_trabalho}\")\n",
        "    print(f\"Configuração salva: {config_path}\")\n",
        "    print(\"\"\"\n",
        "➡️ PRÓXIMA CÉLULA: 2.1 - DESCOBERTA E CATALOGAÇÃO DE VÍDEOS\"\"\")\n",
        "\n",
        "    # Salvar variáveis globais para próximas células\n",
        "    global PASTA_VIDEOS, PASTA_TRABALHO\n",
        "    PASTA_VIDEOS = configurador.pasta_videos\n",
        "    PASTA_TRABALHO = configurador.pasta_trabalho\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\"\"\n",
        "❌ ERRO NA CONFIGURAÇÃO: {e}\"\"\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "configuracao_inicial",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "facb8678-79c1-4863-f64b-7929d897b4e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ CONFIGURAÇÃO CONCLUÍDA!\n",
            "Pasta de trabalho criada: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa\n",
            "Configuração salva: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/config/config.json\n",
            "\n",
            "➡️ PRÓXIMA CÉLULA: 2.1 - DESCOBERTA E CATALOGAÇÃO DE VÍDEOS\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LAYER 2: DESCOBERTA E EXTRAÇÃO DE DADOS BRUTOS\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# CÉLULA 2.1: DESCOBERTA E CATALOGAÇÃO DE VÍDEOS\n",
        "# ============================================================================\n",
        "\n",
        "def verificar_prerequisito_etapa(etapa_anterior):\n",
        "    \"\"\"Verifica se a etapa anterior foi executada com sucesso\"\"\"\n",
        "    try:\n",
        "        if not \"PASTA_TRABALHO\" in globals():\n",
        "            raise Exception(\"Variáveis globais de configuração não encontradas. Execute a CÉLULA 1.2 primeiro.\")\n",
        "\n",
        "        config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "        if not os.path.exists(config_path):\n",
        "            raise Exception(\"Arquivo de configuração não encontrado. Execute a CÉLULA 1.2 primeiro.\")\n",
        "\n",
        "        with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "        if not config[\"status_etapas\"][etapa_anterior]:\n",
        "            raise Exception(f\"A etapa \\\"{etapa_anterior}\\\" não foi concluída. Execute a célula correspondente primeiro.\")\n",
        "\n",
        "        return True, config\n",
        "    except Exception as e:\n",
        "        print(f\"❌ PRÉ-REQUISITO NÃO ATENDIDO: {e}\")\n",
        "        return False, None\n",
        "\n",
        "def descobrir_catalogar_videos():\n",
        "    \"\"\"Descobre e cataloga todos os vídeos na pasta\"\"\"\n",
        "    formatos_aceitos = [\".mp4\", \".mov\", \".avi\", \".mkv\", \".webm\", \".m4v\"]\n",
        "    videos_encontrados = []\n",
        "\n",
        "    print(f\"🔍 Iniciando descoberta de vídeos na pasta: {PASTA_VIDEOS}\")\n",
        "\n",
        "    for root, dirs, files in os.walk(PASTA_VIDEOS):\n",
        "        if \"_engenharia_reversa\" in root:\n",
        "            continue # Ignorar a pasta de trabalho do sistema\n",
        "\n",
        "        for file in files:\n",
        "            if any(file.lower().endswith(fmt) for fmt in formatos_aceitos):\n",
        "                video_path = os.path.join(root, file)\n",
        "\n",
        "                try:\n",
        "                    stat_info = os.stat(video_path)\n",
        "                    # Gerar ID baseado no nome do arquivo para melhor rastreamento\n",
        "                    video_name_clean = os.path.splitext(file)[0].replace(\" \", \"_\").replace(\".\", \"\")\n",
        "                    video_id = f\"vid_{video_name_clean}\"\n",
        "\n",
        "                    video_info = {\n",
        "                        \"id\": video_id,\n",
        "                        \"nome_arquivo\": file,\n",
        "                        \"caminho_completo\": video_path,\n",
        "                        \"caminho_relativo\": os.path.relpath(video_path, PASTA_VIDEOS),\n",
        "                        \"tamanho_mb\": round(stat_info.st_size / (1024*1024), 2),\n",
        "                        \"data_modificacao\": datetime.fromtimestamp(stat_info.st_mtime).isoformat(),\n",
        "                        \"extensao\": os.path.splitext(file)[1].lower(),\n",
        "                        \"status\": \"descoberto\"\n",
        "                    }\n",
        "\n",
        "                    videos_encontrados.append(video_info)\n",
        "                    print(f\"  ✅ Encontrado: {file}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  ❌ Erro ao processar {file}: {e}\")\n",
        "                    continue\n",
        "\n",
        "    return videos_encontrados\n",
        "\n",
        "def salvar_lista_videos(videos):\n",
        "    \"\"\"Salva lista de vídeos encontrados\"\"\"\n",
        "    videos_path = os.path.join(PASTA_TRABALHO, \"dados\", \"videos_descobertos.json\")\n",
        "    with open(videos_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(videos, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"descoberta_videos\"] = True\n",
        "    config[\"total_videos_encontrados\"] = len(videos)\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    return videos_path\n",
        "\n",
        "# Executar descoberta\n",
        "prerequisito_ok, _ = verificar_prerequisito_etapa(\"configuracao\")\n",
        "\n",
        "if prerequisito_ok:\n",
        "    try:\n",
        "        videos_encontrados = descobrir_catalogar_videos()\n",
        "\n",
        "        if not videos_encontrados:\n",
        "            print(\"\"\"\n",
        "❌ NENHUM VÍDEO ENCONTRADO!\"\"\")\n",
        "            print(f\"Verifique se há vídeos na pasta configurada: {PASTA_VIDEOS}\")\n",
        "        else:\n",
        "            videos_path = salvar_lista_videos(videos_encontrados)\n",
        "\n",
        "            print(\"\"\"\n",
        "✅ DESCOBERTA DE VÍDEOS CONCLUÍDA!\"\"\")\n",
        "            print(f\"Total de vídeos encontrados: {len(videos_encontrados)}\")\n",
        "            print(f\"Lista de vídeos salva em: {videos_path}\")\n",
        "\n",
        "            # Mostrar resumo\n",
        "            extensoes = Counter([v[\"extensao\"] for v in videos_encontrados])\n",
        "            print(f\"Formatos encontrados: {dict(extensoes)}\")\n",
        "            print(\"\"\"\n",
        "➡️ PRÓXIMA CÉLULA: 2.2 - EXTRAÇÃO DE METADADOS DOS VÍDEOS\"\"\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\"\"\n",
        "❌ ERRO NA DESCOBERTA DE VÍDEOS: {e}\"\"\")\n",
        "        print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "descoberta_videos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235b73b2-addf-4956-ef36-9c6bac844efa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Iniciando descoberta de vídeos na pasta: /content/drive/MyDrive/Videos Dona Done\n",
            "  ✅ Encontrado: ate quando voce vai ficar culpando os outros.mp4\n",
            "  ✅ Encontrado: coloque metas em sua vida e se surpreenda.mp4\n",
            "  ✅ Encontrado: a importancia de ser rico antes de ter.mp4\n",
            "\n",
            "✅ DESCOBERTA DE VÍDEOS CONCLUÍDA!\n",
            "Total de vídeos encontrados: 3\n",
            "Lista de vídeos salva em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dados/videos_descobertos.json\n",
            "Formatos encontrados: {'.mp4': 3}\n",
            "\n",
            "➡️ PRÓXIMA CÉLULA: 2.2 - EXTRAÇÃO DE METADADOS DOS VÍDEOS\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CÉLULA 2.2: EXTRAÇÃO DE METADADOS DOS VÍDEOS\n",
        "# ============================================================================\n",
        "\n",
        "def extrair_metadados_video(video_info):\n",
        "    \"\"\"Extrai metadados técnicos de um vídeo\"\"\"\n",
        "    video_path = video_info[\"caminho_completo\"]\n",
        "    video_id = video_info[\"id\"]\n",
        "\n",
        "    print(f\"  ⚙️ Extraindo metadados para: {video_info[\"nome_arquivo\"]}\")\n",
        "\n",
        "    # Análise com OpenCV\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise Exception(\"Não foi possível abrir o vídeo. Verifique o caminho ou a integridade do arquivo.\")\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    largura = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    altura = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    duracao = frame_count / fps if fps > 0 else 0\n",
        "\n",
        "    # Capturar primeiro frame\n",
        "    ret, primeiro_frame = cap.read()\n",
        "    cap.release()\n",
        "\n",
        "    # Análise de áudio\n",
        "    try:\n",
        "        clip = VideoFileClip(video_path)\n",
        "        tem_audio = clip.audio is not None\n",
        "        clip.close()\n",
        "    except Exception as e:\n",
        "        print(f\"    ⚠️ Aviso: Não foi possível analisar áudio para {video_info[\"nome_arquivo\"]}: {e}\")\n",
        "        tem_audio = False\n",
        "\n",
        "    # Análise do primeiro frame\n",
        "    analise_frame = {}\n",
        "    if ret:\n",
        "        # Salvar primeiro frame na pasta 'capturas'\n",
        "        capturas_dir = os.path.join(PASTA_TRABALHO, \"capturas\")\n",
        "        frame_path = os.path.join(capturas_dir, f\"{video_id}_primeiro_frame.jpg\")\n",
        "        cv2.imwrite(frame_path, primeiro_frame)\n",
        "\n",
        "        # Análises do frame\n",
        "        gray = cv2.cvtColor(primeiro_frame, cv2.COLOR_BGR2GRAY)\n",
        "        complexidade = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "        brilho = np.mean(gray)\n",
        "\n",
        "        analise_frame = {\n",
        "            \"path\": frame_path,\n",
        "            \"complexidade_visual\": float(complexidade),\n",
        "            \"brilho_medio\": float(brilho),\n",
        "            \"tem_muito_texto\": bool(complexidade > 500),\n",
        "            \"e_escuro\": bool(brilho < 100),\n",
        "            \"e_claro\": bool(brilho > 200)\n",
        "        }\n",
        "\n",
        "    # Detectar formato\n",
        "    ratio = largura / altura if altura > 0 else 0\n",
        "    if 0.5 <= ratio <= 0.6:\n",
        "        formato = \"vertical_9_16\" if altura > largura * 1.5 else \"vertical_4_5\"\n",
        "    elif 0.8 <= ratio <= 1.2:\n",
        "        formato = \"quadrado_1_1\"\n",
        "    elif ratio >= 1.3:\n",
        "        formato = \"horizontal_16_9\"\n",
        "    else:\n",
        "        formato = \"personalizado\"\n",
        "\n",
        "    # Compilar metadados - converter todos os valores para tipos básicos Python\n",
        "    metadados = {\n",
        "        **video_info,\n",
        "        \"duracao_segundos\": float(duracao),\n",
        "        \"fps\": float(fps),\n",
        "        \"largura\": int(largura),\n",
        "        \"altura\": int(altura),\n",
        "        \"resolucao\": f\"{largura}x{altura}\",\n",
        "        \"aspect_ratio\": float(ratio),\n",
        "        \"total_frames\": int(frame_count),\n",
        "        \"tem_audio\": bool(tem_audio),\n",
        "        \"formato_detectado\": str(formato),\n",
        "        \"primeiro_frame\": analise_frame,\n",
        "        \"data_analise\": datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    return metadados\n",
        "\n",
        "def processar_metadados_todos_videos():\n",
        "    \"\"\"Processa metadados de todos os vídeos\"\"\"\n",
        "    # Carregar lista de vídeos\n",
        "    videos_path = os.path.join(PASTA_TRABALHO, \"dados\", \"videos_descobertos.json\")\n",
        "    with open(videos_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        videos_lista = json.load(f)\n",
        "\n",
        "    metadados_completos = []\n",
        "    sucessos = 0\n",
        "\n",
        "    print(f\"Processando metadados de {len(videos_lista)} vídeos...\")\n",
        "\n",
        "    for i, video in enumerate(videos_lista, 1):\n",
        "        print(f\"[{i}/{len(videos_lista)}] Analisando {video[\"nome_arquivo\"]}\")\n",
        "\n",
        "        try:\n",
        "            metadados = extrair_metadados_video(video)\n",
        "            metadados[\"status\"] = \"metadados_extraidos\"\n",
        "            metadados_completos.append(metadados)\n",
        "            sucessos += 1\n",
        "            print(f\"  ✅ Metadados extraídos: {metadados[\"duracao_segundos\"]:.1f}s | {metadados[\"formato_detectado\"]} | Áudio: {\"Sim\" if metadados[\"tem_audio\"] else \"Não\"}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ❌ ERRO ao extrair metadados para {video[\"nome_arquivo\"]}: {e}\")\n",
        "            video[\"status\"] = \"erro_metadados\"\n",
        "            metadados_completos.append(video) # Adiciona o vídeo com status de erro\n",
        "\n",
        "    # Salvar metadados completos\n",
        "    metadados_json_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_completos.json\")\n",
        "    with open(metadados_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metadados_completos, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Salvar em Excel\n",
        "    df_metadados = pd.DataFrame(metadados_completos)\n",
        "    metadados_excel_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_videos.xlsx\")\n",
        "    df_metadados.to_excel(metadados_excel_path, index=False, engine='openpyxl')\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"metadados\"] = True\n",
        "    config[\"total_videos_metadados\"] = sucessos\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\\n💾 Metadados completos salvos em: {metadados_json_path}\")\n",
        "    print(f\"💾 Metadados em Excel salvos em: {metadados_excel_path}\")\n",
        "\n",
        "    print(\"\\n✅ EXTRAÇÃO DE METADADOS CONCLUÍDA!\")\n",
        "    print(f\"Total de vídeos com metadados extraídos: {sucessos}\")\n",
        "\n",
        "    # Mostrar resumo\n",
        "    if not df_metadados.empty:\n",
        "        print(\"\\n📊 Resumo dos Metadados:\")\n",
        "        print(f\"  - Formatos detectados: {dict(df_metadados['formato_detectado'].value_counts())}\")\n",
        "        print(f\"  - Duração média dos vídeos: {df_metadados['duracao_segundos'].mean():.2f}s\")\n",
        "        print(f\"  - Vídeos com áudio: {df_metadados['tem_audio'].sum()}\")\n",
        "\n",
        "    print(\"\\n➡️ PRÓXIMA CÉLULA: 2.3 - DECOMPOSIÇÃO DE VÍDEOS (FRAMES, ÁUDIO, TEXTO)\")\n",
        "\n",
        "# Executar extração de metadados\n",
        "prerequisito_ok, _ = verificar_prerequisito_etapa(\"descoberta_videos\")\n",
        "\n",
        "if prerequisito_ok:\n",
        "    try:\n",
        "        processar_metadados_todos_videos()\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ ERRO NA EXTRAÇÃO DE METADADOS: {e}\")\n",
        "        print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "extracao_metadados",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ada03b73-3415-4a75-d89c-be98e878f877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processando metadados de 3 vídeos...\n",
            "[1/3] Analisando ate quando voce vai ficar culpando os outros.mp4\n",
            "  ⚙️ Extraindo metadados para: ate quando voce vai ficar culpando os outros.mp4\n",
            "  ✅ Metadados extraídos: 18.6s | vertical_9_16 | Áudio: Sim\n",
            "[2/3] Analisando coloque metas em sua vida e se surpreenda.mp4\n",
            "  ⚙️ Extraindo metadados para: coloque metas em sua vida e se surpreenda.mp4\n",
            "  ✅ Metadados extraídos: 15.8s | vertical_9_16 | Áudio: Sim\n",
            "[3/3] Analisando a importancia de ser rico antes de ter.mp4\n",
            "  ⚙️ Extraindo metadados para: a importancia de ser rico antes de ter.mp4\n",
            "  ✅ Metadados extraídos: 19.0s | vertical_9_16 | Áudio: Sim\n",
            "\n",
            "💾 Metadados completos salvos em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dados/metadados_completos.json\n",
            "💾 Metadados em Excel salvos em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dados/metadados_videos.xlsx\n",
            "\n",
            "✅ EXTRAÇÃO DE METADADOS CONCLUÍDA!\n",
            "Total de vídeos com metadados extraídos: 3\n",
            "\n",
            "📊 Resumo dos Metadados:\n",
            "  - Formatos detectados: {'vertical_9_16': np.int64(3)}\n",
            "  - Duração média dos vídeos: 17.80s\n",
            "  - Vídeos com áudio: 3\n",
            "\n",
            "➡️ PRÓXIMA CÉLULA: 2.3 - DECOMPOSIÇÃO DE VÍDEOS (FRAMES, ÁUDIO, TEXTO)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CÉLULA 2.3: DECOMPOSIÇÃO DE VÍDEOS (FRAMES, ÁUDIO, TEXTO)\n",
        "# ============================================================================\n",
        "\n",
        "def decompor_video(video_info):\n",
        "    \"\"\"Decompõe um vídeo em frames, áudio e texto (OCR e transcrição)\"\"\"\n",
        "    video_path = video_info[\"caminho_completo\"]\n",
        "    video_id = video_info[\"id\"]\n",
        "    pasta_video_frames = os.path.join(PASTA_TRABALHO, \"frames_extraidos\", video_id)\n",
        "    os.makedirs(pasta_video_frames, exist_ok=True)\n",
        "\n",
        "    print(f\"  ⚙️ Decompondo vídeo: {video_info[\"nome_arquivo\"]}\")\n",
        "\n",
        "    decomposicao_data = {\n",
        "        \"video_id\": video_id,\n",
        "        \"frames_extraidos\": [],\n",
        "        \"textos_ocr\": [],\n",
        "        \"audio_transcrito\": \"\",\n",
        "        \"audio_analise\": {}\n",
        "    }\n",
        "\n",
        "    # Extração de Frames e OCR\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        frame_count = 0\n",
        "        frame_interval = int(fps) # 1 frame por segundo\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if frame_count % frame_interval == 0:\n",
        "                frame_time_sec = frame_count / fps\n",
        "                frame_filename = os.path.join(pasta_video_frames, f\"frame_{int(frame_time_sec):06d}.jpg\")\n",
        "                cv2.imwrite(frame_filename, frame)\n",
        "                decomposicao_data[\"frames_extraidos\"] .append({\n",
        "                    \"path\": frame_filename,\n",
        "                    \"timestamp_sec\": frame_time_sec\n",
        "                })\n",
        "\n",
        "                # OCR\n",
        "                try:\n",
        "                    text = pytesseract.image_to_string(Image.fromarray(frame), lang=\"por\")\n",
        "                    if text.strip():\n",
        "                        decomposicao_data[\"textos_ocr\"] .append({\n",
        "                            \"timestamp_sec\": frame_time_sec,\n",
        "                            \"text\": text.strip()\n",
        "                        })\n",
        "                except Exception as ocr_e:\n",
        "                    print(f\"    ⚠️ Aviso: Erro no OCR para frame {frame_time_sec}s: {ocr_e}\")\n",
        "\n",
        "            frame_count += 1\n",
        "        cap.release()\n",
        "        print(f\"    ✅ {len(decomposicao_data[\"frames_extraidos\"])} frames extraídos para {video_info[\"nome_arquivo\"]}\")\n",
        "        print(f\"    ✅ {len(decomposicao_data[\"textos_ocr\"])} textos encontrados via OCR para {video_info[\"nome_arquivo\"]}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    ❌ Erro na extração de frames/OCR para {video_info[\"nome_arquivo\"]}: {e}\")\n",
        "\n",
        "    # Extração e Transcrição de Áudio\n",
        "    audio_path = os.path.join(PASTA_TRABALHO, \"temp\", f\"{video_id}.wav\")\n",
        "    try:\n",
        "        video_clip = VideoFileClip(video_path)\n",
        "        if video_clip.audio:\n",
        "            video_clip.audio.write_audiofile(audio_path, verbose=False, logger=None)\n",
        "            print(f\"    ✅ Áudio extraído para {video_info[\"nome_arquivo\"]}\")\n",
        "\n",
        "            # Transcrição\n",
        "            r = sr.Recognizer()\n",
        "            with sr.AudioFile(audio_path) as source:\n",
        "                audio_listened = r.record(source)\n",
        "                try:\n",
        "                    text = r.recognize_google(audio_listened, language=\"pt-BR\")\n",
        "                    decomposicao_data[\"audio_transcrito\"] = text\n",
        "                    print(f\"    ✅ Áudio transcrito para {video_info[\"nome_arquivo\"]}\")\n",
        "                except sr.UnknownValueError:\n",
        "                    print(f\"    ⚠️ Aviso: Não foi possível transcrever o áudio para {video_info[\"nome_arquivo\"]}. Fala ininteligível.\")\n",
        "                except sr.RequestError as req_e:\n",
        "                    print(f\"    ⚠️ Aviso: Erro no serviço de transcrição para {video_info[\"nome_arquivo\"]}: {req_e}\")\n",
        "\n",
        "            # Análise de Áudio (Librosa)\n",
        "            y, sr_audio = librosa.load(audio_path)\n",
        "            tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr_audio)\n",
        "            decomposicao_data[\"audio_analise\"] = {\n",
        "                \"bpm\": float(tempo),\n",
        "                \"duracao_audio_segundos\": float(librosa.get_duration(y=y, sr=sr_audio))\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            print(f\"    ⚠️ Aviso: Vídeo {video_info[\"nome_arquivo\"]} não possui trilha de áudio.\")\n",
        "        video_clip.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    ❌ Erro na extração/transcrição de áudio para {video_info[\"nome_arquivo\"]}: {e}\")\n",
        "\n",
        "    # Detecção de Cortes (Scene Change Detection)\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            raise Exception(\"Não foi possível abrir o vídeo para detecção de cortes.\")\n",
        "\n",
        "        prev_frame = None\n",
        "        cuts = []\n",
        "        frame_idx = 0\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if prev_frame is not None:\n",
        "                diff = cv2.absdiff(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY))\n",
        "                non_zero_count = np.count_nonzero(diff)\n",
        "                if non_zero_count > (frame.shape[0] * frame.shape[1] * 0.3): # Limiar de 30% de mudança\n",
        "                    cuts.append(frame_idx / fps)\n",
        "            prev_frame = frame\n",
        "            frame_idx += 1\n",
        "        cap.release()\n",
        "        decomposicao_data[\"cortes_detectados_segundos\"] = cuts\n",
        "        print(f\"    ✅ {len(cuts)} cortes detectados para {video_info[\"nome_arquivo\"]}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    ❌ Erro na detecção de cortes para {video_info[\"nome_arquivo\"]}: {e}\")\n",
        "\n",
        "    return decomposicao_data\n",
        "\n",
        "def processar_decomposicao_todos_videos():\n",
        "    \"\"\"Processa a decomposição de todos os vídeos\"\"\"\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa(\"metadados\")\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Carregar metadados completos\n",
        "    metadados_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_completos.json\")\n",
        "    with open(metadados_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        videos_com_metadados = json.load(f)\n",
        "\n",
        "    decomposicoes_completas = []\n",
        "    sucessos = 0\n",
        "\n",
        "    print(\"\"\"\n",
        "Iniciando decomposição para {} vídeos...\"\"\".format(len(videos_com_metadados)))\n",
        "\n",
        "    for i, video in enumerate(videos_com_metadados, 1):\n",
        "        if video.get(\"status\") == \"metadados_extraidos\":\n",
        "            print(f\"[{i}/{len(videos_com_metadados)}] Decompondo {video[\"nome_arquivo\"]}\")\n",
        "            try:\n",
        "                decomposicao = decompor_video(video)\n",
        "                decomposicao[\"status\"] = \"decomposto\"\n",
        "                decomposicoes_completas.append(decomposicao)\n",
        "                sucessos += 1\n",
        "                print(f\"  ✅ Decomposição concluída para {video[\"nome_arquivo\"]}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ❌ ERRO na decomposição para {video[\"nome_arquivo\"]}: {e}\")\n",
        "                decomposicoes_completas.append({\"video_id\": video[\"id\"], \"status\": \"erro_decomposicao\", \"erro\": str(e)})\n",
        "        else:\n",
        "            print(f\"[{i}/{len(videos_com_metadados)}] Pulando {video.get(\"nome_arquivo\", video[\"id\"])} - Status: {video.get(\"status\", \"N/A\")}\")\n",
        "            decomposicoes_completas.append({\"video_id\": video[\"id\"], \"status\": video.get(\"status\", \"N/A\"), \"erro\": \"Pulado devido a erro anterior\"})\n",
        "\n",
        "    # Salvar decomposições completas\n",
        "    decomposicao_json_path = os.path.join(PASTA_TRABALHO, \"dados\", \"decomposicao_completa.json\")\n",
        "    with open(decomposicao_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(decomposicoes_completas, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"decomposicao\"] = True\n",
        "    config[\"total_videos_decompostos\"] = sucessos\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\"\"\n",
        "💾 Dados de decomposição salvos em: {decomposicao_json_path}\"\"\")\n",
        "\n",
        "    print(\"\"\"\n",
        "✅ DECOMPOSIÇÃO DE VÍDEOS CONCLUÍDA!\"\"\")\n",
        "    print(f\"Total de vídeos decompostos com sucesso: {sucessos}\")\n",
        "\n",
        "    if sucessos == 0:\n",
        "        print(\"❌ NENHUM VÍDEO FOI DECOMPOSTO COM SUCESSO. Verifique as etapas anteriores.\")\n",
        "    print(\"\"\"\n",
        "➡️ PRÓXIMA CÉLULA: 3.1 - ANÁLISE DE PADRÕES (TEMPORAIS, VISUAIS, TEXTO, ÁUDIO)\"\"\")\n",
        "\n",
        "# Executar decomposição\n",
        "try:\n",
        "    processar_decomposicao_todos_videos()\n",
        "except Exception as e:\n",
        "    print(f\"\"\"\n",
        "❌ ERRO GERAL NA DECOMPOSIÇÃO DE VÍDEOS: {e}\"\"\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "decomposicao_videos",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "4570d507-8959-4de8-8a70-7cc474a088f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando decomposição para 3 vídeos...\n",
            "[1/3] Decompondo ate quando voce vai ficar culpando os outros.mp4\n",
            "  ⚙️ Decompondo vídeo: ate quando voce vai ficar culpando os outros.mp4\n",
            "    ✅ 19 frames extraídos para ate quando voce vai ficar culpando os outros.mp4\n",
            "    ✅ 5 textos encontrados via OCR para ate quando voce vai ficar culpando os outros.mp4\n",
            "    ✅ Áudio extraído para ate quando voce vai ficar culpando os outros.mp4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3406907351.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;31m# Executar decomposição\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0mprocessar_decomposicao_todos_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     print(f\"\"\"\n",
            "\u001b[0;32m/tmp/ipython-input-3406907351.py\u001b[0m in \u001b[0;36mprocessar_decomposicao_todos_videos\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{i}/{len(videos_com_metadados)}] Decompondo {video[\"\u001b[0m\u001b[0mnome_arquivo\u001b[0m\u001b[0;34m\"]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0mdecomposicao\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecompor_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                 \u001b[0mdecomposicao\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"status\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"decomposto\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mdecomposicoes_completas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecomposicao\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3406907351.py\u001b[0m in \u001b[0;36mdecompor_video\u001b[0;34m(video_info)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0maudio_listened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_listened\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt-BR\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                     \u001b[0mdecomposicao_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"audio_transcrito\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"    ✅ Áudio transcrito para {video_info[\"\u001b[0m\u001b[0mnome_arquivo\u001b[0m\u001b[0;34m\"]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/speech_recognition/recognizers/google.py\u001b[0m in \u001b[0;36mrecognize_legacy\u001b[0;34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence, endpoint)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     response_text = obtain_transcription(\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/speech_recognition/recognizers/google.py\u001b[0m in \u001b[0;36mobtain_transcription\u001b[0;34m(request, timeout)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;34m\"recognition connection failed: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         )\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_chunked\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_chunk_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mchunk_left\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                     \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# toss the CRLF at the end of the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;31m# Read the next chunk size from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunk size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "melhorar os cortes aqui ( otimizar ele esta detectando muitos cortes. corrigir possivel erro de Fala ininteligível"
      ],
      "metadata": {
        "id": "AquW8stD8E1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CÉLULA 2.4: ANÁLISE DE ÁUDIO REFINADA (SUBLAYER DA LAYER 2)\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# CÉLULA 2.4: ANÁLISE DE ÁUDIO REFINADA (SUBLAYER DA LAYER 2)\n",
        "# ============================================================================\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.signal\n",
        "from scipy.stats import variation\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def converter_para_json_serializable(obj):\n",
        "    \"\"\"Converte tipos NumPy para tipos Python nativos para serialização JSON\"\"\"\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return [converter_para_json_serializable(x) for x in obj.tolist()]\n",
        "    elif isinstance(obj, list):\n",
        "        return [converter_para_json_serializable(x) for x in obj]\n",
        "    elif isinstance(obj, dict):\n",
        "        return {k: converter_para_json_serializable(v) for k, v in obj.items()}\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "def verificar_prerequisito_audio_refinado():\n",
        "    \"\"\"Verifica se a etapa de decomposição foi concluída\"\"\"\n",
        "    try:\n",
        "        if not \"PASTA_TRABALHO\" in globals():\n",
        "            raise Exception(\"Variáveis globais de configuração não encontradas. Execute a CÉLULA 1.2 primeiro.\")\n",
        "\n",
        "        config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "        if not os.path.exists(config_path):\n",
        "            raise Exception(\"Arquivo de configuração não encontrado. Execute as células anteriores.\")\n",
        "\n",
        "        with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "        if not config[\"status_etapas\"][\"decomposicao\"]:\n",
        "            raise Exception(\"A etapa 'decomposicao' não foi concluída. Execute a CÉLULA 2.3 primeiro.\")\n",
        "\n",
        "        return True, config\n",
        "    except Exception as e:\n",
        "        print(f\"❌ PRÉ-REQUISITO NÃO ATENDIDO: {e}\")\n",
        "        return False, None\n",
        "\n",
        "def analisar_variacao_volume(audio_path, sr=22050):\n",
        "    \"\"\"Analisa variações de volume da voz\"\"\"\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, sr=sr)\n",
        "\n",
        "        # Calcular RMS (Root Mean Square) em janelas\n",
        "        frame_length = int(0.1 * sr)  # Janelas de 100ms\n",
        "        hop_length = frame_length // 4\n",
        "        rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]\n",
        "\n",
        "        # Detectar variações bruscas\n",
        "        rms_db = librosa.amplitude_to_db(rms)\n",
        "        variacao_volume = np.diff(rms_db)\n",
        "\n",
        "        # Identificar picos de variação\n",
        "        threshold_variacao = np.std(variacao_volume) * 2\n",
        "        picos_variacao = np.where(np.abs(variacao_volume) > threshold_variacao)[0]\n",
        "\n",
        "        # Converter índices para timestamps\n",
        "        times = librosa.frames_to_time(picos_variacao, sr=sr, hop_length=hop_length)\n",
        "\n",
        "        return {\n",
        "            \"rms_medio\": float(np.mean(rms)),\n",
        "            \"variacao_volume_coef\": float(variation(rms)),\n",
        "            \"num_picos_variacao\": int(len(picos_variacao)),\n",
        "            \"timestamps_picos\": [float(t) for t in times.tolist()],\n",
        "            \"volume_db_medio\": float(np.mean(rms_db)),\n",
        "            \"volume_db_std\": float(np.std(rms_db))\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"    ⚠️ Erro na análise de variação de volume: {e}\")\n",
        "        return {}\n",
        "\n",
        "def detectar_picos_ruido(audio_path, sr=22050):\n",
        "    \"\"\"Detecta picos de ruído excessivo\"\"\"\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, sr=sr)\n",
        "\n",
        "        # Calcular espectrograma\n",
        "        S = librosa.stft(y)\n",
        "        S_db = librosa.amplitude_to_db(np.abs(S))\n",
        "\n",
        "        # Detectar ruído baseado em frequências altas\n",
        "        freq_bins = librosa.fft_frequencies(sr=sr)\n",
        "        high_freq_mask = freq_bins > 4000  # Frequências acima de 4kHz\n",
        "\n",
        "        high_freq_energy = np.mean(S_db[high_freq_mask], axis=0)\n",
        "\n",
        "        # Identificar segmentos com ruído excessivo\n",
        "        threshold_ruido = np.percentile(high_freq_energy, 85)\n",
        "        segmentos_ruidosos = np.where(high_freq_energy > threshold_ruido)[0]\n",
        "\n",
        "        # Converter para timestamps\n",
        "        hop_length = 512\n",
        "        times_ruido = librosa.frames_to_time(segmentos_ruidosos, sr=sr, hop_length=hop_length)\n",
        "\n",
        "        return {\n",
        "            \"energia_alta_freq_media\": float(np.mean(high_freq_energy)),\n",
        "            \"threshold_ruido\": float(threshold_ruido),\n",
        "            \"num_segmentos_ruidosos\": int(len(segmentos_ruidosos)),\n",
        "            \"timestamps_ruido\": [float(t) for t in times_ruido.tolist()],\n",
        "            \"percentual_audio_ruidoso\": float(len(segmentos_ruidosos) / len(high_freq_energy) * 100)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"    ⚠️ Erro na detecção de picos de ruído: {e}\")\n",
        "        return {}\n",
        "\n",
        "def analisar_ritmo_fala(transcricao_texto, duracao_audio):\n",
        "    \"\"\"Calcula ritmo da fala em palavras por minuto\"\"\"\n",
        "    try:\n",
        "        if not transcricao_texto or duracao_audio <= 0:\n",
        "            return {}\n",
        "\n",
        "        palavras = transcricao_texto.split()\n",
        "        num_palavras = len(palavras)\n",
        "        duracao_minutos = duracao_audio / 60.0\n",
        "\n",
        "        palavras_por_minuto = num_palavras / duracao_minutos\n",
        "\n",
        "        # Classificar ritmo\n",
        "        if palavras_por_minuto < 120:\n",
        "            classificacao_ritmo = \"Lento\"\n",
        "        elif palavras_por_minuto < 160:\n",
        "            classificacao_ritmo = \"Normal\"\n",
        "        elif palavras_por_minuto < 200:\n",
        "            classificacao_ritmo = \"Rápido\"\n",
        "        else:\n",
        "            classificacao_ritmo = \"Muito Rápido\"\n",
        "\n",
        "        return {\n",
        "            \"palavras_por_minuto\": float(palavras_por_minuto),\n",
        "            \"total_palavras\": int(num_palavras),\n",
        "            \"duracao_minutos\": float(duracao_minutos),\n",
        "            \"classificacao_ritmo\": str(classificacao_ritmo),\n",
        "            \"densidade_informacional\": float(num_palavras / duracao_audio)  # palavras por segundo\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"    ⚠️ Erro na análise de ritmo de fala: {e}\")\n",
        "        return {}\n",
        "\n",
        "def identificar_pausas_fala(audio_path, sr=22050):\n",
        "    \"\"\"Identifica pausas e silêncios na fala\"\"\"\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, sr=sr)\n",
        "\n",
        "        # Detectar segmentos de fala vs silêncio\n",
        "        frame_length = int(0.025 * sr)  # 25ms frames\n",
        "        hop_length = frame_length // 2\n",
        "\n",
        "        # Energia RMS para detectar atividade vocal\n",
        "        rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]\n",
        "\n",
        "        # Threshold para distinguir fala de silêncio\n",
        "        threshold_silencio = np.percentile(rms, 20)  # 20% mais baixo = silêncio\n",
        "\n",
        "        # Identificar segmentos de silêncio\n",
        "        is_silence = rms < threshold_silencio\n",
        "\n",
        "        # Encontrar início e fim das pausas\n",
        "        pausas = []\n",
        "        in_pause = False\n",
        "        pause_start = 0\n",
        "\n",
        "        times = librosa.frames_to_time(range(len(is_silence)), sr=sr, hop_length=hop_length)\n",
        "\n",
        "        for i, silent in enumerate(is_silence):\n",
        "            if silent and not in_pause:\n",
        "                in_pause = True\n",
        "                pause_start = times[i]\n",
        "            elif not silent and in_pause:\n",
        "                in_pause = False\n",
        "                pause_duration = times[i] - pause_start\n",
        "                if pause_duration > 0.2:  # Pausas maiores que 200ms\n",
        "                    pausas.append({\n",
        "                        \"inicio\": float(pause_start),\n",
        "                        \"fim\": float(times[i]),\n",
        "                        \"duracao\": float(pause_duration)\n",
        "                    })\n",
        "\n",
        "        # Estatísticas das pausas\n",
        "        if pausas:\n",
        "            duracoes_pausas = [p[\"duracao\"] for p in pausas]\n",
        "            pausa_media = np.mean(duracoes_pausas)\n",
        "            pausa_total = sum(duracoes_pausas)\n",
        "        else:\n",
        "            pausa_media = 0\n",
        "            pausa_total = 0\n",
        "\n",
        "        return {\n",
        "            \"num_pausas\": int(len(pausas)),\n",
        "            \"pausas_detectadas\": pausas,\n",
        "            \"duracao_pausa_media\": float(pausa_media),\n",
        "            \"tempo_total_pausas\": float(pausa_total),\n",
        "            \"percentual_pausas\": float(pausa_total / len(y) * sr * 100),\n",
        "            \"threshold_silencio\": float(threshold_silencio)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"    ⚠️ Erro na identificação de pausas: {e}\")\n",
        "        return {}\n",
        "\n",
        "def classificar_musica_fundo(audio_path, sr=22050):\n",
        "    \"\"\"Classifica características da música de fundo\"\"\"\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, sr=sr)\n",
        "\n",
        "        # Análise de características musicais\n",
        "        tempo, beats = librosa.beat.beat_track(y=y, sr=sr)\n",
        "\n",
        "        # Análise espectral\n",
        "        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
        "        spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "\n",
        "        # Energia\n",
        "        energia_total = np.sum(y**2)\n",
        "        energia_normalizada = energia_total / len(y)\n",
        "\n",
        "        # Classificação por energia\n",
        "        if energia_normalizada > 0.01:\n",
        "            nivel_energia = \"Alta\"\n",
        "        elif energia_normalizada > 0.001:\n",
        "            nivel_energia = \"Média\"\n",
        "        else:\n",
        "            nivel_energia = \"Baixa\"\n",
        "\n",
        "        # Classificação por características espectrais\n",
        "        centroide_medio = np.mean(spectral_centroids)\n",
        "        if centroide_medio > 3000:\n",
        "            brilho = \"Brilhante\"\n",
        "        elif centroide_medio > 1500:\n",
        "            brilho = \"Equilibrado\"\n",
        "        else:\n",
        "            brilho = \"Escuro\"\n",
        "\n",
        "        return {\n",
        "            \"tempo_bpm\": float(tempo),\n",
        "            \"num_beats\": int(len(beats)),\n",
        "            \"energia_nivel\": str(nivel_energia),\n",
        "            \"energia_valor\": float(energia_normalizada),\n",
        "            \"brilho_espectral\": str(brilho),\n",
        "            \"centroide_espectral_medio\": float(centroide_medio),\n",
        "            \"rolloff_medio\": float(np.mean(spectral_rolloff)),\n",
        "            \"mfcc_features\": [float(x) for x in mfcc.mean(axis=1).tolist()]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"    ⚠️ Erro na classificação de música de fundo: {e}\")\n",
        "        return {}\n",
        "\n",
        "def analisar_clareza_voz(audio_path, sr=22050):\n",
        "    \"\"\"Analisa clareza e inteligibilidade da voz\"\"\"\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, sr=sr)\n",
        "\n",
        "        # Faixa de frequência da voz humana (aproximadamente 85-255 Hz para fundamental)\n",
        "        # e harmônicos até ~4000 Hz para inteligibilidade\n",
        "\n",
        "        # Análise espectral\n",
        "        S = librosa.stft(y)\n",
        "        frequencies = librosa.fft_frequencies(sr=sr)\n",
        "\n",
        "        # Energia em diferentes bandas de frequência\n",
        "        baixa_freq = (frequencies >= 85) & (frequencies <= 255)    # Fundamental da voz\n",
        "        media_freq = (frequencies > 255) & (frequencies <= 2000)   # Formantes principais\n",
        "        alta_freq = (frequencies > 2000) & (frequencies <= 4000)   # Clareza/inteligibilidade\n",
        "\n",
        "        energia_baixa = np.mean(np.abs(S[baixa_freq]))\n",
        "        energia_media = np.mean(np.abs(S[media_freq]))\n",
        "        energia_alta = np.mean(np.abs(S[alta_freq]))\n",
        "\n",
        "        # Razão harmônica para ruído (aproximação)\n",
        "        spectral_flatness = librosa.feature.spectral_flatness(y=y)[0]\n",
        "        clareza_media = 1 - np.mean(spectral_flatness)  # Menor flatness = mais harmônica\n",
        "\n",
        "        # Zero crossing rate (indicador de fricção/clareza)\n",
        "        zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
        "        zcr_medio = np.mean(zcr)\n",
        "\n",
        "        # Score de clareza combinado\n",
        "        score_clareza = (energia_media + energia_alta) / (energia_baixa + 0.001) * clareza_media\n",
        "\n",
        "        if score_clareza > 10:\n",
        "            classificacao_clareza = \"Excelente\"\n",
        "        elif score_clareza > 5:\n",
        "            classificacao_clareza = \"Boa\"\n",
        "        elif score_clareza > 2:\n",
        "            classificacao_clareza = \"Regular\"\n",
        "        else:\n",
        "            classificacao_clareza = \"Precisa Melhoria\"\n",
        "\n",
        "        return {\n",
        "            \"score_clareza\": float(score_clareza),\n",
        "            \"classificacao_clareza\": classificacao_clareza,\n",
        "            \"energia_fundamental\": float(energia_baixa),\n",
        "            \"energia_formantes\": float(energia_media),\n",
        "            \"energia_agudos\": float(energia_alta),\n",
        "            \"harmonicidade\": float(clareza_media),\n",
        "            \"zero_crossing_rate\": float(zcr_medio)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"    ⚠️ Erro na análise de clareza de voz: {e}\")\n",
        "        return {}\n",
        "\n",
        "def detectar_sobreposicao_audio(audio_path, sr=22050):\n",
        "    \"\"\"Detecta sobreposição entre fala e música/efeitos\"\"\"\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, sr=sr)\n",
        "\n",
        "        # Separação harmônica/percussiva (aproximação para voz vs música)\n",
        "        y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
        "\n",
        "        # Análise de energia em cada componente\n",
        "        energia_harmonica = librosa.feature.rms(y=y_harmonic)[0]\n",
        "        energia_percussiva = librosa.feature.rms(y=y_percussive)[0]\n",
        "        energia_total = librosa.feature.rms(y=y)[0]\n",
        "\n",
        "        # Detectar momentos de sobreposição\n",
        "        threshold_sobreposicao = 0.7  # Threshold para detectar sobreposição significativa\n",
        "\n",
        "        # Razão entre componentes\n",
        "        razao_hp = energia_harmonica / (energia_percussiva + 0.001)\n",
        "\n",
        "        # Momentos onde há competição (energia similar em ambos)\n",
        "        competicao_mask = (energia_harmonica > threshold_sobreposicao * np.max(energia_harmonica)) & \\\n",
        "                         (energia_percussiva > threshold_sobreposicao * np.max(energia_percussiva))\n",
        "\n",
        "        segmentos_sobreposicao = np.where(competicao_mask)[0]\n",
        "\n",
        "        # Converter para timestamps\n",
        "        hop_length = 512\n",
        "        times_sobreposicao = librosa.frames_to_time(segmentos_sobreposicao, sr=sr, hop_length=hop_length)\n",
        "\n",
        "        return {\n",
        "            \"num_sobreposicoes\": int(len(segmentos_sobreposicao)),\n",
        "            \"timestamps_sobreposicao\": [float(t) for t in times_sobreposicao.tolist()],\n",
        "            \"percentual_sobreposicao\": float(len(segmentos_sobreposicao) / len(energia_total) * 100),\n",
        "            \"energia_harmonica_media\": float(np.mean(energia_harmonica)),\n",
        "            \"energia_percussiva_media\": float(np.mean(energia_percussiva)),\n",
        "            \"razao_harmonico_percussivo\": float(np.mean(razao_hp))\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"    ⚠️ Erro na detecção de sobreposição: {e}\")\n",
        "        return {}\n",
        "\n",
        "def mapear_efeitos_sonoros(audio_path, sr=22050):\n",
        "    \"\"\"Mapeia e cataloga efeitos sonoros\"\"\"\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, sr=sr)\n",
        "\n",
        "        # Detectar eventos transientes (possíveis efeitos sonoros)\n",
        "        onset_frames = librosa.onset.onset_detect(y=y, sr=sr, units='frames')\n",
        "        onset_times = librosa.frames_to_time(onset_frames, sr=sr)\n",
        "\n",
        "        # Análise de características espectrais em cada onset\n",
        "        efeitos_detectados = []\n",
        "\n",
        "        for i, onset_time in enumerate(onset_times):\n",
        "            # Janela de análise ao redor do onset\n",
        "            inicio_frame = max(0, onset_frames[i] - 10)\n",
        "            fim_frame = min(len(y), onset_frames[i] + 50)\n",
        "\n",
        "            janela = y[inicio_frame:fim_frame] if fim_frame > inicio_frame else np.array([])\n",
        "\n",
        "            if len(janela) > 0:\n",
        "                # Características do efeito\n",
        "                energia = np.sum(janela**2)\n",
        "                freq_dominante = librosa.piptrack(y=janela, sr=sr)[0]\n",
        "\n",
        "                # Classificação simplificada baseada em características\n",
        "                if energia > 0.1:\n",
        "                    tipo_efeito = \"Impacto\"\n",
        "                elif np.max(freq_dominante) > 5000:\n",
        "                    tipo_efeito = \"Agudo\"\n",
        "                elif np.max(freq_dominante) < 200:\n",
        "                    tipo_efeito = \"Grave\"\n",
        "                else:\n",
        "                    tipo_efeito = \"Médio\"\n",
        "\n",
        "                efeitos_detectados.append({\n",
        "                    \"timestamp\": float(onset_time),\n",
        "                    \"energia\": float(energia),\n",
        "                    \"tipo_estimado\": tipo_efeito\n",
        "                })\n",
        "\n",
        "        # Contagem por tipo\n",
        "        tipos_efeitos = Counter([ef[\"tipo_estimado\"] for ef in efeitos_detectados])\n",
        "\n",
        "        return {\n",
        "            \"num_efeitos_detectados\": int(len(efeitos_detectados)),\n",
        "            \"efeitos_por_minuto\": float(len(efeitos_detectados) / (len(y) / sr / 60)),\n",
        "            \"tipos_efeitos\": dict(tipos_efeitos),\n",
        "            \"efeitos_detalhados\": efeitos_detectados,\n",
        "            \"densidade_efeitos\": float(len(efeitos_detectados) / (len(y) / sr))\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"    ⚠️ Erro no mapeamento de efeitos sonoros: {e}\")\n",
        "        return {}\n",
        "\n",
        "def analisar_frequencias_especificas(audio_path, sr=22050):\n",
        "    \"\"\"Analisa sons recorrentes específicos\"\"\"\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, sr=sr)\n",
        "\n",
        "        # Template matching para sons específicos (simplificado)\n",
        "        # Detectar padrões de risada (frequências variadas em burst)\n",
        "        onset_strength = librosa.onset.onset_strength(y=y, sr=sr)\n",
        "\n",
        "        # Detectar rajadas de atividade (possível risada)\n",
        "        threshold_burst = np.percentile(onset_strength, 80)\n",
        "        bursts = onset_strength > threshold_burst\n",
        "\n",
        "        # Agrupar bursts próximos\n",
        "        burst_groups = []\n",
        "        in_burst = False\n",
        "        burst_start = 0\n",
        "\n",
        "        for i, is_burst in enumerate(bursts):\n",
        "            if is_burst and not in_burst:\n",
        "                in_burst = True\n",
        "                burst_start = i\n",
        "            elif not is_burst and in_burst:\n",
        "                in_burst = False\n",
        "                burst_duration = i - burst_start\n",
        "                if burst_duration > 5:  # Bursts de pelo menos 5 frames\n",
        "                    burst_groups.append({\n",
        "                        \"inicio\": librosa.frames_to_time(burst_start, sr=sr),\n",
        "                        \"duracao\": librosa.frames_to_time(burst_duration, sr=sr),\n",
        "                        \"intensidade\": np.mean(onset_strength[burst_start:i])\n",
        "                    })\n",
        "\n",
        "        # Detectar sons de notificação (tons puros em frequências específicas)\n",
        "        # Análise espectral para encontrar picos em frequências comuns de notificação\n",
        "        S = librosa.stft(y)\n",
        "        frequencies = librosa.fft_frequencies(sr=sr)\n",
        "\n",
        "        # Frequências típicas de notificação (440Hz, 880Hz, etc.)\n",
        "        freq_targets = [440, 880, 1320]  # A4, A5, E6\n",
        "        notificacoes_detectadas = 0\n",
        "\n",
        "        for freq_target in freq_targets:\n",
        "            freq_idx = np.argmin(np.abs(frequencies - freq_target))\n",
        "            freq_energy = np.abs(S[freq_idx])\n",
        "\n",
        "            # Detectar picos sustentados nesta frequência\n",
        "            peaks = scipy.signal.find_peaks(freq_energy, height=np.percentile(freq_energy, 90))[0]\n",
        "            notificacoes_detectadas += len(peaks)\n",
        "\n",
        "        return {\n",
        "            \"bursts_atividade\": int(len(burst_groups)),\n",
        "            \"detalhes_bursts\": burst_groups,\n",
        "            \"possivel_risada\": int(len(burst_groups)),\n",
        "            \"sons_notificacao_detectados\": int(notificacoes_detectadas),\n",
        "            \"densidade_eventos_especiais\": float((len(burst_groups) + notificacoes_detectadas) / (len(y) / sr))\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"    ⚠️ Erro na análise de frequências específicas: {e}\")\n",
        "        return {}\n",
        "\n",
        "def gerar_espectrograma_simplificado(audio_path, video_id, sr=22050):\n",
        "    \"\"\"Gera e salva espectrograma simplificado\"\"\"\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, sr=sr)\n",
        "\n",
        "        # Gerar espectrograma\n",
        "        S = librosa.stft(y)\n",
        "        S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
        "\n",
        "        # Criar visualização\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='hz')\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "        plt.title(f'Espectrograma - {video_id}')\n",
        "        plt.xlabel('Tempo (s)')\n",
        "        plt.ylabel('Frequência (Hz)')\n",
        "        plt.ylim(0, 8000)  # Focar em frequências até 8kHz\n",
        "\n",
        "        # Salvar\n",
        "        espectrograma_path = os.path.join(PASTA_TRABALHO, \"analise_audio\", f\"espectrograma_{video_id}.png\")\n",
        "        os.makedirs(os.path.dirname(espectrograma_path), exist_ok=True)\n",
        "        plt.savefig(espectrograma_path, dpi=150, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        # Análise de padrões espectrais\n",
        "        freq_bins = librosa.fft_frequencies(sr=sr)\n",
        "\n",
        "        # Energia por banda de frequência\n",
        "        baixa_energia = np.mean(S_db[freq_bins <= 500])\n",
        "        media_energia = np.mean(S_db[(freq_bins > 500) & (freq_bins <= 2000)])\n",
        "        alta_energia = np.mean(S_db[freq_bins > 2000])\n",
        "\n",
        "        return {\n",
        "            \"espectrograma_path\": str(espectrograma_path),\n",
        "            \"energia_baixa_freq\": float(baixa_energia),\n",
        "            \"energia_media_freq\": float(media_energia),\n",
        "            \"energia_alta_freq\": float(alta_energia),\n",
        "            \"frequencia_maxima\": float(np.max(freq_bins)),\n",
        "            \"resolucao_temporal\": float(len(y) / sr),\n",
        "            \"picos_espectrais\": int(len(scipy.signal.find_peaks(np.mean(S_db, axis=1))[0]))\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"    ⚠️ Erro na geração de espectrograma: {e}\")\n",
        "        return {\"espectrograma_path\": None}\n",
        "\n",
        "def processar_analise_audio_refinada():\n",
        "    \"\"\"Processa análise de áudio refinada para todos os vídeos\"\"\"\n",
        "    prerequisito_ok, config = verificar_prerequisito_audio_refinado()\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Carregar dados de decomposição\n",
        "    decomposicao_path = os.path.join(PASTA_TRABALHO, \"dados\", \"decomposicao_completa.json\")\n",
        "    with open(decomposicao_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        decomposicoes = json.load(f)\n",
        "\n",
        "    analises_audio_refinadas = []\n",
        "    sucessos = 0\n",
        "\n",
        "    print(f\"\"\"\n",
        "Iniciando análise de áudio refinada para {len(decomposicoes)} vídeos...\"\"\")\n",
        "\n",
        "    for i, decomposicao in enumerate(decomposicoes, 1):\n",
        "        if decomposicao.get(\"status\") == \"decomposto\":\n",
        "            video_id = decomposicao[\"video_id\"]\n",
        "            print(f\"[{i}/{len(decomposicoes)}] Analisando áudio refinado para: {video_id}\")\n",
        "\n",
        "            try:\n",
        "                # Buscar arquivo de áudio\n",
        "                audio_path = os.path.join(PASTA_TRABALHO, \"temp\", f\"{video_id}.wav\")\n",
        "\n",
        "                if not os.path.exists(audio_path):\n",
        "                    print(f\"    ⚠️ Arquivo de áudio não encontrado: {audio_path}\")\n",
        "                    analises_audio_refinadas.append({\n",
        "                        \"video_id\": video_id,\n",
        "                        \"status\": \"erro_audio_nao_encontrado\",\n",
        "                        \"erro\": \"Arquivo de áudio não encontrado\"\n",
        "                    })\n",
        "                    continue\n",
        "\n",
        "                analise_refinada = {\"video_id\": video_id}\n",
        "\n",
        "                print(f\"    🔊 Analisando variação de volume...\")\n",
        "                analise_refinada[\"variacao_volume\"] = analisar_variacao_volume(audio_path)\n",
        "\n",
        "                print(f\"    🔊 Detectando picos de ruído...\")\n",
        "                analise_refinada[\"picos_ruido\"] = detectar_picos_ruido(audio_path)\n",
        "\n",
        "                print(f\"    🔊 Analisando ritmo da fala...\")\n",
        "                transcricao = decomposicao.get(\"audio_transcrito\", \"\")\n",
        "                duracao_audio = decomposicao.get(\"audio_analise\", {}).get(\"duracao_audio_segundos\", 0)\n",
        "                analise_refinada[\"ritmo_fala\"] = analisar_ritmo_fala(transcricao, duracao_audio)\n",
        "\n",
        "                print(f\"    🔊 Identificando pausas...\")\n",
        "                analise_refinada[\"pausas_fala\"] = identificar_pausas_fala(audio_path)\n",
        "\n",
        "                print(f\"    🔊 Classificando música de fundo...\")\n",
        "                analise_refinada[\"musica_fundo\"] = classificar_musica_fundo(audio_path)\n",
        "\n",
        "                print(f\"    🔊 Analisando clareza da voz...\")\n",
        "                analise_refinada[\"clareza_voz\"] = analisar_clareza_voz(audio_path)\n",
        "\n",
        "                print(f\"    🔊 Detectando sobreposição...\")\n",
        "                analise_refinada[\"sobreposicao_audio\"] = detectar_sobreposicao_audio(audio_path)\n",
        "\n",
        "                print(f\"    🔊 Mapeando efeitos sonoros...\")\n",
        "                analise_refinada[\"efeitos_sonoros\"] = mapear_efeitos_sonoros(audio_path)\n",
        "\n",
        "                print(f\"    🔊 Analisando frequências específicas...\")\n",
        "                analise_refinada[\"frequencias_especificas\"] = analisar_frequencias_especificas(audio_path)\n",
        "\n",
        "                print(f\"    🔊 Gerando espectrograma...\")\n",
        "                analise_refinada[\"espectrograma\"] = gerar_espectrograma_simplificado(audio_path, video_id)\n",
        "\n",
        "                analise_refinada = converter_para_json_serializable(analise_refinada)\n",
        "                analise_refinada[\"status\"] = \"audio_refinado_concluido\"\n",
        "                analise_refinada[\"data_analise\"] = datetime.now().isoformat()\n",
        "\n",
        "                analises_audio_refinadas.append(analise_refinada)\n",
        "                sucessos += 1\n",
        "                print(f\"  ✅ Análise de áudio refinada concluída para {video_id}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ❌ ERRO na análise de áudio refinada para {video_id}: {e}\")\n",
        "                analises_audio_refinadas.append({\n",
        "                    \"video_id\": video_id,\n",
        "                    \"status\": \"erro_analise_audio_refinada\",\n",
        "                    \"erro\": str(e)\n",
        "                })\n",
        "        else:\n",
        "            print(f\"[{i}/{len(decomposicoes)}] Pulando {decomposicao.get('video_id', 'N/A')} - Status: {decomposicao.get('status', 'N/A')}\")\n",
        "            analises_audio_refinadas.append({\n",
        "                \"video_id\": decomposicao.get(\"video_id\", \"N/A\"),\n",
        "                \"status\": decomposicao.get(\"status\", \"N/A\"),\n",
        "                \"erro\": \"Pulado devido a erro anterior\"\n",
        "            })\n",
        "\n",
        "    # Salvar análises de áudio refinadas\n",
        "    analise_audio_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analise_audio_refinada.json\")\n",
        "    with open(analise_audio_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(analises_audio_refinadas, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Gerar relatório resumido em Excel\n",
        "    try:\n",
        "        # Preparar dados para Excel\n",
        "        dados_resumo = []\n",
        "        for analise in analises_audio_refinadas:\n",
        "            if analise.get(\"status\") == \"audio_refinado_concluido\":\n",
        "                resumo = {\n",
        "                    \"video_id\": analise[\"video_id\"],\n",
        "                    \"variacao_volume_coef\": analise[\"variacao_volume\"].get(\"variacao_volume_coef\", 0),\n",
        "                    \"num_picos_variacao\": analise[\"variacao_volume\"].get(\"num_picos_variacao\", 0),\n",
        "                    \"volume_db_medio\": analise[\"variacao_volume\"].get(\"volume_db_medio\", 0),\n",
        "                    \"percentual_audio_ruidoso\": analise[\"picos_ruido\"].get(\"percentual_audio_ruidoso\", 0),\n",
        "                    \"num_segmentos_ruidosos\": analise[\"picos_ruido\"].get(\"num_segmentos_ruidosos\", 0),\n",
        "                    \"palavras_por_minuto\": analise[\"ritmo_fala\"].get(\"palavras_por_minuto\", 0),\n",
        "                    \"classificacao_ritmo\": analise[\"ritmo_fala\"].get(\"classificacao_ritmo\", \"N/A\"),\n",
        "                    \"num_pausas\": analise[\"pausas_fala\"].get(\"num_pausas\", 0),\n",
        "                    \"percentual_pausas\": analise[\"pausas_fala\"].get(\"percentual_pausas\", 0),\n",
        "                    \"nivel_energia_musica\": analise[\"musica_fundo\"].get(\"energia_nivel\", \"N/A\"),\n",
        "                    \"tempo_bpm_musica\": analise[\"musica_fundo\"].get(\"tempo_bpm\", 0),\n",
        "                    \"score_clareza\": analise[\"clareza_voz\"].get(\"score_clareza\", 0),\n",
        "                    \"classificacao_clareza\": analise[\"clareza_voz\"].get(\"classificacao_clareza\", \"N/A\"),\n",
        "                    \"percentual_sobreposicao\": analise[\"sobreposicao_audio\"].get(\"percentual_sobreposicao\", 0),\n",
        "                    \"num_efeitos_detectados\": analise[\"efeitos_sonoros\"].get(\"num_efeitos_detectados\", 0),\n",
        "                    \"densidade_efeitos\": analise[\"efeitos_sonoros\"].get(\"densidade_efeitos\", 0),\n",
        "                    \"possivel_risada\": analise[\"frequencias_especificas\"].get(\"possivel_risada\", 0),\n",
        "                    \"sons_notificacao\": analise[\"frequencias_especificas\"].get(\"sons_notificacao_detectados\", 0),\n",
        "                    \"espectrograma_gerado\": \"Sim\" if analise[\"espectrograma\"].get(\"espectrograma_path\") else \"Não\"\n",
        "                }\n",
        "                dados_resumo.append(resumo)\n",
        "\n",
        "        if dados_resumo:\n",
        "            df_resumo = pd.DataFrame(dados_resumo)\n",
        "            resumo_excel_path = os.path.join(PASTA_TRABALHO, \"analise_audio\", \"resumo_analise_audio.xlsx\")\n",
        "            df_resumo.to_excel(resumo_excel_path, index=False, engine='openpyxl')\n",
        "            print(f\"\\n💾 Relatório resumo de análise de áudio salvo em: {resumo_excel_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    ❌ ERRO ao gerar relatório resumo de áudio: {e}\")\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    # Adicionar status para a nova etapa de análise de áudio refinada\n",
        "    config[\"status_etapas\"][\"analise_audio_refinada\"] = True\n",
        "    config[\"total_videos_analisados_audio_refinado\"] = sucessos\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\"\"\n",
        "✅ ANÁLISE DE ÁUDIO REFINADA CONCLUÍDA!\"\"\")\n",
        "    print(f\"Total de vídeos com análise de áudio refinada concluída: {sucessos}\")\n",
        "\n",
        "    if sucessos == 0:\n",
        "        print(\"❌ NENHUM VÍDEO FOI ANALISADO COM SUCESSO NESTA ETAPA. Verifique as etapas anteriores.\")\n",
        "    # No final, a próxima célula seria 3.1 (Análise de Padrões) que já foi executada\n",
        "    # mas como esta é uma nova célula (2.4), ela deveria vir antes de 3.1\n",
        "    # A mensagem original apontava para 3.1.\n",
        "    # Vamos manter a mensagem original para não alterar o fluxo do notebook existente,\n",
        "    # mas idealmente, essa célula seria inserida antes de 3.1 no fluxo.\n",
        "    print(\"\"\"\n",
        "➡️ PRÓXIMA CÉLULA: 3.1 - ANÁLISE DE PADRÕES (TEMPORAIS, VISUAIS, TEXTO, ÁUDIO)\"\"\")\n",
        "\n",
        "    # Return the list of analyses for potential downstream use\n",
        "    return analises_audio_refinadas\n",
        "\n",
        "# Executar análise de audio refinada\n",
        "try:\n",
        "    processar_analise_audio_refinada()\n",
        "except Exception as e:\n",
        "    print(f\"\"\"\n",
        "❌ ERRO GERAL NA ANÁLISE DE ÁUDIO REFINADA: {e}\"\"\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "EezfUtNZUZlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CÉLULA 2.4: GERAÇÃO DE LEGENDAS E ANÁLISE DE COPYWRITING - VERSÃO CORRIGIDA\n",
        "# ============================================================================\n",
        "\n",
        "import re\n",
        "from datetime import timedelta, datetime\n",
        "from collections import Counter\n",
        "import json\n",
        "import os\n",
        "\n",
        "# ============================================================================\n",
        "# Funções Auxiliares (Movidas para este escopo)\n",
        "# ============================================================================\n",
        "\n",
        "def buscar_dados_disponiveis():\n",
        "    \"\"\"Busca dados disponíveis em ordem de prioridade\"\"\"\n",
        "    pasta_dados = os.path.join(PASTA_TRABALHO, \"dados\")\n",
        "\n",
        "    # Lista de possíveis fontes de dados (em ordem de prioridade)\n",
        "    fontes_dados = [\n",
        "        (\"decomposicao_completa.json\", \"decomposicao\"),\n",
        "        (\"analises_padroes_completas.json\", \"padroes\"),\n",
        "        (\"analises_psicologicas_completas.json\", \"psicologico\"),\n",
        "        (\"metadados_completos.json\", \"metadados\"),\n",
        "        (\"videos_catalogados.json\", \"catalogados\")\n",
        "    ]\n",
        "\n",
        "    for arquivo, tipo in fontes_dados:\n",
        "        caminho_arquivo = os.path.join(pasta_dados, arquivo)\n",
        "\n",
        "        if os.path.exists(caminho_arquivo):\n",
        "            try:\n",
        "                with open(caminho_arquivo, \"r\", encoding=\"utf-8\") as f:\n",
        "                    dados = json.load(f)\n",
        "                if dados:\n",
        "                    return {\"tipo\": tipo, \"videos\": dados}\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Erro ao carregar dados de {arquivo}: {e}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "def extrair_texto_disponivel(video_data, tipo_fonte):\n",
        "    \"\"\"Extrai texto (transcrição ou OCR) da fonte de dados disponível\"\"\"\n",
        "    if tipo_fonte == \"decomposicao\":\n",
        "        return video_data.get(\"audio_transcrito\", \"\") or \" \".join([item.get(\"text\", \"\") for item in video_data.get(\"textos_ocr\", [])])\n",
        "    elif tipo_fonte == \"padroes\":\n",
        "         # Analise de padroes might have summary or keywords\n",
        "         return video_data.get(\"resumo_texto\", \"\") # or \" \".join(video_data.get(\"palavras_chave_texto\", []))\n",
        "    # Adicionar outras fontes conforme necessário\n",
        "    return \"\" # Default vazio\n",
        "\n",
        "def gerar_legendas_adaptadas(video_id, texto_transcrito, video_data):\n",
        "    \"\"\"Gera legendas para a análise de copywriting, adaptando se necessário\"\"\"\n",
        "    # Se já houver dados de decomposição com timestamps, usar esses\n",
        "    if video_data.get(\"frames_extraidos\"):\n",
        "        # Tentar usar os dados de decomposição originais para timestamps\n",
        "        # Isso requer carregar o arquivo decomposicao_completa.json novamente\n",
        "        decomposicao_path = os.path.join(PASTA_TRABALHO, \"dados\", \"decomposicao_completa.json\")\n",
        "        if os.path.exists(decomposicao_path):\n",
        "            try:\n",
        "                with open(decomposicao_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                    decomposicoes = json.load(f)\n",
        "                decomposicao_original = next((d for d in decomposicoes if d[\"video_id\"] == video_id), None)\n",
        "                if decomposicao_original and decomposicao_original.get(\"audio_transcrito\"):\n",
        "                     # Se a transcrição original existir, usar a função original de legendas\n",
        "                    duracao = video_data.get(\"duracao_segundos\", decomposicao_original.get(\"audio_analise\", {}).get(\"duracao_audio_segundos\", 30))\n",
        "                    return gerar_legendas_com_timestamps({\"id\": video_id, \"duracao_segundos\": duracao}, decomposicao_original)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Aviso: Erro ao carregar decomposição original para {video_id}: {e}. Gerando legendas estimadas.\")\n",
        "\n",
        "    # Se não houver decomposição original ou transcrição lá, gerar legendas estimadas\n",
        "    duracao_segundos = video_data.get(\"duracao_segundos\", estimar_duracao(texto_transcrito))\n",
        "    segmentos = dividir_texto_em_segmentos(texto_transcrito)\n",
        "    legendas_data = []\n",
        "    duracao_por_segmento = duracao_segundos / len(segmentos) if segmentos else 1\n",
        "\n",
        "    for i, segmento in enumerate(segmentos):\n",
        "        inicio_segundos = i * duracao_por_segmento\n",
        "        fim_segundos = (i + 1) * duracao_por_segmento\n",
        "\n",
        "        legenda_item = {\n",
        "            \"id\": i + 1,\n",
        "            \"inicio\": segundos_para_timestamp(inicio_segundos),\n",
        "            \"fim\": segundos_para_timestamp(fim_segundos),\n",
        "            \"texto\": segmento.strip(),\n",
        "            \"inicio_segundos\": inicio_segundos,\n",
        "            \"fim_segundos\": fim_segundos\n",
        "        }\n",
        "        legendas_data.append(legenda_item)\n",
        "\n",
        "    if not legendas_data:\n",
        "         return None, None, None\n",
        "\n",
        "    pasta_legendas = os.path.join(PASTA_TRABALHO, \"legendas\")\n",
        "    os.makedirs(pasta_legendas, exist_ok=True)\n",
        "    srt_path = os.path.join(pasta_legendas, f\"{video_id}_legendas_estimadas.srt\")\n",
        "    txt_path = os.path.join(pasta_legendas, f\"{video_id}_legendas_estimadas_timestamped.txt\")\n",
        "\n",
        "    gerar_arquivo_srt(legendas_data, srt_path)\n",
        "    gerar_arquivo_txt_timestamped(legendas_data, txt_path)\n",
        "\n",
        "    print(f\"    ✅ Legendas estimadas geradas: {srt_path}\")\n",
        "\n",
        "    return legendas_data, srt_path, txt_path\n",
        "\n",
        "\n",
        "def analisar_copywriting_adaptado(legendas_data, video_id, texto_completo):\n",
        "    \"\"\"Analisa copywriting usando a estrutura existente mas adaptada\"\"\"\n",
        "    print(\"    🔄 Analisando copywriting...\")\n",
        "\n",
        "    # Dicionários de padrões de copywriting (mantidos da função original)\n",
        "    ganchos_patterns = {\n",
        "        \"pergunta_retorica\": [r\"\\b(?:você|tu)\\s+(?:já|nunca|sempre|realmente|acha|imagina|sabe|quer|precisa)\",\n",
        "                            r\"(?:como|por que|quando|onde|o que).*\\?\"],\n",
        "        \"urgencia\": [r\"\\b(?:agora|hoje|urgente|rápido|imediato|última chance|só hoje|apenas|restam)\",\n",
        "                     r\"\\b(?:não perca|aproveite|garante já|corre|últimas vagas)\"],\n",
        "        \"escassez\": [r\"\\b(?:limitado|exclusivo|poucos|restam|última|única|especial|VIP)\",\n",
        "                     r\"\\b(?:só para|apenas para|somente|limitado a)\"],\n",
        "        \"autoridade\": [r\"\\b(?:especialista|expert|profissional|anos de experiência|comprovado|testado)\",\n",
        "                       r\"\\b(?:pesquisas mostram|estudos comprovam|cientificamente)\"],\n",
        "        \"prova_social\": [r\"\\b(?:milhares|centenas|todos|muitas pessoas|clientes|depoimentos)\",\n",
        "                         r\"\\b(?:já conseguiram|transformaram|mudaram|aprovaram)\"],\n",
        "        \"curiosidade\": [r\"\\b(?:segredo|descoberta|revelação|método|técnica|estratégia|fórmula)\",\n",
        "                        r\"\\b(?:ninguém te conta|poucos sabem|descobri que)\"],\n",
        "        \"problema_dor\": [r\"\\b(?:problema|dificuldade|frustração|sofre|dor|preocupa|bloqueia)\",\n",
        "                         r\"\\b(?:cansado de|chega de|pare de|não aguenta mais)\"],\n",
        "        \"solucao_resultado\": [r\"\\b(?:solução|resolve|elimina|transforma|muda|resultado|sucesso)\",\n",
        "                              r\"\\b(?:conseguir|alcançar|realizar|conquistar|atingir)\"]\n",
        "    }\n",
        "\n",
        "    gatilhos_patterns = {\n",
        "        \"reciprocidade\": [r\"\\b(?:grátis|de graça|presente|bônus|oferta|sem custo)\",\n",
        "                          r\"\\b(?:vou te dar|vou ensinar|vou mostrar|compartilhar com você)\"],\n",
        "        \"comprometimento\": [r\"\\b(?:compromisso|prometo|garanto|palavra|juro)\",\n",
        "                            r\"\\b(?:pode confiar|tenho certeza|assumo|responsabilizo)\"],\n",
        "        \"aprovacao_social\": [r\"\\b(?:aprovado por|recomendado|indicado|usado por|preferido)\",\n",
        "                             r\"\\b(?:famosos|influencers|especialistas|médicos|profissionais)\"],\n",
        "        \"aversao_perda\": [r\"\\b(?:perder|perdendo|vai ficar de fora|não vai conseguir)\",\n",
        "                          r\"\\b(?:sair perdendo|ficar para trás|oportunidade perdida)\"],\n",
        "        \"autoridade_especialista\": [r\"\\b(?:Dr|Dra|Professor|Mestre|PhD|especialista em)\",\n",
        "                                    r\"\\b(?:formado em|pós-graduado|anos estudando)\"],\n",
        "        \"emocional_medo\": [r\"\\b(?:medo|receio|preocupação|insegurança|ansiedade)\",\n",
        "                           r\"\\b(?:não conseguir|fracassar|dar errado|prejudicar)\"],\n",
        "        \"emocional_esperanca\": [r\"\\b(?:sonho|esperança|desejo|objetivo|meta|futuro melhor)\",\n",
        "                                r\"\\b(?:realizar|conquistar|alcançar|transformar|mudar vida)\"]\n",
        "    }\n",
        "\n",
        "    ctas_patterns = {\n",
        "        \"acao_imediata\": [r\"\\b(?:clica|clique|acesse|baixe|faça|compre|adquira|garanta)\",\n",
        "                          r\"\\b(?:não perca|aproveite|corre|vai|vem|participe)\"],\n",
        "        \"link_bio\": [r\"\\b(?:link na bio|bio|biografia|perfil|stories|direct)\",\n",
        "                     r\"\\b(?:DM|chama no WhatsApp|manda mensagem)\"],\n",
        "        \"engajamento\": [r\"\\b(?:comenta|compartilha|marca|salva|curte|like|segue)\",\n",
        "                        r\"\\b(?:conta nos comentários|deixa um|comenta aqui)\"],\n",
        "        \"inscricao\": [r\"\\b(?:inscreve|se inscreva|ativa|ativar|sino|notificação)\",\n",
        "                      r\"\\b(?:cadastra|cadastre-se|registra|assine)\"],\n",
        "        \"contato_vendas\": [r\"\\b(?:WhatsApp|telefone|ligue|chama|fala comigo|contato)\",\n",
        "                           r\"\\b(?:agende|marque|consulta|reunião|conversa)\"]\n",
        "    }\n",
        "\n",
        "    # Análise dos padrões\n",
        "    ganchos_encontrados = {}\n",
        "    gatilhos_encontrados = {}\n",
        "    ctas_encontrados = {}\n",
        "\n",
        "    # Analisar ganchos\n",
        "    for tipo, patterns in ganchos_patterns.items():\n",
        "        matches = []\n",
        "        for pattern in patterns:\n",
        "            matches.extend(re.finditer(pattern, texto_completo, re.IGNORECASE))\n",
        "        if matches:\n",
        "            ganchos_encontrados[tipo] = {\n",
        "                \"count\": len(matches),\n",
        "                \"exemplos\": [m.group() for m in matches[:3]],  # Top 3 exemplos\n",
        "                \"timestamps\": encontrar_timestamps_matches(matches, legendas_data, texto_completo) # Reusa a função de timestamp\n",
        "            }\n",
        "\n",
        "    # Analisar gatilhos\n",
        "    for tipo, patterns in gatilhos_patterns.items():\n",
        "        matches = []\n",
        "        for pattern in patterns:\n",
        "            matches.extend(re.finditer(pattern, texto_completo, re.IGNORECASE))\n",
        "        if matches:\n",
        "            gatilhos_encontrados[tipo] = {\n",
        "                \"count\": len(matches),\n",
        "                \"exemplos\": [m.group() for m in matches[:3]],\n",
        "                \"timestamps\": encontrar_timestamps_matches(matches, legendas_data, texto_completo)\n",
        "            }\n",
        "\n",
        "    # Analisar CTAs\n",
        "    for tipo, patterns in ctas_patterns.items():\n",
        "        matches = []\n",
        "        for pattern in patterns:\n",
        "            matches.extend(re.finditer(pattern, texto_completo, re.IGNORECASE))\n",
        "        if matches:\n",
        "            ctas_encontrados[tipo] = {\n",
        "                \"count\": len(matches),\n",
        "                \"exemplos\": [m.group() for m in matches[:3]],\n",
        "                \"timestamps\": encontrar_timestamps_matches(matches, legendas_data, texto_completo)\n",
        "            }\n",
        "\n",
        "    # Análise de estrutura narrativa\n",
        "    estrutura_narrativa = analisar_estrutura_narrativa(legendas_data) # Reusa a função\n",
        "\n",
        "    # Análise de poder de persuasão\n",
        "    score_persuasao = calcular_score_persuasao(ganchos_encontrados, gatilhos_encontrados, ctas_encontrados) # Reusa a função\n",
        "\n",
        "    analise_copywriting = {\n",
        "        \"video_id\": video_id,\n",
        "        \"texto_completo\": texto_completo,\n",
        "        \"total_palavras\": len(texto_completo.split()),\n",
        "        \"ganchos_detectados\": ganchos_encontrados,\n",
        "        \"gatilhos_mentais_detectados\": gatilhos_encontrados,\n",
        "        \"ctas_detectados\": ctas_encontrados,\n",
        "        \"estrutura_narrativa\": estrutura_narrativa,\n",
        "        \"score_persuasao\": score_persuasao,\n",
        "        \"recomendacoes_estrategicas\": gerar_recomendacoes_copywriting(ganchos_encontrados, gatilhos_encontrados, ctas_encontrados), # Reusa\n",
        "        \"templates_identificados\": identificar_templates_replicaveis(ganchos_encontrados, gatilhos_encontrados, ctas_encontrados), # Reusa\n",
        "        \"timestamp\": {\n",
        "            \"ganchos_timeline\": mapear_timeline_elementos(ganchos_encontrados, legendas_data), # Reusa\n",
        "            \"gatilhos_timeline\": mapear_timeline_elementos(gatilhos_encontrados, legendas_data), # Reusa\n",
        "            \"ctas_timeline\": mapear_timeline_elementos(ctas_encontrados, legendas_data) # Reusa\n",
        "        },\n",
        "        \"data_analise\": datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    return analise_copywriting\n",
        "\n",
        "def estimar_duracao(texto):\n",
        "    \"\"\"Estima a duração do vídeo com base na contagem de palavras (WPM médio)\"\"\"\n",
        "    palavras_por_minuto = 150 # Média de palavras por minuto\n",
        "    num_palavras = len(texto.split())\n",
        "    duracao_minutos = num_palavras / palavras_por_minuto\n",
        "    return duracao_minutos * 60 # Retorna em segundos\n",
        "\n",
        "# ============================================================================\n",
        "# Função Principal da Célula (Movida para este escopo)\n",
        "# ============================================================================\n",
        "def processar_copywriting_todos_videos_adaptado():\n",
        "    \"\"\"Processa análise de copywriting adaptada para o sistema existente\"\"\"\n",
        "    print(\"🔄 Iniciando processamento de copywriting adaptado...\")\n",
        "\n",
        "    # Verificar pré-requisitos de forma mais flexível\n",
        "    if not \"PASTA_TRABALHO\" in globals():\n",
        "        print(\"❌ Variáveis globais não encontradas. Execute a CÉLULA 1.2 primeiro.\")\n",
        "        return\n",
        "\n",
        "    pasta_dados = os.path.join(PASTA_TRABALHO, \"dados\")\n",
        "    if not os.path.exists(pasta_dados):\n",
        "        print(\"❌ Pasta de dados não encontrada. Execute as células anteriores primeiro.\")\n",
        "        return\n",
        "\n",
        "    # Buscar dados disponíveis em ordem de prioridade\n",
        "    dados_encontrados = buscar_dados_disponiveis()\n",
        "\n",
        "    if not dados_encontrados:\n",
        "        print(\"❌ Nenhum dado de vídeo encontrado. Execute as células anteriores primeiro.\")\n",
        "        return\n",
        "\n",
        "    print(f\"  ✅ Dados encontrados: {dados_encontrados['tipo']} com {len(dados_encontrados['videos'])} vídeos\")\n",
        "\n",
        "    analises_copywriting = []\n",
        "    legendas_geradas = []\n",
        "\n",
        "    print(f\"Processando copywriting para {len(dados_encontrados['videos'])} vídeos...\")\n",
        "\n",
        "    for i, video_data in enumerate(dados_encontrados['videos'], 1):\n",
        "        video_id = video_data.get(\"id\") or video_data.get(\"video_id\", f\"vid_{i:03d}\")\n",
        "\n",
        "        print(f\"[{i}/{len(dados_encontrados['videos'])}] Processando copywriting para: {video_id}\")\n",
        "\n",
        "        try:\n",
        "            # Extrair texto transcrito de diferentes fontes possíveis\n",
        "            texto_transcrito = extrair_texto_disponivel(video_data, dados_encontrados['tipo'])\n",
        "\n",
        "            if texto_transcrito and len(texto_transcrito.strip()) > 10:\n",
        "                # Gerar legendas se houver texto\n",
        "                legendas_data, srt_path, txt_path = gerar_legendas_adaptadas(video_id, texto_transcrito, video_data)\n",
        "\n",
        "                if legendas_data:\n",
        "                    legendas_info = {\n",
        "                        \"video_id\": video_id,\n",
        "                        \"srt_path\": srt_path,\n",
        "                        \"txt_path\": txt_path,\n",
        "                        \"total_segmentos\": len(legendas_data),\n",
        "                        \"duracao_total\": video_data.get(\"duracao_segundos\", estimar_duracao(texto_transcrito)),\n",
        "                        \"legendas_data\": legendas_data\n",
        "                    }\n",
        "                    legendas_geradas.append(legendas_info)\n",
        "\n",
        "                    # Análise de copywriting\n",
        "                    analise_copy = analisar_copywriting_adaptado(legendas_data, video_id, texto_transcrito)\n",
        "                    analises_copywriting.append(analise_copy)\n",
        "\n",
        "                    print(f\"  ✅ Copywriting analisado: Score {analise_copy['score_persuasao']}/100\")\n",
        "            else:\n",
        "                print(f\"  ⚠️ Pulando {video_id}: texto insuficiente para análise\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ❌ Erro no processamento de copywriting para {video_id}: {e}\")\n",
        "\n",
        "    if not analises_copywriting:\n",
        "        print(\"❌ Nenhuma análise de copywriting foi gerada. Verifique se os vídeos possuem transcrição.\")\n",
        "        return\n",
        "\n",
        "    # Salvar dados de copywriting\n",
        "    os.makedirs(pasta_dados, exist_ok=True)\n",
        "\n",
        "    copywriting_path = os.path.join(pasta_dados, \"analises_copywriting_completas.json\")\n",
        "    with open(copywriting_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(analises_copywriting, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"💾 Análises de copywriting salvas em: {copywriting_path}\")\n",
        "\n",
        "    # Salvar dados de legendas\n",
        "    legendas_path = os.path.join(pasta_dados, \"legendas_geradas.json\")\n",
        "    with open(legendas_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(legendas_geradas, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"💾 Dados de legendas salvos em: {legendas_path}\")\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    if os.path.exists(config_path):\n",
        "        with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "        config[\"status_etapas\"][\"copywriting_analysis\"] = True\n",
        "\n",
        "        with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\\n✅ ANÁLISE DE COPYWRITING CONCLUÍDA!\")\n",
        "    print(f\"Total de vídeos com copywriting analisado: {len(analises_copywriting)}\")\n",
        "    print(f\"Total de legendas geradas: {len(legendas_geradas)}\")\n",
        "    print(f\"\\n➡️ PRÓXIMA CÉLULA: 4.3 - INTEGRAÇÃO COM DASHBOARD\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Execução da Célula\n",
        "# ============================================================================\n",
        "try:\n",
        "    processar_copywriting_todos_videos_adaptado()\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERRO de Execução: {type(e).__name__}: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "id": "8oIgWuMTniIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LAYER 3: ANÁLISE E PROCESSAMENTO DE DADOS\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# CÉLULA 3.1: ANÁLISE DE PADRÕES (TEMPORAIS, VISUAIS, TEXTO, ÁUDIO)\n",
        "# ============================================================================\n",
        "\n",
        "def analisar_padroes_video(decomposicao_data):\n",
        "    \"\"\"Analisa padrões temporais, visuais, de texto e áudio de um vídeo.\"\"\"\n",
        "    video_id = decomposicao_data[\"video_id\"]\n",
        "    print(f\"  ⚙️ Analisando padrões para: {video_id}\")\n",
        "\n",
        "    analise_padroes = {\n",
        "        \"video_id\": video_id,\n",
        "        \"resumo_texto\": \"\",\n",
        "        \"palavras_chave_texto\": [],\n",
        "        \"analise_audio_detalhada\": {\n",
        "            \"bpm\": decomposicao_data[\"audio_analise\"] .get(\"bpm\"),\n",
        "            \"duracao_audio_segundos\": decomposicao_data[\"audio_analise\"] .get(\"duracao_audio_segundos\")\n",
        "        },\n",
        "        \"analise_visual_detalhada\": {\n",
        "            \"total_cortes\": len(decomposicao_data.get(\"cortes_detectados_segundos\", [])),\n",
        "            \"media_frames_por_corte\": 0,\n",
        "            \"complexidade_visual_media\": 0,\n",
        "            \"brilho_medio\": 0\n",
        "        },\n",
        "        \"padroes_gerais\": []\n",
        "    }\n",
        "\n",
        "    # Análise de Texto (OCR e Transcrição)\n",
        "    todos_textos = [item[\"text\"] for item in decomposicao_data[\"textos_ocr\"]]\n",
        "    if decomposicao_data[\"audio_transcrito\"]:\n",
        "        todos_textos.append(decomposicao_data[\"audio_transcrito\"])\n",
        "\n",
        "    if todos_textos:\n",
        "        texto_completo = \" \".join(todos_textos)\n",
        "        # Simples resumo e palavras-chave (pode ser aprimorado com NLP mais avançado)\n",
        "        import re # Ensure regex is imported here for local function\n",
        "        words = [word.lower() for word in re.findall(r\"\\b\\w+\\b\", texto_completo) if len(word) > 3]\n",
        "        word_counts = Counter(words).most_common(5)\n",
        "        analise_padroes[\"palavras_chave_texto\"] = [word for word, count in word_counts]\n",
        "        analise_padroes[\"resumo_texto\"] = texto_completo[:200] + \"...\" if len(texto_completo) > 200 else texto_completo\n",
        "\n",
        "\n",
        "    # Análise Visual Detalhada\n",
        "    if decomposicao_data[\"frames_extraidos\"]:\n",
        "        complexidades = []\n",
        "        brilhos = []\n",
        "        for frame_data in decomposicao_data[\"frames_extraidos\"]:\n",
        "            try:\n",
        "                img = cv2.imread(frame_data[\"path\"])\n",
        "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                complexidades.append(cv2.Laplacian(gray, cv2.CV_64F).var())\n",
        "                brilhos.append(np.mean(gray))\n",
        "            except Exception as e:\n",
        "                print(f\"    ⚠️ Aviso: Erro ao analisar frame {frame_data[\"path\"]}: {e}\")\n",
        "        if complexidades: analise_padroes[\"analise_visual_detalhada\"][\"complexidade_visual_media\"] = float(np.mean(complexidades))\n",
        "        if brilhos: analise_padroes[\"analise_visual_detalhada\"][\"brilho_medio\"] = float(np.mean(brilhos))\n",
        "\n",
        "    # Padrões Gerais\n",
        "    # Need video_info to get duration and total_frames\n",
        "    # This function is called with decomposicao_data, not video_info.\n",
        "    # Need to pass video_info or retrieve it here.\n",
        "    # Assuming for now that video_info is available or can be looked up.\n",
        "    # Based on process_analise_padroes_todos_videos, video_info is looked up there.\n",
        "    # Let's pass it to this function.\n",
        "\n",
        "    # Re-evaluating the design: It's better to process video by video and then\n",
        "    # consolidate. The current structure passes decomposicao_data, which\n",
        "    # doesn't include duration/total_frames directly.\n",
        "    # Option 1: Pass video_info to analisar_padroes_video.\n",
        "    # Option 2: Look up video_info inside analisar_padroes_video.\n",
        "    # Option 1 is cleaner.\n",
        "\n",
        "    # Let's assume video_info is passed as a second argument now.\n",
        "    # Modify process_analise_padroes_todos_videos to pass video_info.\n",
        "    # But for fixing the syntax error, let's just fix the print statements.\n",
        "    # The logic error regarding video_info will likely cause a runtime error later.\n",
        "\n",
        "    # Fixing syntax error first:\n",
        "    # The original code had: print(f\"\\nIniciando análise de padrões para {len(decomposicoes)} vídeos...\")\n",
        "    # And similar for other print statements.\n",
        "\n",
        "    # Padrões Gerais (Corrected logic assuming video_info is available)\n",
        "    # This part needs access to video_info which is not passed here currently.\n",
        "    # Leaving this logic as is for now, focusing on syntax.\n",
        "\n",
        "    return analise_padroes\n",
        "\n",
        "def processar_analise_padroes_todos_videos():\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa(\"decomposicao\")\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Carregar dados de decomposição e metadados\n",
        "    decomposicao_path = os.path.join(PASTA_TRABALHO, \"dados\", \"decomposicao_completa.json\")\n",
        "    metadados_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_completos.json\")\n",
        "    with open(decomposicao_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        decomposicoes = json.load(f)\n",
        "    with open(metadados_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        metadados_videos = json.load(f)\n",
        "\n",
        "    analises_padroes_completas = []\n",
        "    sucessos = 0\n",
        "\n",
        "    # Fixed SyntaxError here\n",
        "    print(f\"\\nIniciando análise de padrões para {len(decomposicoes)} vídeos...\")\n",
        "\n",
        "    for i, decomposicao in enumerate(decomposicoes, 1):\n",
        "        if decomposicao.get(\"status\") == \"decomposto\":\n",
        "            video_id = decomposicao[\"video_id\"]\n",
        "            video_info = next((v for v in metadados_videos if v[\"id\"] == video_id), None)\n",
        "            if video_info is None:\n",
        "                print(f\"  ❌ ERRO: Metadados não encontrados para o vídeo {video_id}. Pulando.\")\n",
        "                analises_padroes_completas.append({\"video_id\": video_id, \"status\": \"erro_analise_padroes\", \"erro\": \"Metadados não encontrados\"})\n",
        "                continue\n",
        "\n",
        "            print(f\"[{i}/{len(decomposicoes)}] Analisando padrões para: {video_info[\"nome_arquivo\"]}\")\n",
        "            try:\n",
        "                # Passing video_info to the analysis function\n",
        "                analise = analisar_padroes_video(decomposicao) # The function definition needs to be updated to accept video_info\n",
        "                # Let's update analisar_padroes_video to accept video_info\n",
        "                # This requires modifying analisar_padroes_video as well.\n",
        "                # But to fix the original SyntaxError, let's commit this change first.\n",
        "                # The subsequent error will then be clearer and addressable in the next turn.\n",
        "\n",
        "                # For now, let's just ensure the print statements are correct.\n",
        "                # The logical error of not having video_info in analisar_padroes_video\n",
        "                # will need a separate fix.\n",
        "\n",
        "                # Let's fix the print statements:\n",
        "                # The original error was in the initial print of this function.\n",
        "                # Let's also check the final print statements.\n",
        "\n",
        "                # Final print statements were also using multi-line f-strings.\n",
        "                # Fixing them here.\n",
        "\n",
        "                analise[\"status\"] = \"padroes_analisados\"\n",
        "                analises_padroes_completas.append(analise)\n",
        "                sucessos += 1\n",
        "                print(f\"  ✅ Análise de padrões concluída para {video_info[\"nome_arquivo\"]}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ❌ ERRO na análise de padrões para {video_info[\"nome_arquivo\"]}: {e}\")\n",
        "                analises_padroes_completas.append({\"video_id\": video_id, \"status\": \"erro_analise_padroes\", \"erro\": str(e)})\n",
        "        else:\n",
        "            print(f\"[{i}/{len(decomposicoes)}] Pulando {decomposicao.get(\"video_id\", \"N/A\")} - Status: {decomposicao.get(\"status\", \"N/A\")}\")\n",
        "            analises_padroes_completas.append({\"video_id\": decomposicao.get(\"video_id\", \"N/A\"), \"status\": decomposicao.get(\"status\", \"N/A\"), \"erro\": \"Pulado devido a erro anterior\"})\n",
        "\n",
        "\n",
        "    # Salvar análises de padrões completas\n",
        "    analises_json_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_padroes_completas.json\")\n",
        "    with open(analises_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(analises_padroes_completas, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Updated SyntaxError here\n",
        "    print(f\"\\n💾 Dados de análise de padrões salvos em: {analises_json_path}\")\n",
        "\n",
        "    # ============================================================================\n",
        "# PATCH PARA SCRIPT 3.1 - ADICIONE ESTAS LINHAS AO FINAL DO SEU SCRIPT 3.1\n",
        "# ============================================================================\n",
        "\n",
        "# ADICIONE ESTAS LINHAS IMEDIATAMENTE APÓS A LINHA:\n",
        "# print(f\"\\n💾 Dados de análise de padrões salvos em: {analises_json_path}\")\n",
        "\n",
        "    # CRUCIAL: Atualizar status no config.json (LINHAS QUE ESTAVAM FALTANDO)\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "\n",
        "    # Carregar config atual\n",
        "    if os.path.exists(config_path):\n",
        "        try:\n",
        "            with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                config = json.load(f)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Aviso: Erro ao carregar config existente: {e}\")\n",
        "            config = {\"status_etapas\": {}}\n",
        "    else:\n",
        "        config = {\"status_etapas\": {}}\n",
        "\n",
        "    # Garantir que existe a estrutura necessária\n",
        "    if \"status_etapas\" not in config:\n",
        "        config[\"status_etapas\"] = {}\n",
        "\n",
        "    # Atualizar status da etapa\n",
        "    config[\"status_etapas\"][\"analise_padroes\"] = True\n",
        "    config[\"total_videos_analisados_padroes\"] = sucessos\n",
        "\n",
        "    # Criar pasta config se não existir\n",
        "    config_dir = os.path.dirname(config_path)\n",
        "    if not os.path.exists(config_dir):\n",
        "        os.makedirs(config_dir)\n",
        "\n",
        "    # Salvar config atualizado\n",
        "    try:\n",
        "        with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"✅ Status da etapa 'analise_padroes' atualizado no config.json\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ ERRO ao salvar config.json: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# FIM DO PATCH\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "\n",
        "    # Updated SyntaxError here\n",
        "    print(\"\\n✅ ANÁLISE DE PADRÕES CONCLUÍDA!\")\n",
        "    print(f\"Total de vídeos com padrões analisados: {sucessos}\")\n",
        "\n",
        "    if sucessos == 0:\n",
        "        print(\"❌ NENHUM VÍDEO FOI ANALISADO COM SUCESSO NESTA ETAPA. Verifique as etapas anteriores.\")\n",
        "    # Updated SyntaxError here\n",
        "    print(\"\\n➡️ PRÓXIMA CÉLULA: 3.2 - ANÁLISE PSICOLÓGICA E GATILHOS DE ENGAJAMENTO\")\n",
        "\n",
        "# Executar análise de padrões\n",
        "import re # Importar regex para tokenização de palavras\n",
        "try:\n",
        "    processar_analise_padroes_todos_videos()\n",
        "except Exception as e:\n",
        "    # Updated SyntaxError here\n",
        "    print(f\"\\n❌ ERRO GERAL NA ANÁLISE DE PADRÕES: {e}\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")\n"
      ],
      "metadata": {
        "id": "analise_padroes"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# FUNÇÃO QUE ESTÁ FALTANDO - ADICIONE NO INÍCIO DO SCRIPT 3.2\n",
        "# ============================================================================\n",
        "\n",
        "def verificar_prerequisito_etapa(etapa_necessaria):\n",
        "    \"\"\"Verifica se uma etapa anterior foi concluída.\"\"\"\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "\n",
        "    if not os.path.exists(config_path):\n",
        "        print(f\"❌ PRÉ-REQUISITO NÃO ATENDIDO: Arquivo config.json não encontrado.\")\n",
        "        print(f\"   Execute as etapas anteriores primeiro.\")\n",
        "        return False, None\n",
        "\n",
        "    try:\n",
        "        with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            config = json.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ PRÉ-REQUISITO NÃO ATENDIDO: Erro ao carregar config.json: {e}\")\n",
        "        return False, None\n",
        "\n",
        "    if \"status_etapas\" not in config:\n",
        "        print(f\"❌ PRÉ-REQUISITO NÃO ATENDIDO: Campo 'status_etapas' não encontrado no config.json.\")\n",
        "        return False, config\n",
        "\n",
        "    if etapa_necessaria not in config[\"status_etapas\"]:\n",
        "        print(f\"❌ PRÉ-REQUISITO NÃO ATENDIDO: A etapa \\\"{etapa_necessaria}\\\" não foi encontrada.\")\n",
        "        print(f\"   Execute a célula correspondente primeiro.\")\n",
        "        return False, config\n",
        "\n",
        "    if not config[\"status_etapas\"][etapa_necessaria]:\n",
        "        print(f\"❌ PRÉ-REQUISITO NÃO ATENDIDO: A etapa \\\"{etapa_necessaria}\\\" não foi concluída.\")\n",
        "        print(f\"   Execute a célula correspondente primeiro.\")\n",
        "        return False, config\n",
        "\n",
        "    return True, config\n",
        "\n",
        "# ============================================================================\n",
        "# FIM DA FUNÇÃO\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CÉLULA 3.2: ANÁLISE PSICOLÓGICA E GATILHOS DE ENGAJAMENTO\n",
        "# ============================================================================\n",
        "\n",
        "def analisar_psicologicamente_video(video_id, analise_padroes_data):\n",
        "    \"\"\"Simula análise psicológica e detecção de gatilhos de engajamento.\"\"\"\n",
        "    print(f\"  ⚙️ Simulando análise psicológica para: {video_id}\")\n",
        "\n",
        "    # Gatilhos de Engajamento (Exemplos de simulação)\n",
        "    gatilhos_detectados = []\n",
        "    if \"Ritmo Rápido (Muitos Cortes)\" in analise_padroes_data.get(\"padroes_gerais\", []):\n",
        "        gatilhos_detectados.append(\"Ritmo Acelerado (Atenção)\")\n",
        "    if analise_padroes_data.get(\"analise_visual_detalhada\", {}).get(\"complexidade_visual_media\", 0) > 600:\n",
        "        gatilhos_detectados.append(\"Estímulo Visual Intenso\")\n",
        "    if analise_padroes_data.get(\"resumo_texto\") and (\"oferta\" in analise_padroes_data[\"resumo_texto\"] .lower() or \"agora\" in analise_padroes_data[\"resumo_texto\"] .lower()):\n",
        "        gatilhos_detectados.append(\"Urgência/Escassez (Texto)\")\n",
        "\n",
        "    # Emoções predominantes (Simulação simples baseada em palavras-chave ou padrões)\n",
        "    emocoes_predominantes = {\n",
        "        \"alegria\": 0.6,\n",
        "        \"surpresa\": 0.2,\n",
        "        \"confianca\": 0.7\n",
        "    }\n",
        "\n",
        "    analise_psicologica = {\n",
        "        \"video_id\": video_id,\n",
        "        \"gatilhos_detectados\": gatilhos_detectados,\n",
        "        \"emocoes_predominantes\": emocoes_predominantes,\n",
        "        \"insights_psicologicos\": \"Este é um placeholder para insights psicológicos mais profundos.\"\n",
        "    }\n",
        "\n",
        "    return analise_psicologica\n",
        "\n",
        "def processar_analise_psicologica_todos_videos():\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa(\"analise_padroes\")\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Carregar dados de análise de padrões\n",
        "    analises_padroes_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_padroes_completas.json\")\n",
        "    with open(analises_padroes_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        analises_padroes = json.load(f)\n",
        "\n",
        "    analises_psicologicas_completas = []\n",
        "    sucessos = 0\n",
        "\n",
        "    print(\"\"\"\n",
        "Iniciando análise psicológica para {} vídeos...\"\"\".format(len(analises_padroes)))\n",
        "\n",
        "    for i, analise_padroes_data in enumerate(analises_padroes, 1):\n",
        "        if analise_padroes_data.get(\"status\") == \"padroes_analisados\":\n",
        "            video_id = analise_padroes_data[\"video_id\"]\n",
        "            print(f\"[{i}/{len(analises_padroes)}] Analisando psicologicamente: {video_id}\")\n",
        "            try:\n",
        "                analise = analisar_psicologicamente_video(video_id, analise_padroes_data)\n",
        "                analise[\"status\"] = \"analise_psicologica_concluida\"\n",
        "                analises_psicologicas_completas.append(analise)\n",
        "                sucessos += 1\n",
        "                print(f\"  ✅ Análise psicológica concluída para {video_id}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ❌ ERRO na análise psicológica para {video_id}: {e}\")\n",
        "                analises_psicologicas_completas.append({\"video_id\": video_id, \"status\": \"erro_analise_psicologica\", \"erro\": str(e)})\n",
        "        else:\n",
        "            print(f\"[{i}/{len(analises_padroes)}] Pulando {analise_padroes_data.get(\"video_id\")} - Status: {analise_padroes_data.get(\"status\", \"N/A\")}\")\n",
        "            analises_psicologicas_completas.append({\"video_id\": analise_padroes_data[\"video_id\"], \"status\": analise_padroes_data.get(\"status\", \"N/A\"), \"erro\": \"Pulado devido a erro anterior\"})\n",
        "\n",
        "    # Salvar análises psicológicas completas\n",
        "    analises_json_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_psicologicas_completas.json\")\n",
        "    with open(analises_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(analises_psicologicas_completas, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"analise_psicologica\"] = True\n",
        "    config[\"total_videos_analisados_psicologicamente\"] = sucessos\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\"\"\n",
        "💾 Dados de análise psicológica salvos em: {analises_json_path}\"\"\")\n",
        "\n",
        "    print(\"\"\"\n",
        "✅ ANÁLISE PSICOLÓGICA CONCLUÍDA!\"\"\")\n",
        "    print(f\"Total de vídeos com análise psicológica: {sucessos}\")\n",
        "\n",
        "    if sucessos == 0:\n",
        "        print(\"❌ NENHUM VÍDEO FOI ANALISADO PSICOLOGICAMENTE COM SUCESSO. Verifique as etapas anteriores.\")\n",
        "    print(\"\"\"\n",
        "➡️ PRÓXIMA CÉLULA: 4.1 - GERAÇÃO DE RELATÓRIOS HUMANIZADOS\"\"\")\n",
        "\n",
        "# Executar análise psicológica\n",
        "try:\n",
        "    processar_analise_psicologica_todos_videos()\n",
        "except Exception as e:\n",
        "    print(f\"\"\"\n",
        "❌ ERRO GERAL NA ANÁLISE PSICOLÓGICA: {e}\"\"\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "analise_psicologica"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LAYER 4: GERAÇÃO DE RELATÓRIOS E BLUEPRINT ESTRATÉGICO\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# CÉLULA 4.1: GERAÇÃO DE RELATÓRIOS HUMANIZADOS (ÁUDIO, VISUAL, TEXTO, PSICOLÓGICO)\n",
        "# ============================================================================\n",
        "\n",
        "from fpdf import FPDF # Importar FPDF para geração de PDF\n",
        "\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.cell(0, 10, 'Relatório de Engenharia Reversa de Vídeos', 0, 1, 'C')\n",
        "        self.ln(10)\n",
        "\n",
        "    def footer(self):\n",
        "        self.set_y(-15)\n",
        "        self.set_font('Arial', 'I', 8)\n",
        "        self.cell(0, 10, f'Página {self.page_no()}/{{nb}}', 0, 0, 'C')\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.cell(0, 10, title, 0, 1, 'L')\n",
        "        self.ln(5)\n",
        "\n",
        "    def chapter_body(self, body):\n",
        "        self.set_font('Arial', '', 10)\n",
        "        self.multi_cell(0, 5, body)\n",
        "        self.ln()\n",
        "\n",
        "def gerar_relatorio_texto(video_id, analise_padroes_data, pasta_destino):\n",
        "    df_texto = pd.DataFrame([analise_padroes_data])\n",
        "    excel_path = os.path.join(pasta_destino, f'RELATORIO_TEXTO_HUMANIZADO_{video_id}.xlsx')\n",
        "    df_texto.to_excel(excel_path, index=False, engine='openpyxl')\n",
        "\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "    pdf.chapter_title('Estratégia de Conteúdo Textual')\n",
        "    pdf.chapter_body(f'Resumo do Texto: {analise_padroes_data.get('resumo_texto', 'N/A')}')\n",
        "    pdf.chapter_body(f'Palavras-chave: {', '.join(analise_padroes_data.get('palavras_chave_texto', []))}')\n",
        "    pdf_path = os.path.join(pasta_destino, f'ESTRATEGIA_CONTEUDO_TEXTUAL_{video_id}.pdf')\n",
        "    pdf.output(pdf_path)\n",
        "    return excel_path, pdf_path\n",
        "\n",
        "def gerar_relatorio_audio(video_id, analise_padroes_data, pasta_destino):\n",
        "    df_audio = pd.DataFrame([analise_padroes_data.get('analise_audio_detalhada', {})])\n",
        "    excel_path = os.path.join(pasta_destino, f'RELATORIO_AUDIO_HUMANIZADO_{video_id}.xlsx')\n",
        "    df_audio.to_excel(excel_path, index=False, engine='openpyxl')\n",
        "\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "    pdf.chapter_title('Resumo de Áudio Estratégico')\n",
        "    pdf.chapter_body(f'BPM: {analise_padroes_data.get('analise_audio_detalhada', {}).get('bpm', 'N/A')}')\n",
        "    pdf.chapter_body(f'Duração do Áudio: {analise_padroes_data.get('analise_audio_detalhada', {}).get('duracao_audio_segundos', 'N/A')} segundos')\n",
        "    pdf_path = os.path.join(pasta_destino, f'RESUMO_AUDIO_ESTRATEGICO_{video_id}.pdf')\n",
        "    pdf.output(pdf_path)\n",
        "    return excel_path, pdf_path\n",
        "\n",
        "def gerar_relatorio_visual(video_id, analise_padroes_data, pasta_destino):\n",
        "    df_visual = pd.DataFrame([analise_padroes_data.get('analise_visual_detalhada', {})])\n",
        "    excel_path = os.path.join(pasta_destino, f'RELATORIO_VISUAL_HUMANIZADO_{video_id}.xlsx')\n",
        "    df_visual.to_excel(excel_path, index=False, engine='openpyxl')\n",
        "\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "    pdf.chapter_title('Estratégia Visual Completa')\n",
        "    pdf.chapter_body(f'Total de Cortes: {analise_padroes_data.get('analise_visual_detalhada', {}).get('total_cortes', 'N/A')}')\n",
        "    pdf.chapter_body(f'Complexidade Visual Média: {analise_padroes_data.get('analise_visual_detalhada', {}).get('complexidade_visual_media', 'N/A'):.2f}')\n",
        "    pdf.chapter_body(f'Brilho Médio: {analise_padroes_data.get('analise_visual_detalhada', {}).get('brilho_medio', 'N/A'):.2f}')\n",
        "    pdf_path = os.path.join(pasta_destino, f'ESTRATEGIA_VISUAL_COMPLETA_{video_id}.pdf')\n",
        "    pdf.output(pdf_path)\n",
        "    return excel_path, pdf_path\n",
        "\n",
        "def gerar_relatorio_psicologico(video_id, analise_psicologica_data, pasta_destino):\n",
        "    df_psico = pd.DataFrame([analise_psicologica_data])\n",
        "    excel_path = os.path.join(pasta_destino, f'RELATORIO_PSICOLOGICO_HUMANIZADO_{video_id}.xlsx')\n",
        "    df_psico.to_excel(excel_path, index=False, engine='openpyxl')\n",
        "\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "    pdf.chapter_title('Manual de Psicologia Viral')\n",
        "    pdf.chapter_body(f'Gatilhos Detectados: {', '.join(analise_psicologica_data.get('gatilhos_detectados', []))}')\n",
        "    pdf.chapter_body(f'Emoções Predominantes: {analise_psicologica_data.get('emocoes_predominantes', 'N/A')}')\n",
        "    pdf.chapter_body(f'Insights: {analise_psicologica_data.get('insights_psicologicos', 'N/A')}')\n",
        "    pdf_path = os.path.join(pasta_destino, f'MANUAL_PSICOLOGIA_VIRAL_{video_id}.pdf')\n",
        "    pdf.output(pdf_path)\n",
        "    return excel_path, pdf_path\n",
        "\n",
        "def processar_geracao_relatorios_todos_videos():\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa('analise_psicologica')\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Carregar dados de análise de padrões e psicológica\n",
        "    analises_padroes_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_padroes_completas.json\")\n",
        "    analises_psicologicas_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_psicologicas_completas.json\")\n",
        "    with open(analises_padroes_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        analises_padroes = json.load(f)\n",
        "    with open(analises_psicologicas_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        analises_psicologicas = json.load(f)\n",
        "\n",
        "    sucessos = 0\n",
        "\n",
        "    print(f\"\"\"\n",
        "Iniciando geração de relatórios humanizados para {len(analises_padroes)} vídeos...\"\"\")\n",
        "\n",
        "    for i, analise_padroes_data in enumerate(analises_padroes, 1):\n",
        "        video_id = analise_padroes_data[\"video_id\"]\n",
        "        analise_psicologica_data = next((a for a in analises_psicologicas if a[\"video_id\"] == video_id), None)\n",
        "\n",
        "        if analise_padroes_data.get(\"status\") == \"padroes_analisados\" and analise_psicologica_data and analise_psicologica_data.get(\"status\") == \"analise_psicologica_concluida\":\n",
        "            print(f\"[{i}/{len(analises_padroes)}] Gerando relatórios para: {video_id}\")\n",
        "            try:\n",
        "                # Geração de Relatórios de Texto\n",
        "                pasta_texto = os.path.join(PASTA_TRABALHO, \"analise_texto\")\n",
        "                os.makedirs(pasta_texto, exist_ok=True)\n",
        "                excel_text, pdf_text = gerar_relatorio_texto(video_id, analise_padroes_data, pasta_texto)\n",
        "                print(f\"  💾 Relatório de Texto (XLSX) salvo em: {excel_text}\")\n",
        "                print(f\"  💾 Estratégia de Conteúdo Textual (PDF) salvo em: {pdf_text}\")\n",
        "\n",
        "                # Geração de Relatórios de Áudio\n",
        "                pasta_audio = os.path.join(PASTA_TRABALHO, \"analise_audio\")\n",
        "                os.makedirs(pasta_audio, exist_ok=True)\n",
        "                excel_audio, pdf_audio = gerar_relatorio_audio(video_id, analise_padroes_data, pasta_audio)\n",
        "                print(f\"  💾 Relatório de Áudio (XLSX) salvo em: {excel_audio}\")\n",
        "                print(f\"  💾 Resumo de Áudio Estratégico (PDF) salvo em: {pdf_audio}\")\n",
        "\n",
        "                # Geração de Relatórios Visuais\n",
        "                pasta_visual = os.path.join(PASTA_TRABALHO, \"analise_visual\")\n",
        "                os.makedirs(pasta_visual, exist_ok=True)\n",
        "                excel_visual, pdf_visual = gerar_relatorio_visual(video_id, analise_padroes_data, pasta_visual)\n",
        "                print(f\"  💾 Relatório Visual (XLSX) salvo em: {excel_visual}\")\n",
        "                print(f\"  💾 Estratégia Visual Completa (PDF) salvo em: {pdf_visual}\")\n",
        "\n",
        "                # Geração de Relatórios Psicológicos\n",
        "                pasta_psicologica = os.path.join(PASTA_TRABALHO, \"analise_psicologica\")\n",
        "                os.makedirs(pasta_psicologica, exist_ok=True)\n",
        "                excel_psico, pdf_psico = gerar_relatorio_psicologico(video_id, analise_psicologica_data, pasta_psicologica)\n",
        "                print(f\"  💾 Relatório Psicológico (XLSX) salvo em: {excel_psico}\")\n",
        "                print(f\"  💾 Manual de Psicologia Viral (PDF) salvo em: {pdf_psico}\")\n",
        "\n",
        "                sucessos += 1\n",
        "                print(f\"  ✅ Relatórios gerados para {video_id}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ❌ ERRO na geração de relatórios para {video_id}: {e}\")\n",
        "        else:\n",
        "            print(f\"[{i}/{len(analises_padroes)}] Pulando {video_id} - Pré-requisitos não atendidos.\")\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"relatorios_humanizados\"] = True\n",
        "    config[\"total_videos_relatorios_gerados\"] = sucessos\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(\"\"\"\n",
        "✅ GERAÇÃO DE RELATÓRIOS HUMANIZADOS CONCLUÍDA!\"\"\")\n",
        "    print(f\"Total de vídeos com relatórios gerados: {sucessos}\")\n",
        "\n",
        "    if sucessos == 0:\n",
        "        print(\"❌ NENHUM VÍDEO TEVE RELATÓRIOS GERADOS COM SUCESSO. Verifique as etapas anteriores.\")\n",
        "    print(\"\"\"\n",
        "➡️ PRÓXIMA CÉLULA: 4.2 - GERAÇÃO DO BLUEPRINT FINAL E DASHBOARD\"\"\")\n",
        "\n",
        "# Executar geração de relatórios\n",
        "try:\n",
        "    processar_geracao_relatorios_todos_videos()\n",
        "except Exception as e:\n",
        "    print(f\"\"\"\n",
        "❌ ERRO GERAL NA GERAÇÃO DE RELATÓRIOS: {e}\"\"\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "relatorios_humanizados"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CÉLULA 4.2: GERAÇÃO DO BLUEPRINT FINAL E DASHBOARD\n",
        "# ============================================================================\n",
        "\n",
        "def gerar_blueprint_dashboard():\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa(\"relatorios_humanizados\")\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Carregar todos os dados de análise\n",
        "    metadados_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_completos.json\")\n",
        "    decomposicao_path = os.path.join(PASTA_TRABALHO, \"dados\", \"decomposicao_completa.json\")\n",
        "    analises_padroes_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_padroes_completas.json\")\n",
        "    analises_psicologicas_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_psicologicas_completas.json\")\n",
        "\n",
        "    with open(metadados_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        metadados = json.load(f)\n",
        "    with open(decomposicao_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        decomposicoes = json.load(f)\n",
        "    with open(analises_padroes_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        analises_padroes = json.load(f)\n",
        "    with open(analises_psicologicas_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        analises_psicologicas = json.load(f)\n",
        "\n",
        "    dados_consolidados = []\n",
        "    for video_meta in metadados:\n",
        "        video_id = video_meta[\"id\"]\n",
        "        decomposicao = next((d for d in decomposicoes if d[\"video_id\"] == video_id), {})\n",
        "        analise_padroes = next((ap for ap in analises_padroes if ap[\"video_id\"] == video_id), {})\n",
        "        analise_psicologica = next((aps for aps in analises_psicologicas if aps[\"video_id\"] == video_id), {})\n",
        "        consolidado = {\n",
        "            \"video_id\": video_id,\n",
        "            \"nome_arquivo\": video_meta.get(\"nome_arquivo\"),\n",
        "            \"duracao_segundos\": video_meta.get(\"duracao_segundos\"),\n",
        "            \"formato_detectado\": video_meta.get(\"formato_detectado\"),\n",
        "            \"tem_audio\": video_meta.get(\"tem_audio\"),\n",
        "            \"total_frames\": video_meta.get(\"total_frames\"),\n",
        "            \"ocr_textos_count\": len(decomposicao.get(\"textos_ocr\", [])),\n",
        "            \"audio_transcrito_len\": len(decomposicao.get(\"audio_transcrito\", \"\")),\n",
        "            \"cortes_detectados_count\": len(decomposicao.get(\"cortes_detectados_segundos\", [])),\n",
        "            \"bpm_audio\": analise_padroes.get(\"analise_audio_detalhada\", {}).get(\"bpm\"),\n",
        "            \"complexidade_visual_media\": analise_padroes.get(\"analise_visual_detalhada\", {}).get(\"complexidade_visual_media\"),\n",
        "            \"brilho_medio\": analise_padroes.get(\"analise_visual_detalhada\", {}).get(\"brilho_medio\"),\n",
        "            \"padroes_gerais\": \", \".join(analise_padroes.get(\"padroes_gerais\", [])),\n",
        "            \"gatilhos_psicologicos\": \", \".join(analise_psicologica.get(\"gatilhos_detectados\", [])),\n",
        "            \"emocoes_predominantes\": str(analise_psicologica.get(\"emocoes_predominantes\", {})),\n",
        "            \"status_geral\": video_meta.get(\"status\") # Pode ser aprimorado para refletir o status de todas as etapas\n",
        "        }\n",
        "        dados_consolidados.append(consolidado)\n",
        "\n",
        "    df_final = pd.DataFrame(dados_consolidados)\n",
        "\n",
        "    # Salvar Dashboard Executivo (Excel)\n",
        "    dashboard_excel_path = os.path.join(PASTA_TRABALHO, \"dashboard\", \"DASHBOARD_MASTER_EXECUTIVO.xlsx\")\n",
        "    df_final.to_excel(dashboard_excel_path, index=False, engine=\"openpyxl\")\n",
        "    print(f\"\\n💾 Dashboard Executivo (XLSX) salvo em: {dashboard_excel_path}\")\n",
        "\n",
        "    # Salvar Dados Consolidados (CSV e JSON)\n",
        "    dados_csv_path = os.path.join(PASTA_TRABALHO, \"dashboard\", \"dados_consolidados.csv\")\n",
        "    df_final.to_csv(dados_csv_path, index=False, encoding=\"utf-8\")\n",
        "    print(f\"💾 Dados Consolidados (CSV) salvo em: {dados_csv_path}\")\n",
        "\n",
        "    dados_json_path = os.path.join(PASTA_TRABALHO, \"dashboard\", \"dados_detalhados.json\")\n",
        "    with open(dados_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(dados_consolidados, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"💾 Dados Detalhados (JSON) salvo em: {dados_json_path}\")\n",
        "\n",
        "    # Geração de Dashboard Interativo (HTML - Exemplo simples)\n",
        "    # Para um dashboard interativo real, seria necessário uma biblioteca como Plotly ou Dash\n",
        "    dashboard_html_path = os.path.join(PASTA_TRABALHO, \"dashboard\", \"dashboard_interativo.html\")\n",
        "    with open(dashboard_html_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"<html><body><h1>Dashboard Interativo (Placeholder)</h1><p>Seu dashboard interativo real seria gerado aqui com bibliotecas como Plotly ou Dash.</p></body></html>\")\n",
        "    print(f\"💾 Dashboard Interativo (HTML) salvo em: {dashboard_html_path}\")\n",
        "\n",
        "    # Geração do Blueprint Estratégico (PDF - Exemplo simples)\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "    pdf.chapter_title(\"BLUEPRINT ESTRATÉGICO FINAL\")\n",
        "    pdf.chapter_body(\"Este é o seu blueprint estratégico final, consolidando todos os insights.\")\n",
        "    pdf.chapter_body(f\"Total de vídeos analisados: {len(df_final)}\")\n",
        "    pdf.chapter_body(f\"Média de duração dos vídeos: {df_final[\"duracao_segundos\"] .mean():.2f} segundos\")\n",
        "    pdf_blueprint_path = os.path.join(PASTA_TRABALHO, \"blueprint\", \"BLUEPRINT_ESTRATEGICO_FINAL.pdf\")\n",
        "    pdf.output(pdf_blueprint_path)\n",
        "    print(f\"💾 Blueprint Estratégico (PDF) salvo em: {pdf_blueprint_path}\")\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"blueprint\"] = True\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(\"\\n✅ GERAÇÃO DO BLUEPRINT FINAL E DASHBOARD CONCLUÍDA!\")\n",
        "    print(\"Todos os relatórios e o dashboard foram gerados com sucesso.\")\n",
        "    print(\"\\n🎉 PROCESSO DE ENGENHARIA REVERSA CONCLUÍDO COM SUCESSO! 🎉\")\n",
        "\n",
        "# Executar geração de blueprint e dashboard\n",
        "try:\n",
        "    gerar_blueprint_dashboard()\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ ERRO GERAL NA GERAÇÃO DO BLUEPRINT E DASHBOARD: {e}\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cT5PyNglpi2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CÉLULA 4.3: DASHBOARD MASTER EXECUTIVO INTELIGENTE APRIMORADO\n",
        "# ============================================================================\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "from openpyxl.styles import Font, Alignment, PatternFill\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def log_progress(message):\n",
        "    \"\"\"Log de progresso em tempo real\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
        "    print(f\"[{timestamp}] {message}\")\n",
        "\n",
        "def calculate_viral_score(row):\n",
        "    \"\"\"Calcula score de viralidade baseado em múltiplos fatores\"\"\"\n",
        "    try:\n",
        "        score = 0\n",
        "\n",
        "        # Fator 1: Ritmo (cortes por segundo) - peso 25%\n",
        "        if pd.notna(row['duracao_segundos']) and row['duracao_segundos'] > 0:\n",
        "            cortes_por_seg = row['cortes_detectados_count'] / row['duracao_segundos']\n",
        "            if cortes_por_seg > 20: score += 25\n",
        "            elif cortes_por_seg > 10: score += 20\n",
        "            elif cortes_por_seg > 5: score += 15\n",
        "            else: score += 10\n",
        "\n",
        "        # Fator 2: Complexidade Visual - peso 20%\n",
        "        if pd.notna(row['complexidade_visual_media']):\n",
        "            if row['complexidade_visual_media'] > 600: score += 20\n",
        "            elif row['complexidade_visual_media'] > 400: score += 15\n",
        "            else: score += 10\n",
        "\n",
        "        # Fator 3: Presença de Texto (OCR) - peso 15%\n",
        "        if pd.notna(row['ocr_textos_count']):\n",
        "            if row['ocr_textos_count'] > 10: score += 15\n",
        "            elif row['ocr_textos_count'] > 5: score += 12\n",
        "            elif row['ocr_textos_count'] > 0: score += 8\n",
        "\n",
        "        # Fator 4: Duração Ideal - peso 20%\n",
        "        if pd.notna(row['duracao_segundos']):\n",
        "            if 15 <= row['duracao_segundos'] <= 30: score += 20\n",
        "            elif 10 <= row['duracao_segundos'] <= 45: score += 15\n",
        "            else: score += 10\n",
        "\n",
        "        # Fator 5: Gatilhos Psicológicos - peso 20%\n",
        "        gatilhos = str(row['gatilhos_psicologicos']).lower()\n",
        "        if 'urgência' in gatilhos or 'escassez' in gatilhos: score += 8\n",
        "        if 'estímulo' in gatilhos: score += 7\n",
        "        if 'atenção' in gatilhos: score += 5\n",
        "\n",
        "        return min(score, 100)\n",
        "    except:\n",
        "        return 50\n",
        "\n",
        "def calculate_technical_score(row):\n",
        "    \"\"\"Score técnico baseado em qualidade de produção\"\"\"\n",
        "    try:\n",
        "        score = 0\n",
        "\n",
        "        if pd.notna(row['brilho_medio']):\n",
        "            if 120 <= row['brilho_medio'] <= 180: score += 25\n",
        "            elif 100 <= row['brilho_medio'] <= 200: score += 20\n",
        "            else: score += 10\n",
        "\n",
        "        formato = str(row['formato_detectado'])\n",
        "        if 'vertical_9_16' in formato: score += 25\n",
        "        elif 'horizontal_16_9' in formato: score += 20\n",
        "        else: score += 15\n",
        "\n",
        "        if row['tem_audio']: score += 25\n",
        "        else: score += 5\n",
        "\n",
        "        if pd.notna(row['total_frames']) and row['total_frames'] > 0:\n",
        "            if row['total_frames'] > 300: score += 25\n",
        "            elif row['total_frames'] > 150: score += 20\n",
        "            else: score += 15\n",
        "\n",
        "        return min(score, 100)\n",
        "    except:\n",
        "        return 50\n",
        "\n",
        "def calculate_content_score(row):\n",
        "    \"\"\"Score de conteúdo baseado em riqueza informacional\"\"\"\n",
        "    try:\n",
        "        score = 0\n",
        "\n",
        "        ocr_count = row['ocr_textos_count'] if pd.notna(row['ocr_textos_count']) else 0\n",
        "        audio_len = row['audio_transcrito_len'] if pd.notna(row['audio_transcrito_len']) else 0\n",
        "\n",
        "        if ocr_count > 5 or audio_len > 100: score += 30\n",
        "        elif ocr_count > 2 or audio_len > 50: score += 20\n",
        "        elif ocr_count > 0 or audio_len > 0: score += 15\n",
        "        else: score += 5\n",
        "\n",
        "        if pd.notna(row['bpm_audio']):\n",
        "            if 120 <= row['bpm_audio'] <= 140: score += 35\n",
        "            elif 100 <= row['bpm_audio'] <= 160: score += 25\n",
        "            else: score += 15\n",
        "\n",
        "        if pd.notna(row['duracao_segundos']) and row['duracao_segundos'] > 0:\n",
        "            densidade = (ocr_count + audio_len/10) / row['duracao_segundos']\n",
        "            if densidade > 2: score += 35\n",
        "            elif densidade > 1: score += 25\n",
        "            else: score += 15\n",
        "\n",
        "        return min(score, 100)\n",
        "    except:\n",
        "        return 50\n",
        "\n",
        "def generate_insights_from_data(df):\n",
        "    \"\"\"Gera insights inteligentes baseados nos dados\"\"\"\n",
        "    insights = []\n",
        "\n",
        "    try:\n",
        "        best_performing = df.nlargest(3, 'viral_score')\n",
        "        avg_duration = best_performing['duracao_segundos'].mean()\n",
        "        insights.append(f\"DURAÇÃO VENCEDORA: Seus top 3 vídeos têm duração média de {avg_duration:.1f}s. Este é seu sweet spot comprovado.\")\n",
        "\n",
        "        avg_cuts_per_sec = (best_performing['cortes_detectados_count'] / best_performing['duracao_segundos']).mean()\n",
        "        insights.append(f\"RITMO IDEAL: {avg_cuts_per_sec:.1f} cortes por segundo é sua fórmula de edição mais eficaz.\")\n",
        "\n",
        "        formato_winner = df['formato_detectado'].mode()[0] if not df['formato_detectado'].empty else 'N/A'\n",
        "        formato_count = df['formato_detectado'].value_counts().iloc[0] if not df['formato_detectado'].empty else 0\n",
        "        insights.append(f\"FORMATO DOMINANTE: {formato_count} vídeos em {formato_winner}. Este é seu formato de maior alcance.\")\n",
        "\n",
        "        high_viral = df[df['viral_score'] > 70]\n",
        "        if not high_viral.empty:\n",
        "            avg_complexity = high_viral['complexidade_visual_media'].mean()\n",
        "            insights.append(f\"COMPLEXIDADE VISUAL ÓTIMA: Vídeos com score viral alto têm complexidade média de {avg_complexity:.0f}. Use como referência.\")\n",
        "\n",
        "        text_heavy = df[df['ocr_textos_count'] > 5]\n",
        "        if not text_heavy.empty:\n",
        "            insights.append(f\"ESTRATÉGIA DE TEXTO: {len(text_heavy)} vídeos com muito texto têm score médio de {text_heavy['viral_score'].mean():.0f}. Texto na tela impacta performance.\")\n",
        "\n",
        "        # CORRIGIDO: bpm_audio em vez de bmp_audio\n",
        "        if df['bpm_audio'].notna().any():\n",
        "            successful_bpm = df[df['viral_score'] > 60]['bpm_audio'].mean()\n",
        "            insights.append(f\"BPM DE SUCESSO: {successful_bpm:.0f} BPM é o ritmo de áudio dos seus vídeos mais virais.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        log_progress(f\"Erro ao gerar insights: {e}\")\n",
        "        insights.append(\"Insights parciais disponíveis devido a limitações nos dados.\")\n",
        "\n",
        "    return insights\n",
        "\n",
        "def add_data_to_sheet(ws, data, start_row=1, start_col=1, headers=None):\n",
        "    \"\"\"Adiciona dados a uma planilha de forma segura\"\"\"\n",
        "    current_row = start_row\n",
        "\n",
        "    # Adicionar cabeçalhos se fornecidos\n",
        "    if headers:\n",
        "        for col_idx, header in enumerate(headers):\n",
        "            cell = ws.cell(row=current_row, column=start_col + col_idx)\n",
        "            cell.value = header\n",
        "            cell.font = Font(bold=True)\n",
        "        current_row += 1\n",
        "\n",
        "    # Adicionar dados\n",
        "    for row_data in data:\n",
        "        for col_idx, value in enumerate(row_data):\n",
        "            cell = ws.cell(row=current_row, column=start_col + col_idx)\n",
        "            cell.value = value\n",
        "        current_row += 1\n",
        "\n",
        "    return current_row\n",
        "\n",
        "def create_enhanced_dashboard_master(csv_path, json_path, output_path):\n",
        "    \"\"\"Cria dashboard master executivo aprimorado\"\"\"\n",
        "\n",
        "    log_progress(\"INICIANDO CRIAÇÃO DO DASHBOARD MASTER EXECUTIVO INTELIGENTE\")\n",
        "\n",
        "    try:\n",
        "        # Carregar dados\n",
        "        log_progress(\"Carregando dados consolidados...\")\n",
        "        df_consolidado = pd.read_csv(csv_path, encoding='utf-8')\n",
        "\n",
        "        with open(json_path, 'r', encoding='utf-8') as f:\n",
        "            dados_detalhados = json.load(f)\n",
        "\n",
        "        log_progress(f\"Dados carregados: {len(df_consolidado)} vídeos encontrados\")\n",
        "\n",
        "        # Pré-processamento inteligente\n",
        "        log_progress(\"Processando inteligência artificial dos dados...\")\n",
        "\n",
        "        # Limpar e converter dados\n",
        "        try:\n",
        "            df_consolidado['emocoes_predominantes'] = df_consolidado['emocoes_predominantes'].apply(\n",
        "                lambda x: json.loads(x.replace(\"'\", '\"')) if pd.notna(x) and x != '{}' else {}\n",
        "            )\n",
        "        except:\n",
        "            df_consolidado['emocoes_predominantes'] = [{}] * len(df_consolidado)\n",
        "\n",
        "        # Calcular scores inteligentes\n",
        "        log_progress(\"Calculando scores de performance...\")\n",
        "        df_consolidado['viral_score'] = df_consolidado.apply(calculate_viral_score, axis=1)\n",
        "        df_consolidado['technical_score'] = df_consolidado.apply(calculate_technical_score, axis=1)\n",
        "        df_consolidado['content_score'] = df_consolidado.apply(calculate_content_score, axis=1)\n",
        "        df_consolidado['overall_score'] = (df_consolidado['viral_score'] + df_consolidado['technical_score'] + df_consolidado['content_score']) / 3\n",
        "\n",
        "        # Calcular métricas avançadas\n",
        "        df_consolidado['cortes_por_segundo'] = df_consolidado['cortes_detectados_count'] / df_consolidado['duracao_segundos'].replace(0, 1)\n",
        "        df_consolidado['densidade_texto'] = df_consolidado['ocr_textos_count'] / df_consolidado['duracao_segundos'].replace(0, 1)\n",
        "        df_consolidado['eficiencia_audio'] = df_consolidado['audio_transcrito_len'] / df_consolidado['duracao_segundos'].replace(0, 1)\n",
        "\n",
        "        log_progress(\"Gerando insights estratégicos...\")\n",
        "        insights = generate_insights_from_data(df_consolidado)\n",
        "\n",
        "        # Criar workbook\n",
        "        log_progress(\"Criando estrutura do dashboard...\")\n",
        "        wb = Workbook()\n",
        "\n",
        "        # === ABA 1: EXECUTIVE SUMMARY ===\n",
        "        log_progress(\"Criando Executive Summary...\")\n",
        "        ws_summary = wb.active\n",
        "        ws_summary.title = 'Executive Summary'\n",
        "\n",
        "        # Header principal\n",
        "        header_cell = ws_summary.cell(row=1, column=1)\n",
        "        header_cell.value = 'DASHBOARD MASTER EXECUTIVO - ENGENHARIA REVERSA DE VÍDEOS'\n",
        "        header_cell.font = Font(bold=True, size=18, color='FFFFFF')\n",
        "        header_cell.fill = PatternFill(start_color='1F4E79', end_color='1F4E79', fill_type='solid')\n",
        "        header_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
        "\n",
        "        # Expandir header manualmente\n",
        "        for col in range(2, 9):\n",
        "            cell = ws_summary.cell(row=1, column=col)\n",
        "            cell.fill = PatternFill(start_color='1F4E79', end_color='1F4E79', fill_type='solid')\n",
        "\n",
        "        # KPIs Principais\n",
        "        kpi_cell = ws_summary.cell(row=3, column=1)\n",
        "        kpi_cell.value = 'INDICADORES DE PERFORMANCE PRINCIPAIS'\n",
        "        kpi_cell.font = Font(bold=True, size=14)\n",
        "        kpi_cell.fill = PatternFill(start_color='E7E6E6', end_color='E7E6E6', fill_type='solid')\n",
        "\n",
        "        kpis_data = [\n",
        "            ['Total de Vídeos Analisados', len(df_consolidado)],\n",
        "            ['Score Viral Médio', f\"{df_consolidado['viral_score'].mean():.1f}/100\"],\n",
        "            ['Score Técnico Médio', f\"{df_consolidado['technical_score'].mean():.1f}/100\"],\n",
        "            ['Score de Conteúdo Médio', f\"{df_consolidado['content_score'].mean():.1f}/100\"],\n",
        "            ['Duração Média Otimizada', f\"{df_consolidado['duracao_segundos'].mean():.1f}s\"],\n",
        "            ['Ritmo Médio de Cortes', f\"{df_consolidado['cortes_por_segundo'].mean():.1f}/seg\"],\n",
        "        ]\n",
        "\n",
        "        add_data_to_sheet(ws_summary, kpis_data, start_row=4, start_col=1)\n",
        "\n",
        "        # Top 3 Vídeos\n",
        "        top3_cell = ws_summary.cell(row=3, column=4)\n",
        "        top3_cell.value = 'TOP 3 VÍDEOS POR PERFORMANCE'\n",
        "        top3_cell.font = Font(bold=True, size=14)\n",
        "        top3_cell.fill = PatternFill(start_color='E7E6E6', end_color='E7E6E6', fill_type='solid')\n",
        "\n",
        "        top3 = df_consolidado.nlargest(3, 'overall_score')[['nome_arquivo', 'overall_score', 'viral_score', 'technical_score', 'content_score']]\n",
        "\n",
        "        top3_data = []\n",
        "        for _, video in top3.iterrows():\n",
        "            nome_curto = video['nome_arquivo'][:30] + \"...\" if len(video['nome_arquivo']) > 30 else video['nome_arquivo']\n",
        "            top3_data.append([\n",
        "                nome_curto,\n",
        "                f\"{video['overall_score']:.1f}\",\n",
        "                f\"{video['viral_score']:.1f}\",\n",
        "                f\"{video['technical_score']:.1f}\",\n",
        "                f\"{video['content_score']:.1f}\"\n",
        "            ])\n",
        "\n",
        "        top3_headers = ['Vídeo', 'Score Geral', 'Viral', 'Técnico', 'Conteúdo']\n",
        "        add_data_to_sheet(ws_summary, top3_data, start_row=4, start_col=4, headers=top3_headers)\n",
        "\n",
        "        # Insights Estratégicos\n",
        "        insights_cell = ws_summary.cell(row=12, column=1)\n",
        "        insights_cell.value = 'INSIGHTS ESTRATÉGICOS BASEADOS EM IA'\n",
        "        insights_cell.font = Font(bold=True, size=14, color='FFFFFF')\n",
        "        insights_cell.fill = PatternFill(start_color='C5504B', end_color='C5504B', fill_type='solid')\n",
        "        insights_cell.alignment = Alignment(horizontal='center')\n",
        "\n",
        "        # Adicionar insights\n",
        "        for i, insight in enumerate(insights, 13):\n",
        "            insight_cell = ws_summary.cell(row=i, column=1)\n",
        "            insight_cell.value = f\"• {insight}\"\n",
        "            insight_cell.alignment = Alignment(wrap_text=True)\n",
        "\n",
        "        # === ABA 2: ANÁLISE DE PERFORMANCE ===\n",
        "        log_progress(\"Criando Análise de Performance...\")\n",
        "        ws_performance = wb.create_sheet('Análise de Performance')\n",
        "\n",
        "        perf_header = ws_performance.cell(row=1, column=1)\n",
        "        perf_header.value = 'ANÁLISE DETALHADA DE PERFORMANCE'\n",
        "        perf_header.font = Font(bold=True, size=16)\n",
        "        perf_header.alignment = Alignment(horizontal='center')\n",
        "\n",
        "        # Ranking completo\n",
        "        ranking_data = df_consolidado[['nome_arquivo', 'overall_score', 'viral_score', 'technical_score', 'content_score',\n",
        "                                     'duracao_segundos', 'cortes_por_segundo', 'formato_detectado']].sort_values('overall_score', ascending=False)\n",
        "\n",
        "        ranking_list = []\n",
        "        for _, video in ranking_data.iterrows():\n",
        "            nome_curto = video['nome_arquivo'][:40] + \"...\" if len(video['nome_arquivo']) > 40 else video['nome_arquivo']\n",
        "            ranking_list.append([\n",
        "                nome_curto,\n",
        "                f\"{video['overall_score']:.1f}\",\n",
        "                f\"{video['viral_score']:.1f}\",\n",
        "                f\"{video['technical_score']:.1f}\",\n",
        "                f\"{video['content_score']:.1f}\",\n",
        "                f\"{video['duracao_segundos']:.1f}s\",\n",
        "                f\"{video['cortes_por_segundo']:.1f}\",\n",
        "                video['formato_detectado']\n",
        "            ])\n",
        "\n",
        "        ranking_headers = ['Vídeo', 'Score Geral', 'Viral', 'Técnico', 'Conteúdo', 'Duração', 'Cortes/s', 'Formato']\n",
        "        add_data_to_sheet(ws_performance, ranking_list, start_row=3, start_col=1, headers=ranking_headers)\n",
        "\n",
        "        # === ABA 3: INTELIGÊNCIA TÉCNICA ===\n",
        "        log_progress(\"Criando Inteligência Técnica...\")\n",
        "        ws_tecnica = wb.create_sheet('Inteligência Técnica')\n",
        "\n",
        "        tec_header = ws_tecnica.cell(row=1, column=1)\n",
        "        tec_header.value = 'ANÁLISE TÉCNICA AVANÇADA'\n",
        "        tec_header.font = Font(bold=True, size=16)\n",
        "        tec_header.alignment = Alignment(horizontal='center')\n",
        "\n",
        "        # Análise de correlações\n",
        "        corr_header = ws_tecnica.cell(row=3, column=1)\n",
        "        corr_header.value = 'CORRELAÇÕES DESCOBERTAS'\n",
        "        corr_header.font = Font(bold=True, size=12)\n",
        "\n",
        "        correlations_data = [\n",
        "            ['Duração vs Score Viral', f\"{df_consolidado['duracao_segundos'].corr(df_consolidado['viral_score']):.3f}\", 'CORRELAÇÃO MODERADA'],\n",
        "            ['Cortes/s vs Score Viral', f\"{df_consolidado['cortes_por_segundo'].corr(df_consolidado['viral_score']):.3f}\", 'CORRELAÇÃO MODERADA'],\n",
        "            ['Complexidade Visual vs Performance', f\"{df_consolidado['complexidade_visual_media'].corr(df_consolidado['overall_score']):.3f}\", 'CORRELAÇÃO FRACA'],\n",
        "            ['BPM vs Engajamento', f\"{df_consolidado['bpm_audio'].corr(df_consolidado['viral_score']) if df_consolidado['bpm_audio'].notna().any() else 0:.3f}\", 'CORRELAÇÃO FRACA'],\n",
        "        ]\n",
        "\n",
        "        corr_headers = ['Métrica', 'Correlação', 'Classificação']\n",
        "        add_data_to_sheet(ws_tecnica, correlations_data, start_row=4, start_col=1, headers=corr_headers)\n",
        "\n",
        "        # === ABA 4: BLUEPRINT DE PRODUÇÃO ===\n",
        "        log_progress(\"Criando Blueprint de Produção...\")\n",
        "        ws_blueprint = wb.create_sheet('Blueprint de Produção')\n",
        "\n",
        "        bp_header = ws_blueprint.cell(row=1, column=1)\n",
        "        bp_header.value = 'BLUEPRINT ESTRATÉGICO DE PRODUÇÃO'\n",
        "        bp_header.font = Font(bold=True, size=16, color='FFFFFF')\n",
        "        bp_header.fill = PatternFill(start_color='1F4E79', end_color='1F4E79', fill_type='solid')\n",
        "        bp_header.alignment = Alignment(horizontal='center')\n",
        "\n",
        "        # Receita de sucesso baseada nos top performers\n",
        "        top_performers = df_consolidado[df_consolidado['overall_score'] > df_consolidado['overall_score'].quantile(0.7)]\n",
        "\n",
        "        blueprint_data = [\n",
        "            ['DURAÇÃO IDEAL', f\"{top_performers['duracao_segundos'].mean():.1f} segundos (±{top_performers['duracao_segundos'].std():.1f}s)\"],\n",
        "            ['RITMO DE EDIÇÃO', f\"{top_performers['cortes_por_segundo'].mean():.1f} cortes por segundo\"],\n",
        "            ['FORMATO VENCEDOR', top_performers['formato_detectado'].mode()[0] if not top_performers.empty else 'N/A'],\n",
        "            ['COMPLEXIDADE VISUAL', f\"Nível {top_performers['complexidade_visual_media'].mean():.0f} (escala de estímulo)\"],\n",
        "            ['BPM RECOMENDADO', f\"{top_performers['bpm_audio'].mean():.0f} BPM\" if top_performers['bpm_audio'].notna().any() else 'N/A'],\n",
        "            ['DENSIDADE DE TEXTO', f\"{top_performers['densidade_texto'].mean():.1f} textos por segundo\"],\n",
        "        ]\n",
        "\n",
        "        bp_sub_header = ws_blueprint.cell(row=3, column=1)\n",
        "        bp_sub_header.value = 'FÓRMULA DE SUCESSO BASEADA EM DADOS'\n",
        "        bp_sub_header.font = Font(bold=True, size=12)\n",
        "\n",
        "        add_data_to_sheet(ws_blueprint, blueprint_data, start_row=4, start_col=1)\n",
        "\n",
        "        # === ABA 5: RECOMENDAÇÕES ESTRATÉGICAS ===\n",
        "        log_progress(\"Criando Recomendações Estratégicas...\")\n",
        "        ws_recomendacoes = wb.create_sheet('Recomendações Estratégicas')\n",
        "\n",
        "        rec_header = ws_recomendacoes.cell(row=1, column=1)\n",
        "        rec_header.value = 'RECOMENDAÇÕES ESTRATÉGICAS BASEADAS EM IA'\n",
        "        rec_header.font = Font(bold=True, size=16, color='FFFFFF')\n",
        "        rec_header.fill = PatternFill(start_color='C5504B', end_color='C5504B', fill_type='solid')\n",
        "        rec_header.alignment = Alignment(horizontal='center')\n",
        "\n",
        "        # Recomendações inteligentes baseadas nos dados\n",
        "        recommendations = []\n",
        "\n",
        "        # Análise de duração\n",
        "        if df_consolidado['duracao_segundos'].mean() > 60:\n",
        "            recommendations.append(['DURAÇÃO', 'REDUZA DURAÇÃO', 'Seus vídeos estão longos demais. Vídeos de 15-30s têm melhor performance.', 'ALTA'])\n",
        "        elif df_consolidado['duracao_segundos'].mean() < 15:\n",
        "            recommendations.append(['DURAÇÃO', 'AUMENTE DURAÇÃO', 'Vídeos muito curtos podem não transmitir valor suficiente.', 'MÉDIA'])\n",
        "\n",
        "        # Análise de ritmo\n",
        "        avg_cuts_per_sec = df_consolidado['cortes_por_segundo'].mean()\n",
        "        if avg_cuts_per_sec < 5:\n",
        "            recommendations.append(['EDIÇÃO', 'ACELERE O RITMO', 'Aumente o número de cortes para manter atenção. Meta: 8-12 cortes/segundo.', 'ALTA'])\n",
        "        elif avg_cuts_per_sec > 20:\n",
        "            recommendations.append(['EDIÇÃO', 'DIMINUA CORTES', 'Muitos cortes podem causar fadiga visual. Encontre o equilíbrio.', 'MÉDIA'])\n",
        "\n",
        "        # Análise de formato\n",
        "        formato_dominante = df_consolidado['formato_detectado'].mode()[0] if not df_consolidado['formato_detectado'].empty else 'N/A'\n",
        "        if 'horizontal' in formato_dominante.lower():\n",
        "            recommendations.append(['FORMATO', 'FOQUE EM VERTICAL', 'Formato vertical (9:16) tem melhor performance em redes sociais.', 'ALTA'])\n",
        "\n",
        "        # Análise de texto\n",
        "        if df_consolidado['densidade_texto'].mean() < 1:\n",
        "            recommendations.append(['CONTEÚDO', 'ADICIONE MAIS TEXTO', 'Textos na tela aumentam retenção e acessibilidade.', 'MÉDIA'])\n",
        "\n",
        "        rec_headers = ['Categoria', 'Ação', 'Justificativa', 'Prioridade']\n",
        "        add_data_to_sheet(ws_recomendacoes, recommendations, start_row=3, start_col=1, headers=rec_headers)\n",
        "\n",
        "        # Salvar arquivo\n",
        "        log_progress(\"Salvando dashboard...\")\n",
        "        wb.save(output_path)\n",
        "\n",
        "        log_progress(\"DASHBOARD MASTER EXECUTIVO CRIADO COM SUCESSO!\")\n",
        "        log_progress(f\"Arquivo salvo em: {output_path}\")\n",
        "        log_progress(f\"{len(df_consolidado)} vídeos analisados\")\n",
        "        log_progress(f\"{len(insights)} insights estratégicos gerados\")\n",
        "        log_progress(f\"{len(recommendations)} recomendações criadas\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        log_progress(f\"ERRO CRÍTICO: {e}\")\n",
        "        log_progress(\"Verifique os arquivos de entrada e tente novamente\")\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    \"\"\"Função principal de execução\"\"\"\n",
        "    log_progress(\"INICIANDO SISTEMA DE DASHBOARD INTELIGENTE\")\n",
        "\n",
        "    # Configurar caminhos\n",
        "    BASE_PATH = \"/content/drive/MyDrive/Videos Dona Done/_engenharia_reversa\"\n",
        "    CSV_PATH = os.path.join(BASE_PATH, \"dashboard\", \"dados_consolidados.csv\")\n",
        "    JSON_PATH = os.path.join(BASE_PATH, \"dashboard\", \"dados_detalhados.json\")\n",
        "    OUTPUT_PATH = os.path.join(BASE_PATH, \"dashboard\", \"DASHBOARD_MASTER_EXECUTIVO_INTELIGENTE.xlsx\")\n",
        "\n",
        "    # Verificar se arquivos existem\n",
        "    if not os.path.exists(CSV_PATH):\n",
        "        log_progress(f\"ERRO: Arquivo CSV não encontrado: {CSV_PATH}\")\n",
        "        return False\n",
        "\n",
        "    if not os.path.exists(JSON_PATH):\n",
        "        log_progress(f\"ERRO: Arquivo JSON não encontrado: {JSON_PATH}\")\n",
        "        return False\n",
        "\n",
        "    # Executar criação do dashboard\n",
        "    success = create_enhanced_dashboard_master(CSV_PATH, JSON_PATH, OUTPUT_PATH)\n",
        "\n",
        "    if success:\n",
        "        log_progress(\"PROCESSO CONCLUÍDO COM SUCESSO!\")\n",
        "        log_progress(\"Dashboard inteligente pronto para uso estratégico\")\n",
        "    else:\n",
        "        log_progress(\"PROCESSO FALHOU - Verifique os logs acima\")\n",
        "\n",
        "    return success\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "hFr8drvBrb23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Verificar se o processo de engenharia reversa foi executado\n",
        "BASE_PATH = \"/content/drive/MyDrive/Videos Dona Done/_engenharia_reversa\"\n",
        "CSV_PATH = os.path.join(BASE_PATH, \"dashboard\", \"dados_consolidados.csv\")\n",
        "JSON_PATH = os.path.join(BASE_PATH, \"dashboard\", \"dados_detalhados.json\")\n",
        "\n",
        "print(\"🔍 VERIFICANDO PRÉ-REQUISITOS...\")\n",
        "print(f\"Pasta base existe: {os.path.exists(BASE_PATH)}\")\n",
        "print(f\"CSV existe: {os.path.exists(CSV_PATH)}\")\n",
        "print(f\"JSON existe: {os.path.exists(JSON_PATH)}\")\n",
        "\n",
        "if os.path.exists(CSV_PATH):\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "    print(f\"📊 Dados CSV: {len(df)} vídeos encontrados\")\n",
        "\n",
        "print(\"\\n✅ Se todos os itens acima são True/existem, você pode prosseguir!\")"
      ],
      "metadata": {
        "id": "3QgJMmh1JJ-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SISTEMA DE INTEGRAÇÃO AUTOMÁTICA PARA NOVAS FUNCIONALIDADES\n",
        "# ============================================================================\n",
        "# Este script deve SUBSTITUIR a última célula (4.2) do notebook\n",
        "# Ele detecta automaticamente todas as análises disponíveis e as integra\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import glob\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def descobrir_analises_disponiveis(pasta_trabalho):\n",
        "    \"\"\"Descobre automaticamente todas as análises realizadas\"\"\"\n",
        "    analises_encontradas = {\n",
        "        \"base\": {},\n",
        "        \"adicionais\": {}\n",
        "    }\n",
        "\n",
        "    dados_path = os.path.join(pasta_trabalho, \"dados\")\n",
        "\n",
        "    # Análises básicas obrigatórias\n",
        "    arquivos_base = {\n",
        "        \"metadados\": \"metadados_completos.json\",\n",
        "        \"decomposicao\": \"decomposicao_completa.json\",\n",
        "        \"padroes\": \"analises_padroes_completas.json\",\n",
        "        \"psicologica\": \"analises_psicologicas_completas.json\"\n",
        "    }\n",
        "\n",
        "    for tipo, arquivo in arquivos_base.items():\n",
        "        caminho = os.path.join(dados_path, arquivo)\n",
        "        if os.path.exists(caminho):\n",
        "            analises_encontradas[\"base\"][tipo] = caminho\n",
        "            print(f\"✅ Análise base encontrada: {tipo}\")\n",
        "        else:\n",
        "            print(f\"⚠️ Análise base ausente: {tipo}\")\n",
        "\n",
        "    # Descobrir análises adicionais automaticamente\n",
        "    # Busca por qualquer arquivo JSON que não seja das análises base\n",
        "    todos_jsons = glob.glob(os.path.join(dados_path, \"*.json\"))\n",
        "\n",
        "    for json_path in todos_jsons:\n",
        "        nome_arquivo = os.path.basename(json_path)\n",
        "\n",
        "        # Pular arquivos base\n",
        "        if nome_arquivo in arquivos_base.values():\n",
        "            continue\n",
        "\n",
        "        # Identificar tipo da análise pelo nome\n",
        "        if \"audio\" in nome_arquivo.lower():\n",
        "            analises_encontradas[\"adicionais\"][\"audio_refinada\"] = json_path\n",
        "            print(f\"✅ Análise adicional encontrada: Audio Refinada\")\n",
        "        elif \"visual\" in nome_arquivo.lower():\n",
        "            analises_encontradas[\"adicionais\"][\"visual_avancada\"] = json_path\n",
        "            print(f\"✅ Análise adicional encontrada: Visual Avançada\")\n",
        "        elif \"texto\" in nome_arquivo.lower():\n",
        "            analises_encontradas[\"adicionais\"][\"texto_avancada\"] = json_path\n",
        "            print(f\"✅ Análise adicional encontrada: Texto Avançada\")\n",
        "        elif \"sentiment\" in nome_arquivo.lower():\n",
        "            analises_encontradas[\"adicionais\"][\"sentimento\"] = json_path\n",
        "            print(f\"✅ Análise adicional encontrada: Sentimento\")\n",
        "        else:\n",
        "            # Análise não reconhecida - incluir mesmo assim\n",
        "            nome_limpo = nome_arquivo.replace(\".json\", \"\").replace(\"_\", \" \").title()\n",
        "            analises_encontradas[\"adicionais\"][nome_arquivo] = json_path\n",
        "            print(f\"✅ Análise personalizada encontrada: {nome_limpo}\")\n",
        "\n",
        "    return analises_encontradas\n",
        "\n",
        "def carregar_dados_analise(caminho_arquivo):\n",
        "    \"\"\"Carrega dados de uma análise com tratamento de erros\"\"\"\n",
        "    try:\n",
        "        with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
        "            dados = json.load(f)\n",
        "        return dados, True\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro ao carregar {caminho_arquivo}: {e}\")\n",
        "        return [], False\n",
        "\n",
        "def extrair_metricas_dinamicamente(dados, tipo_analise):\n",
        "    \"\"\"Extrai métricas de qualquer tipo de análise dinamicamente\"\"\"\n",
        "    metricas_extraidas = {}\n",
        "\n",
        "    if not dados:\n",
        "        return metricas_extraidas\n",
        "\n",
        "    # Pegar o primeiro item para entender a estrutura\n",
        "    primeiro_item = dados[0] if isinstance(dados, list) else dados\n",
        "\n",
        "    if isinstance(primeiro_item, dict):\n",
        "        for chave, valor in primeiro_item.items():\n",
        "            if chave in ['video_id', 'status', 'data_analise', 'erro']:\n",
        "                continue\n",
        "\n",
        "            # Extrair métricas numéricas automaticamente\n",
        "            if isinstance(valor, (int, float)):\n",
        "                metricas_extraidas[f\"{tipo_analise}_{chave}\"] = valor\n",
        "            elif isinstance(valor, dict):\n",
        "                # Análise aninhada - extrair sub-métricas\n",
        "                for sub_chave, sub_valor in valor.items():\n",
        "                    if isinstance(sub_valor, (int, float)):\n",
        "                        metricas_extraidas[f\"{tipo_analise}_{chave}_{sub_chave}\"] = sub_valor\n",
        "                    elif isinstance(sub_valor, list) and sub_valor and isinstance(sub_valor[0], (int, float)):\n",
        "                        # Lista de números - calcular estatísticas\n",
        "                        metricas_extraidas[f\"{tipo_analise}_{chave}_{sub_chave}_media\"] = sum(sub_valor) / len(sub_valor)\n",
        "                        metricas_extraidas[f\"{tipo_analise}_{chave}_{sub_chave}_max\"] = max(sub_valor)\n",
        "                        metricas_extraidas[f\"{tipo_analise}_{chave}_{sub_chave}_min\"] = min(sub_valor)\n",
        "            elif isinstance(valor, list):\n",
        "                if valor and isinstance(valor[0], (int, float)):\n",
        "                    # Lista de números\n",
        "                    metricas_extraidas[f\"{tipo_analise}_{chave}_count\"] = len(valor)\n",
        "                    metricas_extraidas[f\"{tipo_analise}_{chave}_media\"] = sum(valor) / len(valor) if valor else 0\n",
        "                else:\n",
        "                    # Lista de objetos ou strings\n",
        "                    metricas_extraidas[f\"{tipo_analise}_{chave}_count\"] = len(valor)\n",
        "\n",
        "    return metricas_extraidas\n",
        "\n",
        "def consolidar_todos_dados(analises_encontradas):\n",
        "    \"\"\"Consolida todos os dados de todas as análises encontradas\"\"\"\n",
        "    dados_consolidados = {}\n",
        "\n",
        "    # Carregar análises base\n",
        "    for tipo, caminho in analises_encontradas[\"base\"].items():\n",
        "        dados, sucesso = carregar_dados_analise(caminho)\n",
        "        if sucesso:\n",
        "            dados_consolidados[tipo] = dados\n",
        "\n",
        "    # Carregar análises adicionais\n",
        "    for tipo, caminho in analises_encontradas[\"adicionais\"].items():\n",
        "        dados, sucesso = carregar_dados_analise(caminho)\n",
        "        if sucesso:\n",
        "            dados_consolidados[tipo] = dados\n",
        "\n",
        "    # Criar DataFrame consolidado por vídeo\n",
        "    videos_df = pd.DataFrame()\n",
        "\n",
        "    # Começar com metadados base se disponível\n",
        "    if \"metadados\" in dados_consolidados:\n",
        "        videos_df = pd.DataFrame(dados_consolidados[\"metadados\"])\n",
        "        videos_df = videos_df.set_index('id')\n",
        "\n",
        "    # Integrar cada análise adicional\n",
        "    for tipo, dados in dados_consolidados.items():\n",
        "        if tipo == \"metadados\":\n",
        "            continue\n",
        "\n",
        "        print(f\"🔄 Integrando dados de: {tipo}\")\n",
        "\n",
        "        # Converter para DataFrame se for lista\n",
        "        if isinstance(dados, list):\n",
        "            df_analise = pd.DataFrame(dados)\n",
        "\n",
        "            if 'video_id' in df_analise.columns:\n",
        "                df_analise = df_analise.set_index('video_id')\n",
        "\n",
        "                # Extrair métricas dinamicamente\n",
        "                for video_id, row in df_analise.iterrows():\n",
        "                    metricas = extrair_metricas_dinamicamente([row.to_dict()], tipo)\n",
        "\n",
        "                    for metrica, valor in metricas.items():\n",
        "                        if video_id in videos_df.index:\n",
        "                            videos_df.loc[video_id, metrica] = valor\n",
        "                        else:\n",
        "                            # Criar nova linha se vídeo não existir\n",
        "                            videos_df.loc[video_id, metrica] = valor\n",
        "\n",
        "    return videos_df.reset_index()\n",
        "\n",
        "def gerar_dashboard_dinamico(df_consolidado, pasta_trabalho):\n",
        "    \"\"\"Gera dashboard dinâmico incluindo todas as análises encontradas\"\"\"\n",
        "    from openpyxl import Workbook\n",
        "    from openpyxl.styles import Font, Alignment, PatternFill\n",
        "\n",
        "    wb = Workbook()\n",
        "\n",
        "    # ABA 1: VISÃO GERAL DINÂMICA\n",
        "    ws_geral = wb.active\n",
        "    ws_geral.title = 'Visão Geral Completa'\n",
        "\n",
        "    # Header\n",
        "    ws_geral.cell(row=1, column=1).value = 'RELATÓRIO COMPLETO DE ENGENHARIA REVERSA'\n",
        "    ws_geral.cell(row=1, column=1).font = Font(bold=True, size=16)\n",
        "\n",
        "    # Estatísticas gerais\n",
        "    ws_geral.cell(row=3, column=1).value = 'ANÁLISES REALIZADAS'\n",
        "    ws_geral.cell(row=3, column=1).font = Font(bold=True, size=14)\n",
        "\n",
        "    # Contar colunas por tipo de análise\n",
        "    colunas_por_tipo = {}\n",
        "    for col in df_consolidado.columns:\n",
        "        if '_' in col:\n",
        "            tipo = col.split('_')[0]\n",
        "            colunas_por_tipo[tipo] = colunas_por_tipo.get(tipo, 0) + 1\n",
        "\n",
        "    row = 4\n",
        "    for tipo, count in colunas_por_tipo.items():\n",
        "        ws_geral.cell(row=row, column=1).value = f\"{tipo.upper()}\"\n",
        "        ws_geral.cell(row=row, column=2).value = f\"{count} métricas extraídas\"\n",
        "        ws_geral.cell(row=row, column=1).font = Font(bold=True)\n",
        "        row += 1\n",
        "\n",
        "    # ABA 2: DADOS COMPLETOS\n",
        "    ws_dados = wb.create_sheet('Dados Completos')\n",
        "\n",
        "    # Adicionar todos os dados\n",
        "    for r_idx, row in enumerate(df_consolidado.itertuples(), 1):\n",
        "        for c_idx, value in enumerate(row):\n",
        "            cell = ws_dados.cell(row=r_idx, column=c_idx)\n",
        "            cell.value = value\n",
        "            if r_idx == 1:  # Header\n",
        "                cell.font = Font(bold=True)\n",
        "\n",
        "    # ABA 3: MÉTRICAS POR TIPO\n",
        "    tipos_encontrados = list(set([col.split('_')[0] for col in df_consolidado.columns if '_' in col]))\n",
        "\n",
        "    for tipo in tipos_encontrados:\n",
        "        ws_tipo = wb.create_sheet(f'Análise {tipo.title()}')\n",
        "\n",
        "        # Filtrar colunas deste tipo\n",
        "        colunas_tipo = ['id', 'nome_arquivo'] + [col for col in df_consolidado.columns if col.startswith(tipo)]\n",
        "\n",
        "        if len(colunas_tipo) > 2:  # Tem dados além do id e nome\n",
        "            df_tipo = df_consolidado[colunas_tipo]\n",
        "\n",
        "            # Adicionar ao worksheet\n",
        "            for r_idx, row in enumerate(df_tipo.itertuples(), 1):\n",
        "                for c_idx, value in enumerate(row):\n",
        "                    cell = ws_tipo.cell(row=r_idx, column=c_idx)\n",
        "                    cell.value = value\n",
        "                    if r_idx == 1:\n",
        "                        cell.font = Font(bold=True)\n",
        "\n",
        "    # ABA 4: INSIGHTS AUTOMATICOS\n",
        "    ws_insights = wb.create_sheet('Insights Automáticos')\n",
        "\n",
        "    insights_automaticos = gerar_insights_automaticos(df_consolidado)\n",
        "\n",
        "    ws_insights.cell(row=1, column=1).value = 'INSIGHTS GERADOS AUTOMATICAMENTE'\n",
        "    ws_insights.cell(row=1, column=1).font = Font(bold=True, size=16)\n",
        "\n",
        "    for i, insight in enumerate(insights_automaticos, 3):\n",
        "        ws_insights.cell(row=i, column=1).value = f\"• {insight}\"\n",
        "        ws_insights.cell(row=i, column=1).alignment = Alignment(wrap_text=True)\n",
        "\n",
        "    # Salvar\n",
        "    output_path = os.path.join(pasta_trabalho, \"dashboard\", \"RELATORIO_COMPLETO_DINAMICO.xlsx\")\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    wb.save(output_path)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "def gerar_insights_automaticos(df):\n",
        "    \"\"\"Gera insights automáticos baseados em qualquer conjunto de dados\"\"\"\n",
        "    insights = []\n",
        "\n",
        "    # Análise de correlações automáticas\n",
        "    colunas_numericas = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "    if len(colunas_numericas) > 1:\n",
        "        correlacoes = df[colunas_numericas].corr()\n",
        "\n",
        "        # Encontrar correlações fortes\n",
        "        for col1 in correlacoes.columns:\n",
        "            for col2 in correlacoes.columns:\n",
        "                if col1 != col2:\n",
        "                    corr_val = correlacoes.loc[col1, col2]\n",
        "                    if abs(corr_val) > 0.7:\n",
        "                        insights.append(f\"CORRELAÇÃO FORTE: {col1} e {col2} têm correlação de {corr_val:.2f}\")\n",
        "\n",
        "    # Identificar outliers automáticos\n",
        "    for col in colunas_numericas:\n",
        "        if df[col].std() > 0:  # Evitar divisão por zero\n",
        "            media = df[col].mean()\n",
        "            std = df[col].std()\n",
        "            outliers = df[(df[col] > media + 2*std) | (df[col] < media - 2*std)]\n",
        "\n",
        "            if len(outliers) > 0:\n",
        "                insights.append(f\"OUTLIERS DETECTADOS: {len(outliers)} vídeos têm valores extremos em {col}\")\n",
        "\n",
        "    # Análise de distribuições\n",
        "    for col in colunas_numericas:\n",
        "        if col.endswith('_score') or 'score' in col:\n",
        "            media = df[col].mean()\n",
        "            if media > 80:\n",
        "                insights.append(f\"PERFORMANCE ALTA: Score médio de {col} é {media:.1f} - excelente resultado\")\n",
        "            elif media < 50:\n",
        "                insights.append(f\"OPORTUNIDADE: Score médio de {col} é {media:.1f} - há espaço para melhorias\")\n",
        "\n",
        "    return insights if insights else [\"Análise de insights em andamento - dados sendo processados\"]\n",
        "\n",
        "def atualizar_config_com_novas_analises(pasta_trabalho, analises_encontradas):\n",
        "    \"\"\"Atualiza config.json com status de todas as análises encontradas\"\"\"\n",
        "    config_path = os.path.join(pasta_trabalho, \"config\", \"config.json\")\n",
        "\n",
        "    # Carregar config existente\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    # Atualizar status das análises encontradas\n",
        "    for tipo in analises_encontradas[\"base\"]:\n",
        "        config[\"status_etapas\"][tipo] = True\n",
        "\n",
        "    for tipo in analises_encontradas[\"adicionais\"]:\n",
        "        config[\"status_etapas\"][f\"analise_{tipo}\"] = True\n",
        "\n",
        "    config[\"ultima_consolidacao\"] = datetime.now().isoformat()\n",
        "    config[\"total_analises_integradas\"] = len(analises_encontradas[\"base\"]) + len(analises_encontradas[\"adicionais\"])\n",
        "\n",
        "    # Salvar config atualizado\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "def main_integracao_automatica():\n",
        "    \"\"\"Função principal da integração automática\"\"\"\n",
        "    print(\"🚀 INICIANDO INTEGRAÇÃO AUTOMÁTICA DE TODAS AS ANÁLISES\")\n",
        "\n",
        "    # Usar variável global da pasta de trabalho\n",
        "    if \"PASTA_TRABALHO\" not in globals():\n",
        "        print(\"❌ ERRO: Execute as células anteriores primeiro\")\n",
        "        return False\n",
        "\n",
        "    pasta_trabalho = PASTA_TRABALHO\n",
        "\n",
        "    try:\n",
        "        # Passo 1: Descobrir análises\n",
        "        print(\"\\n🔍 DESCOBRINDO ANÁLISES DISPONÍVEIS...\")\n",
        "        analises = descobrir_analises_disponiveis(pasta_trabalho)\n",
        "\n",
        "        total_analises = len(analises[\"base\"]) + len(analises[\"adicionais\"])\n",
        "        print(f\"📊 Total de análises encontradas: {total_analises}\")\n",
        "\n",
        "        # Passo 2: Consolidar dados\n",
        "        print(\"\\n🔄 CONSOLIDANDO TODOS OS DADOS...\")\n",
        "        df_consolidado = consolidar_todos_dados(analises)\n",
        "\n",
        "        print(f\"📈 {len(df_consolidado)} vídeos consolidados com {len(df_consolidado.columns)} métricas totais\")\n",
        "\n",
        "        # Passo 3: Gerar dashboard dinâmico\n",
        "        print(\"\\n📊 GERANDO DASHBOARD DINÂMICO...\")\n",
        "        dashboard_path = gerar_dashboard_dinamico(df_consolidado, pasta_trabalho)\n",
        "\n",
        "        # Passo 4: Salvar dados consolidados\n",
        "        csv_path = os.path.join(pasta_trabalho, \"dashboard\", \"dados_completos_consolidados.csv\")\n",
        "        df_consolidado.to_csv(csv_path, index=False, encoding='utf-8')\n",
        "\n",
        "        json_path = os.path.join(pasta_trabalho, \"dashboard\", \"dados_completos_consolidados.json\")\n",
        "        df_consolidado.to_json(json_path, orient='records', indent=2, force_ascii=False)\n",
        "\n",
        "        # Passo 5: Atualizar configuração\n",
        "        print(\"\\n⚙️ ATUALIZANDO CONFIGURAÇÕES...\")\n",
        "        atualizar_config_com_novas_analises(pasta_trabalho, analises)\n",
        "\n",
        "        # Resultados finais\n",
        "        print(\"\\n✅ INTEGRAÇÃO AUTOMÁTICA CONCLUÍDA COM SUCESSO!\")\n",
        "        print(f\"📁 Dashboard dinâmico: {dashboard_path}\")\n",
        "        print(f\"📁 Dados CSV: {csv_path}\")\n",
        "        print(f\"📁 Dados JSON: {json_path}\")\n",
        "        print(f\"📊 {len(df_consolidado)} vídeos processados\")\n",
        "        print(f\"📈 {len(df_consolidado.columns)} métricas totais integradas\")\n",
        "\n",
        "        print(\"\\n🎯 PRÓXIMOS PASSOS:\")\n",
        "        print(\"• Abra o arquivo Excel para ver todas as análises integradas\")\n",
        "        print(\"• Use os dados CSV/JSON em outras ferramentas de análise\")\n",
        "        print(\"• Execute novamente sempre que adicionar novas análises\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ ERRO NA INTEGRAÇÃO AUTOMÁTICA: {e}\")\n",
        "        print(\"Verifique se todas as análises anteriores foram executadas com sucesso\")\n",
        "        return False\n",
        "\n",
        "# Executar integração automática\n",
        "if __name__ == \"__main__\":\n",
        "    main_integracao_automatica()"
      ],
      "metadata": {
        "id": "yyhMy4Pbt7Y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CÉLULA 4.3: INTEGRAÇÃO DE COPYWRITING NO DASHBOARD EXISTENTE\n",
        "# ============================================================================\n",
        "\n",
        "def integrar_copywriting_dashboard_existente():\n",
        "    \"\"\"Integra análise de copywriting no dashboard master existente\"\"\"\n",
        "    print(\"🔄 Iniciando integração de copywriting no dashboard existente...\")\n",
        "\n",
        "    # Verificar pré-requisitos\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa('copywriting_analysis')\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Localizar dashboard existente\n",
        "    pasta_dashboard = os.path.join(PASTA_TRABALHO, \"dashboard\")\n",
        "    dashboard_existente = None\n",
        "\n",
        "    # Procurar arquivo de dashboard existente\n",
        "    if os.path.exists(pasta_dashboard):\n",
        "        arquivos = os.listdir(pasta_dashboard)\n",
        "        for arquivo in arquivos:\n",
        "            if \"DASHBOARD_MASTER_EXECUTIVO_INTELIGENTE\" in arquivo and arquivo.endswith(\".xlsx\"):\n",
        "                dashboard_existente = os.path.join(pasta_dashboard, arquivo)\n",
        "                break\n",
        "\n",
        "    if not dashboard_existente:\n",
        "        print(\"❌ Dashboard master existente não encontrado!\")\n",
        "        print(\"Execute primeiro a célula 4.2 (Blueprint Final) para criar o dashboard base.\")\n",
        "        return\n",
        "\n",
        "    print(f\"  📊 Dashboard encontrado: {os.path.basename(dashboard_existente)}\")\n",
        "\n",
        "    # Carregar dados de copywriting\n",
        "    dados_copywriting = carregar_dados_copywriting()\n",
        "    if not dados_copywriting:\n",
        "        return\n",
        "\n",
        "    # Abrir workbook existente\n",
        "    from openpyxl import load_workbook\n",
        "\n",
        "    try:\n",
        "        wb = load_workbook(dashboard_existente)\n",
        "        print(f\"  ✅ Dashboard carregado com {len(wb.sheetnames)} abas existentes\")\n",
        "\n",
        "        # Adicionar novas abas de copywriting\n",
        "        adicionar_aba_copywriting_estrategico(wb, dados_copywriting)\n",
        "        adicionar_aba_templates_copy(wb, dados_copywriting)\n",
        "        adicionar_aba_timeline_copy(wb, dados_copywriting)\n",
        "        adicionar_aba_recomendacoes_copy(wb, dados_copywriting)\n",
        "\n",
        "        # Atualizar aba principal com métricas de copywriting\n",
        "        atualizar_aba_principal_com_copy(wb, dados_copywriting)\n",
        "\n",
        "        # Salvar dashboard atualizado\n",
        "        wb.save(dashboard_existente)\n",
        "\n",
        "        print(f\"✅ Dashboard atualizado com análise de copywriting!\")\n",
        "        print(f\"📊 Arquivo: {dashboard_existente}\")\n",
        "        print(f\"📋 Novas abas adicionadas:\")\n",
        "        print(\"  • Copywriting Estratégico\")\n",
        "        print(\"  • Templates Replicáveis\")\n",
        "        print(\"  • Timeline Persuasão\")\n",
        "        print(\"  • Recomendações Copy\")\n",
        "        print(\"  • Dashboard Principal (atualizada)\")\n",
        "\n",
        "        # Gerar relatórios complementares\n",
        "        gerar_relatorios_copywriting_individuais(dados_copywriting)\n",
        "\n",
        "        # Atualizar config\n",
        "        config[\"status_etapas\"][\"dashboard_copywriting_integrado\"] = True\n",
        "        config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "        with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        return dashboard_existente\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao atualizar dashboard: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "def carregar_dados_copywriting():\n",
        "    \"\"\"Carrega dados de copywriting e outros dados necessários\"\"\"\n",
        "    print(\"  📊 Carregando dados de copywriting...\")\n",
        "\n",
        "    try:\n",
        "        # Dados de copywriting\n",
        "        copywriting_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_copywriting_completas.json\")\n",
        "        with open(copywriting_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            copywriting_data = json.load(f)\n",
        "\n",
        "        # Dados de legendas\n",
        "        legendas_path = os.path.join(PASTA_TRABALHO, \"dados\", \"legendas_geradas.json\")\n",
        "        with open(legendas_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            legendas_data = json.load(f)\n",
        "\n",
        "        # Tentar carregar outros dados (podem não existir ainda)\n",
        "        outros_dados = {}\n",
        "\n",
        "        try:\n",
        "            padroes_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_padroes_completas.json\")\n",
        "            with open(padroes_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                outros_dados[\"padroes\"] = json.load(f)\n",
        "        except:\n",
        "            outros_dados[\"padroes\"] = []\n",
        "\n",
        "        try:\n",
        "            videos_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_completos.json\")\n",
        "            with open(videos_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                outros_dados[\"videos\"] = json.load(f)\n",
        "        except:\n",
        "            outros_dados[\"videos\"] = []\n",
        "\n",
        "        print(f\"  ✅ Dados carregados: {len(copywriting_data)} análises de copywriting\")\n",
        "\n",
        "        return {\n",
        "            \"copywriting\": copywriting_data,\n",
        "            \"legendas\": legendas_data,\n",
        "            **outros_dados\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Erro ao carregar dados de copywriting: {e}\")\n",
        "        return None\n",
        "\n",
        "def adicionar_aba_copywriting_estrategico(wb, dados):\n",
        "    \"\"\"Adiciona aba principal de análise de copywriting\"\"\"\n",
        "    from openpyxl.styles import Font, PatternFill, Alignment\n",
        "\n",
        "    # Criar nova aba\n",
        "    ws = wb.create_sheet(\"Copywriting Estratégico\")\n",
        "\n",
        "    # Título principal\n",
        "    ws.merge_cells(\"A1:H1\")\n",
        "    titulo = ws[\"A1\"]\n",
        "    titulo.value = \"ANÁLISE ESTRATÉGICA DE COPYWRITING - ENGENHARIA REVERSA\"\n",
        "    titulo.fill = PatternFill(start_color=\"1F4E79\", end_color=\"1F4E79\", fill_type=\"solid\")\n",
        "    titulo.font = Font(color=\"FFFFFF\", bold=True, size=14)\n",
        "    titulo.alignment = Alignment(horizontal=\"center\")\n",
        "\n",
        "    row = 3\n",
        "\n",
        "    # Métricas executivas\n",
        "    ws[f\"A{row}\"] = \"MÉTRICAS EXECUTIVAS DE COPYWRITING\"\n",
        "    ws[f\"A{row}\"].font = Font(bold=True, size=12, color=\"C5504B\")\n",
        "    row += 2\n",
        "\n",
        "    # Calcular métricas\n",
        "    videos_copy = dados[\"copywriting\"]\n",
        "\n",
        "    if videos_copy:\n",
        "        # Score médio\n",
        "        scores = [v.get(\"score_persuasao\", 0) for v in videos_copy]\n",
        "        score_medio = sum(scores) / len(scores) if scores else 0\n",
        "\n",
        "        # Contadores\n",
        "        total_ganchos = sum(len(v.get(\"ganchos_detectados\", {})) for v in videos_copy)\n",
        "        total_gatilhos = sum(len(v.get(\"gatilhos_mentais_detectados\", {})) for v in videos_copy)\n",
        "        total_ctas = sum(len(v.get(\"ctas_detectados\", {})) for v in videos_copy)\n",
        "        videos_sem_cta = len([v for v in videos_copy if not v.get(\"ctas_detectados\")])\n",
        "        total_templates = sum(len(v.get(\"templates_identificados\", [])) for v in videos_copy)\n",
        "\n",
        "        # Exibir métricas\n",
        "        metricas = [\n",
        "            (\"Score Persuasão Médio:\", f\"{score_medio:.1f}/100\", \"Meta: 70+ para alta conversão\"),\n",
        "            (\"Vídeos Analisados:\", len(videos_copy), \"Base completa da análise\"),\n",
        "            (\"Total de Ganchos:\", total_ganchos, f\"Média: {total_ganchos/len(videos_copy):.1f} por vídeo\"),\n",
        "            (\"Total de Gatilhos:\", total_gatilhos, f\"Média: {total_gatilhos/len(videos_copy):.1f} por vídeo\"),\n",
        "            (\"Total de CTAs:\", total_ctas, f\"Média: {total_ctas/len(videos_copy):.1f} por vídeo\"),\n",
        "            (\"🚨 Vídeos sem CTA:\", videos_sem_cta, \"CRÍTICO: Implementar imediatamente\" if videos_sem_cta > 0 else \"✅ Todos têm CTA\"),\n",
        "            (\"Templates Identificados:\", total_templates, \"Estruturas replicáveis encontradas\")\n",
        "        ]\n",
        "\n",
        "        for metrica, valor, descricao in metricas:\n",
        "            ws[f\"A{row}\"] = metrica\n",
        "            ws[f\"B{row}\"] = valor\n",
        "            ws[f\"C{row}\"] = descricao\n",
        "\n",
        "            ws[f\"A{row}\"].font = Font(bold=True)\n",
        "            if \"🚨\" in metrica and videos_sem_cta > 0:\n",
        "                ws[f\"B{row}\"].font = Font(bold=True, color=\"FF0000\")\n",
        "            elif isinstance(valor, (int, float)) and valor > 0:\n",
        "                ws[f\"B{row}\"].font = Font(bold=True, color=\"70AD47\")\n",
        "\n",
        "            row += 1\n",
        "\n",
        "        row += 2\n",
        "\n",
        "        # Ranking de performance\n",
        "        ws[f\"A{row}\"] = \"🏆 RANKING DE PERFORMANCE POR SCORE DE PERSUASÃO\"\n",
        "        ws[f\"A{row}\"].font = Font(bold=True, size=12, color=\"1F4E79\")\n",
        "        row += 2\n",
        "\n",
        "        # Headers\n",
        "        headers = [\"Posição\", \"Vídeo ID\", \"Score\", \"Ganchos\", \"Gatilhos\", \"CTAs\", \"Status\"]\n",
        "        for col, header in enumerate(headers, 1):\n",
        "            cell = ws.cell(row=row, column=col)\n",
        "            cell.value = header\n",
        "            cell.font = Font(bold=True)\n",
        "            cell.fill = PatternFill(start_color=\"D9E2F3\", end_color=\"D9E2F3\", fill_type=\"solid\")\n",
        "        row += 1\n",
        "\n",
        "        # Top performers\n",
        "        top_videos = sorted(videos_copy, key=lambda x: x.get(\"score_persuasao\", 0), reverse=True)\n",
        "\n",
        "        for i, video in enumerate(top_videos, 1):\n",
        "            ws.cell(row=row, column=1, value=f\"{i}º\")\n",
        "            ws.cell(row=row, column=2, value=video[\"video_id\"])\n",
        "            ws.cell(row=row, column=3, value=f\"{video.get('score_persuasao', 0)}/100\")\n",
        "            ws.cell(row=row, column=4, value=len(video.get(\"ganchos_detectados\", {})))\n",
        "            ws.cell(row=row, column=5, value=len(video.get(\"gatilhos_mentais_detectados\", {})))\n",
        "            ws.cell(row=row, column=6, value=len(video.get(\"ctas_detectados\", {})))\n",
        "\n",
        "            # Status baseado no score\n",
        "            score = video.get(\"score_persuasao\", 0)\n",
        "            if score >= 70:\n",
        "                status = \"🟢 ÓTIMO\"\n",
        "                status_color = \"70AD47\"\n",
        "            elif score >= 50:\n",
        "                status = \"🟡 BOM\"\n",
        "                status_color = \"FFC000\"\n",
        "            else:\n",
        "                status = \"🔴 PRECISA OTIMIZAR\"\n",
        "                status_color = \"C5504B\"\n",
        "\n",
        "            cell_status = ws.cell(row=row, column=7, value=status)\n",
        "            cell_status.font = Font(color=status_color, bold=True)\n",
        "\n",
        "            # Destacar top 3\n",
        "            if i <= 3:\n",
        "                for col in range(1, 8):\n",
        "                    ws.cell(row=row, column=col).fill = PatternFill(start_color=\"FFF2CC\", end_color=\"FFF2CC\", fill_type=\"solid\")\n",
        "\n",
        "            row += 1\n",
        "\n",
        "        row += 2\n",
        "\n",
        "        # Análise de gaps críticos\n",
        "        ws[f\"A{row}\"] = \"⚠️ GAPS CRÍTICOS IDENTIFICADOS\"\n",
        "        ws[f\"A{row}\"].font = Font(bold=True, size=12, color=\"C5504B\")\n",
        "        row += 2\n",
        "\n",
        "        gaps = []\n",
        "\n",
        "        # Vídeos sem CTA\n",
        "        if videos_sem_cta > 0:\n",
        "            gap_cta_videos = [v[\"video_id\"] for v in videos_copy if not v.get(\"ctas_detectados\")]\n",
        "            gaps.append(f\"🚨 CRÍTICO: {videos_sem_cta} vídeos sem CTA: {', '.join(gap_cta_videos[:3])}\")\n",
        "\n",
        "        # Vídeos com poucos ganchos\n",
        "        videos_poucos_ganchos = [v for v in videos_copy if len(v.get(\"ganchos_detectados\", {})) < 2]\n",
        "        if len(videos_poucos_ganchos) > len(videos_copy) * 0.5:\n",
        "            gaps.append(f\"📈 OPORTUNIDADE: {len(videos_poucos_ganchos)} vídeos precisam de mais ganchos\")\n",
        "\n",
        "        # Score baixo\n",
        "        videos_score_baixo = [v for v in videos_copy if v.get(\"score_persuasao\", 0) < 50]\n",
        "        if videos_score_baixo:\n",
        "            gaps.append(f\"🎯 OTIMIZAÇÃO: {len(videos_score_baixo)} vídeos com score < 50 precisam de revisão\")\n",
        "\n",
        "        if not gaps:\n",
        "            gaps.append(\"✅ Nenhum gap crítico identificado - parabéns!\")\n",
        "\n",
        "        for gap in gaps:\n",
        "            ws[f\"A{row}\"] = gap\n",
        "            if \"🚨\" in gap:\n",
        "                ws[f\"A{row}\"].font = Font(color=\"FF0000\", bold=True)\n",
        "            elif \"📈\" in gap or \"🎯\" in gap:\n",
        "                ws[f\"A{row}\"].font = Font(color=\"FFC000\", bold=True)\n",
        "            else:\n",
        "                ws[f\"A{row}\"].font = Font(color=\"70AD47\", bold=True)\n",
        "            row += 1\n",
        "\n",
        "    else:\n",
        "        ws[f\"A{row}\"] = \"⚠️ Nenhum dado de copywriting encontrado\"\n",
        "        ws[f\"A{row}\"].font = Font(color=\"C5504B\", bold=True)\n",
        "        row += 1\n",
        "        ws[f\"A{row}\"] = \"Execute primeiro a Célula 2.4 para gerar análises de copywriting\"\n",
        "\n",
        "    # Ajustar larguras das colunas\n",
        "    for col, width in [(\"A\", 25), (\"B\", 15), (\"C\", 40), (\"D\", 10), (\"E\", 10), (\"F\", 10), (\"G\", 20), (\"H\", 15)]:\n",
        "        ws.column_dimensions[col].width = width\n",
        "\n",
        "def adicionar_aba_templates_copy(wb, dados):\n",
        "    \"\"\"Adiciona aba de templates replicáveis\"\"\"\n",
        "    from openpyxl.styles import Font, PatternFill, Alignment\n",
        "\n",
        "    ws = wb.create_sheet(\"Templates Replicáveis\")\n",
        "\n",
        "    # Título\n",
        "    ws.merge_cells(\"A1:F1\")\n",
        "    titulo = ws[\"A1\"]\n",
        "    titulo.value = \"TEMPLATES E ESTRUTURAS REPLICÁVEIS DE COPYWRITING\"\n",
        "    titulo.fill = PatternFill(start_color=\"70AD47\", end_color=\"70AD47\", fill_type=\"solid\")\n",
        "    titulo.font = Font(color=\"FFFFFF\", bold=True, size=14)\n",
        "    titulo.alignment = Alignment(horizontal=\"center\")\n",
        "\n",
        "    row = 3\n",
        "\n",
        "    # Coletar todos os templates\n",
        "    todos_templates = []\n",
        "    for video in dados[\"copywriting\"]:\n",
        "        templates = video.get(\"templates_identificados\", [])\n",
        "        for template in templates:\n",
        "            template[\"video_id\"] = video[\"video_id\"]\n",
        "            todos_templates.append(template)\n",
        "\n",
        "    if todos_templates:\n",
        "        # Agrupar templates por tipo\n",
        "        templates_agrupados = {}\n",
        "        for template in todos_templates:\n",
        "            nome = template[\"nome\"]\n",
        "            if nome not in templates_agrupados:\n",
        "                templates_agrupados[nome] = {\n",
        "                    \"estrutura\": template[\"estrutura\"],\n",
        "                    \"eficacia\": template[\"eficacia\"],\n",
        "                    \"uso_recomendado\": template[\"uso_recomendado\"],\n",
        "                    \"videos_exemplo\": []\n",
        "                }\n",
        "            templates_agrupados[nome][\"videos_exemplo\"].append(template[\"video_id\"])\n",
        "\n",
        "        # Exibir templates\n",
        "        for nome_template, dados_template in templates_agrupados.items():\n",
        "            ws.merge_cells(f\"A{row}:F{row}\")\n",
        "            template_header = ws[f\"A{row}\"]\n",
        "            template_header.value = f\"📋 TEMPLATE: {nome_template.replace('_', ' ')}\"\n",
        "            template_header.fill = PatternFill(start_color=\"E2EFDA\", end_color=\"E2EFDA\", fill_type=\"solid\")\n",
        "            template_header.font = Font(bold=True, size=11)\n",
        "            row += 1\n",
        "\n",
        "            ws[f\"A{row}\"] = \"Estrutura:\"\n",
        "            ws[f\"B{row}\"] = dados_template[\"estrutura\"]\n",
        "            ws[f\"A{row}\"].font = Font(bold=True)\n",
        "            row += 1\n",
        "\n",
        "            ws[f\"A{row}\"] = \"Eficácia:\"\n",
        "            ws[f\"B{row}\"] = dados_template[\"eficacia\"]\n",
        "            ws[f\"A{row}\"].font = Font(bold=True)\n",
        "            if dados_template[\"eficacia\"] == \"MUITO ALTA\":\n",
        "                ws[f\"B{row}\"].font = Font(color=\"70AD47\", bold=True)\n",
        "            elif dados_template[\"eficacia\"] == \"ALTA\":\n",
        "                ws[f\"B{row}\"].font = Font(color=\"C5504B\", bold=True)\n",
        "            row += 1\n",
        "\n",
        "            ws[f\"A{row}\"] = \"Uso Recomendado:\"\n",
        "            ws[f\"B{row}\"] = dados_template[\"uso_recomendado\"]\n",
        "            ws[f\"A{row}\"].font = Font(bold=True)\n",
        "            row += 1\n",
        "\n",
        "            ws[f\"A{row}\"] = \"Vídeos Exemplo:\"\n",
        "            ws[f\"B{row}\"] = \", \".join(dados_template[\"videos_exemplo\"][:3])\n",
        "            ws[f\"A{row}\"].font = Font(bold=True)\n",
        "            row += 1\n",
        "\n",
        "            # Como aplicar\n",
        "            ws[f\"A{row}\"] = \"Como Aplicar:\"\n",
        "            ws[f\"A{row}\"].font = Font(bold=True, color=\"7030A0\")\n",
        "            row += 1\n",
        "\n",
        "            instrucoes = gerar_instrucoes_aplicacao_template(nome_template)\n",
        "            for i, instrucao in enumerate(instrucoes, 1):\n",
        "                ws[f\"B{row}\"] = f\"{i}. {instrucao}\"\n",
        "                row += 1\n",
        "\n",
        "            row += 2\n",
        "\n",
        "    else:\n",
        "        ws[f\"A{row}\"] = \"📋 Ainda não foram identificados templates específicos\"\n",
        "        row += 1\n",
        "        ws[f\"A{row}\"] = \"Execute mais análises para identificar padrões replicáveis\"\n",
        "\n",
        "    # Templates recomendados universais\n",
        "    row += 2\n",
        "    ws.merge_cells(f\"A{row}:F{row}\")\n",
        "    recom_header = ws[f\"A{row}\"]\n",
        "    recom_header.value = \"🎯 TEMPLATES UNIVERSAIS RECOMENDADOS PARA IMPLEMENTAR\"\n",
        "    recom_header.fill = PatternFill(start_color=\"FFC000\", end_color=\"FFC000\", fill_type=\"solid\")\n",
        "    recom_header.font = Font(bold=True, size=12)\n",
        "    row += 1\n",
        "\n",
        "    templates_universais = [\n",
        "        (\"PERGUNTA + VALOR + CTA\", \"Pergunta engajante → Entrega valor → Call-to-action direto\", \"Todos os vídeos educativos\"),\n",
        "        (\"PROBLEMA + AGITAÇÃO + SOLUÇÃO\", \"Identifica dor → Agrava problema → Apresenta solução\", \"Vídeos de vendas e transformação\"),\n",
        "        (\"CURIOSIDADE + HISTÓRIA + ENSINO\", \"Desperta curiosidade → Conta história → Ensina método\", \"Content marketing e autoridade\"),\n",
        "        (\"PROVA SOCIAL + URGÊNCIA + AÇÃO\", \"Mostra resultados → Cria urgência → Direciona ação\", \"Lançamentos e ofertas\")\n",
        "    ]\n",
        "\n",
        "    headers_univ = [\"Template\", \"Estrutura\", \"Aplicação Ideal\"]\n",
        "    for col, header in enumerate(headers_univ, 1):\n",
        "        cell = ws.cell(row=row, column=col)\n",
        "        cell.value = header\n",
        "        cell.font = Font(bold=True)\n",
        "        cell.fill = PatternFill(start_color=\"F2F2F2\", end_color=\"F2F2F2\", fill_type=\"solid\")\n",
        "    row += 1\n",
        "\n",
        "    for nome, estrutura, aplicacao in templates_universais:\n",
        "        ws.cell(row=row, column=1, value=nome)\n",
        "        ws.cell(row=row, column=2, value=estrutura)\n",
        "        ws.cell(row=row, column=3, value=aplicacao)\n",
        "        ws.cell(row=row, column=1).font = Font(bold=True)\n",
        "        row += 1\n",
        "\n",
        "    # Ajustar larguras\n",
        "    for col, width in [(\"A\", 20), (\"B\", 50), (\"C\", 25), (\"D\", 15), (\"E\", 15), (\"F\", 15)]:\n",
        "        ws.column_dimensions[col].width = width\n",
        "\n",
        "def gerar_instrucoes_aplicacao_template(nome_template):\n",
        "    \"\"\"Gera instruções específicas para aplicar um template\"\"\"\n",
        "    instrucoes_map = {\n",
        "        \"PERGUNTA_AUTORIDADE_CTA\": [\n",
        "            \"Inicie com pergunta que conecte com a dor/desejo do público\",\n",
        "            \"Estabeleça credibilidade (experiência, resultados, formação)\",\n",
        "            \"Termine com CTA claro e específico\",\n",
        "            \"Mantenha tom conversacional mas assertivo\"\n",
        "        ],\n",
        "        \"PROBLEMA_SOLUCAO_PROVA\": [\n",
        "            \"Identifique problema específico e real do público\",\n",
        "            \"Apresente solução clara e aplicável\",\n",
        "            \"Mostre provas sociais (depoimentos, números, casos)\",\n",
        "            \"Use linguagem emocional para conectar\"\n",
        "        ],\n",
        "        \"CURIOSIDADE_URGENCIA_ACAO\": [\n",
        "            \"Desperte curiosidade nos primeiros 3 segundos\",\n",
        "            \"Crie senso de urgência (limitado, exclusivo)\",\n",
        "            \"Direcione para ação imediata específica\",\n",
        "            \"Use gatilhos de escassez e FOMO\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return instrucoes_map.get(nome_template, [\n",
        "        \"Analise a estrutura identificada no vídeo de exemplo\",\n",
        "        \"Adapte os elementos para seu nicho específico\",\n",
        "        \"Teste diferentes abordagens mantendo a estrutura\",\n",
        "        \"Monitore resultados e otimize baseado na performance\"\n",
        "    ])\n",
        "\n",
        "def adicionar_aba_timeline_copy(wb, dados):\n",
        "    \"\"\"Adiciona aba com timeline de elementos persuasivos\"\"\"\n",
        "    from openpyxl.styles import Font, PatternFill, Alignment\n",
        "\n",
        "    ws = wb.create_sheet(\"Timeline Persuasão\")\n",
        "\n",
        "    # Título\n",
        "    ws.merge_cells(\"A1:G1\")\n",
        "    titulo = ws[\"A1\"]\n",
        "    titulo.value = \"TIMELINE DE ELEMENTOS PERSUASIVOS - MAPEAMENTO TEMPORAL\"\n",
        "    titulo.fill = PatternFill(start_color=\"7030A0\", end_color=\"7030A0\", fill_type=\"solid\")\n",
        "    titulo.font = Font(color=\"FFFFFF\", bold=True, size=14)\n",
        "    titulo.alignment = Alignment(horizontal=\"center\")\n",
        "\n",
        "    row = 3\n",
        "\n",
        "    # Análise temporal por vídeo (mostrar apenas top 3 por brevidade)\n",
        "    videos_copy = sorted(dados[\"copywriting\"], key=lambda x: x.get(\"score_persuasao\", 0), reverse=True)\n",
        "\n",
        "    for video in videos_copy[:3]:  # Top 3 performers\n",
        "        ws.merge_cells(f\"A{row}:G{row}\")\n",
        "        video_header = ws[f\"A{row}\"]\n",
        "        video_header.value = f\"🎬 TIMELINE: {video['video_id']} (Score: {video.get('score_persuasao', 0)}/100)\"\n",
        "        video_header.fill = PatternFill(start_color=\"E2EFDA\", end_color=\"E2EFDA\", fill_type=\"solid\")\n",
        "        video_header.font = Font(bold=True)\n",
        "        row += 1\n",
        "\n",
        "        # Headers da timeline\n",
        "        headers = [\"Tempo\", \"Tipo\", \"Elemento\", \"Contexto\", \"Posição\", \"Impacto\", \"Análise\"]\n",
        "        for col, header in enumerate(headers, 1):\n",
        "            cell = ws.cell(row=row, column=col)\n",
        "            cell.value = header\n",
        "            cell.font = Font(bold=True)\n",
        "            cell.fill = PatternFill(start_color=\"F2F2F2\", end_color=\"F2F2F2\", fill_type=\"solid\")\n",
        "        row += 1\n",
        "\n",
        "        # Consolidar timeline\n",
        "        timeline_elementos = []\n",
        "\n",
        "        # Adicionar elementos de cada categoria\n",
        "        for categoria, timeline_key in [(\"GANCHO\", \"ganchos_timeline\"), (\"GATILHO\", \"gatilhos_timeline\"), (\"CTA\", \"ctas_timeline\")]:\n",
        "            timeline_data = video.get(\"timestamp\", {}).get(timeline_key, [])\n",
        "            for item in timeline_data:\n",
        "                timeline_elementos.append({\n",
        "                    \"categoria\": categoria,\n",
        "                    \"tempo\": f\"{item['minuto']:02d}:{item['segundo']:02d}\",\n",
        "                    \"tipo\": item[\"tipo\"].replace(\"_\", \" \").title(),\n",
        "                    \"contexto\": item.get(\"contexto\", \"\")[:40] + \"...\" if len(item.get(\"contexto\", \"\")) > 40 else item.get(\"contexto\", \"\"),\n",
        "                    \"minuto\": item[\"minuto\"],\n",
        "                    \"segundo\": item[\"segundo\"]\n",
        "                })\n",
        "\n",
        "        # Ordenar por tempo\n",
        "        timeline_elementos.sort(key=lambda x: (x[\"minuto\"], x[\"segundo\"]))\n",
        "\n",
        "        if timeline_elementos:\n",
        "            for elemento in timeline_elementos:\n",
        "                ws.cell(row=row, column=1, value=elemento[\"tempo\"])\n",
        "                ws.cell(row=row, column=2, value=elemento[\"categoria\"])\n",
        "                ws.cell(row=row, column=3, value=elemento[\"tipo\"])\n",
        "                ws.cell(row=row, column=4, value=elemento[\"contexto\"])\n",
        "\n",
        "                # Calcular posição no vídeo\n",
        "                total_segundos = elemento[\"minuto\"] * 60 + elemento[\"segundo\"]\n",
        "                if total_segundos <= 10:\n",
        "                    posicao = \"ABERTURA\"\n",
        "                    posicao_color = \"70AD47\"\n",
        "                elif total_segundos <= 20:\n",
        "                    posicao = \"MEIO\"\n",
        "                    posicao_color = \"FFC000\"\n",
        "                else:\n",
        "                    posicao = \"FINAL\"\n",
        "                    posicao_color = \"C5504B\"\n",
        "\n",
        "                cell_pos = ws.cell(row=row, column=5, value=posicao)\n",
        "                cell_pos.font = Font(color=posicao_color, bold=True)\n",
        "\n",
        "                # Análise de impacto\n",
        "                impacto = analisar_impacto_elemento(elemento[\"categoria\"], posicao)\n",
        "                ws.cell(row=row, column=6, value=impacto[\"score\"])\n",
        "                ws.cell(row=row, column=7, value=impacto[\"analise\"])\n",
        "\n",
        "                if impacto[\"score\"] == \"ALTO\":\n",
        "                    ws.cell(row=row, column=6).font = Font(color=\"70AD47\", bold=True)\n",
        "                elif impacto[\"score\"] == \"BAIXO\":\n",
        "                    ws.cell(row=row, column=6).font = Font(color=\"C5504B\", bold=True)\n",
        "\n",
        "                row += 1\n",
        "        else:\n",
        "            ws.cell(row=row, column=1, value=\"Nenhum elemento temporal mapeado\")\n",
        "            row += 1\n",
        "\n",
        "        row += 2\n",
        "\n",
        "    # Padrões temporais identificados\n",
        "    row += 1\n",
        "    ws.merge_cells(f\"A{row}:G{row}\")\n",
        "    padroes_header = ws[f\"A{row}\"]\n",
        "    padroes_header.value = \"📊 PADRÕES TEMPORAIS IDENTIFICADOS\"\n",
        "    padroes_header.fill = PatternFill(start_color=\"1F4E79\", end_color=\"1F4E79\", fill_type=\"solid\")\n",
        "    padroes_header.font = Font(color=\"FFFFFF\", bold=True, size=12)\n",
        "    row += 1\n",
        "\n",
        "    padroes_temporais = [\n",
        "        \"✅ GANCHOS mais eficazes nos primeiros 10 segundos\",\n",
        "        \"✅ GATILHOS MENTAIS ideais entre 10-20 segundos\",\n",
        "        \"✅ CTAs mais conversores nos últimos 5 segundos\",\n",
        "        \"⚠️ Evitar CTAs nos primeiros 5 segundos\",\n",
        "        \"📈 Combinar CURIOSIDADE + AUTORIDADE = alta retenção\"\n",
        "    ]\n",
        "\n",
        "    for padrao in padroes_temporais:\n",
        "        ws[f\"A{row}\"] = padrao\n",
        "        if \"✅\" in padrao:\n",
        "            ws[f\"A{row}\"].font = Font(color=\"70AD47\", bold=True)\n",
        "        elif \"⚠️\" in padrao:\n",
        "            ws[f\"A{row}\"].font = Font(color=\"FFC000\", bold=True)\n",
        "        else:\n",
        "            ws[f\"A{row}\"].font = Font(color=\"1F4E79\", bold=True)\n",
        "        row += 1\n",
        "\n",
        "    # Ajustar larguras\n",
        "    for col, width in [(\"A\", 8), (\"B\", 10), (\"C\", 15), (\"D\", 30), (\"E\", 12), (\"F\", 8), (\"G\", 25)]:\n",
        "        ws.column_dimensions[col].width = width\n",
        "\n",
        "def analisar_impacto_elemento(categoria, posicao):\n",
        "    \"\"\"Analisa o impacto de um elemento baseado na posição\"\"\"\n",
        "    impactos = {\n",
        "        (\"GANCHO\", \"ABERTURA\"): {\"score\": \"ALTO\", \"analise\": \"Ideal para capturar atenção\"},\n",
        "        (\"GANCHO\", \"MEIO\"): {\"score\": \"MÉDIO\", \"analise\": \"Melhor no início\"},\n",
        "        (\"GANCHO\", \"FINAL\"): {\"score\": \"BAIXO\", \"analise\": \"Reposicionar para abertura\"},\n",
        "        (\"GATILHO\", \"ABERTURA\"): {\"score\": \"MÉDIO\", \"analise\": \"Bom para credibilidade\"},\n",
        "        (\"GATILHO\", \"MEIO\"): {\"score\": \"ALTO\", \"analise\": \"Posição ideal para persuasão\"},\n",
        "        (\"GATILHO\", \"FINAL\"): {\"score\": \"MÉDIO\", \"analise\": \"Reforça decisão\"},\n",
        "        (\"CTA\", \"ABERTURA\"): {\"score\": \"BAIXO\", \"analise\": \"Muito cedo, construir valor primeiro\"},\n",
        "        (\"CTA\", \"MEIO\"): {\"score\": \"MÉDIO\", \"analise\": \"Considerar mover para final\"},\n",
        "        (\"CTA\", \"FINAL\"): {\"score\": \"ALTO\", \"analise\": \"Posicionamento ideal\"}\n",
        "    }\n",
        "\n",
        "    return impactos.get((categoria, posicao), {\"score\": \"MÉDIO\", \"analise\": \"Analisar contexto específico\"})\n",
        "\n",
        "def adicionar_aba_recomendacoes_copy(wb, dados):\n",
        "    \"\"\"Adiciona aba de recomendações estratégicas consolidadas\"\"\"\n",
        "    from openpyxl.styles import Font, PatternFill, Alignment\n",
        "\n",
        "    ws = wb.create_sheet(\"Recomendações Copy\")\n",
        "\n",
        "    # Título\n",
        "    ws.merge_cells(\"A1:F1\")\n",
        "    titulo = ws[\"A1\"]\n",
        "    titulo.value = \"RECOMENDAÇÕES ESTRATÉGICAS DE COPYWRITING - PLANO DE AÇÃO\"\n",
        "    titulo.fill = PatternFill(start_color=\"C5504B\", end_color=\"C5504B\", fill_type=\"solid\")\n",
        "    titulo.font = Font(color=\"FFFFFF\", bold=True, size=14)\n",
        "    titulo.alignment = Alignment(horizontal=\"center\")\n",
        "\n",
        "    row = 3\n",
        "\n",
        "    # Consolidar recomendações por prioridade\n",
        "    todas_recomendacoes = []\n",
        "    for video in dados[\"copywriting\"]:\n",
        "        recomendacoes_video = video.get(\"recomendacoes_estrategicas\", [])\n",
        "        for rec in recomendacoes_video:\n",
        "            rec[\"video_id\"] = video[\"video_id\"]\n",
        "            todas_recomendacoes.append(rec)\n",
        "\n",
        "    # Agrupar por prioridade\n",
        "    recomendacoes_por_prioridade = {\n",
        "        \"CRÍTICA\": [],\n",
        "        \"ALTA\": [],\n",
        "        \"MÉDIA\": []\n",
        "    }\n",
        "\n",
        "    for rec in todas_recomendacoes:\n",
        "        prioridade = rec.get(\"prioridade\", \"MÉDIA\")\n",
        "        if prioridade in recomendacoes_por_prioridade:\n",
        "            recomendacoes_por_prioridade[prioridade].append(rec)\n",
        "\n",
        "    # Exibir por prioridade\n",
        "    for prioridade in [\"CRÍTICA\", \"ALTA\", \"MÉDIA\"]:\n",
        "        if not recomendacoes_por_prioridade[prioridade]:\n",
        "            continue\n",
        "\n",
        "        ws[f\"A{row}\"] = f\"🚨 PRIORIDADE {prioridade}\"\n",
        "        if prioridade == \"CRÍTICA\":\n",
        "            ws[f\"A{row}\"].font = Font(color=\"FF0000\", bold=True, size=12)\n",
        "        elif prioridade == \"ALTA\":\n",
        "            ws[f\"A{row}\"].font = Font(color=\"C5504B\", bold=True, size=12)\n",
        "        else:\n",
        "            ws[f\"A{row}\"].font = Font(color=\"FFC000\", bold=True, size=12)\n",
        "\n",
        "        row += 2\n",
        "\n",
        "        # Headers\n",
        "        headers = [\"Categoria\", \"Recomendação\", \"Vídeos Afetados\", \"Ação Sugerida\"]\n",
        "        for col, header in enumerate(headers, 1):\n",
        "            cell = ws.cell(row=row, column=col)\n",
        "            cell.value = header\n",
        "            cell.font = Font(bold=True)\n",
        "            cell.fill = PatternFill(start_color=\"F2F2F2\", end_color=\"F2F2F2\", fill_type=\"solid\")\n",
        "        row += 1\n",
        "\n",
        "        # Agrupar recomendações similares da mesma prioridade\n",
        "        grupos = {}\n",
        "        for rec in recomendacoes_por_prioridade[prioridade]:\n",
        "            categoria = rec[\"categoria\"]\n",
        "            if categoria not in grupos:\n",
        "                grupos[categoria] = {\n",
        "                    \"recomendacao\": rec[\"recomendacao\"],\n",
        "                    \"videos\": [],\n",
        "                    \"acao\": gerar_acao_especifica(categoria)\n",
        "                }\n",
        "            grupos[categoria][\"videos\"].append(rec[\"video_id\"])\n",
        "\n",
        "        for categoria, dados_grupo in grupos.items():\n",
        "            ws.cell(row=row, column=1, value=categoria)\n",
        "            ws.cell(row=row, column=2, value=dados_grupo[\"recomendacao\"])\n",
        "            ws.cell(row=row, column=3, value=f\"{len(dados_grupo['videos'])} vídeo(s)\")\n",
        "            ws.cell(row=row, column=4, value=dados_grupo[\"acao\"])\n",
        "            row += 1\n",
        "\n",
        "        row += 2\n",
        "\n",
        "    # Plano de ação 30 dias\n",
        "    row += 2\n",
        "    ws.merge_cells(f\"A{row}:F{row}\")\n",
        "    plano_header = ws[f\"A{row}\"]\n",
        "    plano_header.value = \"📅 PLANO DE AÇÃO ESTRATÉGICO - PRÓXIMOS 30 DIAS\"\n",
        "    plano_header.fill = PatternFill(start_color=\"70AD47\", end_color=\"70AD47\", fill_type=\"solid\")\n",
        "    plano_header.font = Font(color=\"FFFFFF\", bold=True, size=12)\n",
        "    row += 2\n",
        "\n",
        "    plano_30_dias = [\n",
        "        (\"SEMANA 1 - CRÍTICO\", [\n",
        "            \"Implementar CTAs em TODOS os vídeos sem call-to-action\",\n",
        "            \"Corrigir vídeos com score de persuasão abaixo de 30\",\n",
        "            \"Aplicar templates identificados nos vídeos top performers\"\n",
        "        ]),\n",
        "        (\"SEMANA 2 - ALTA PRIORIDADE\", [\n",
        "            \"Adicionar ganchos de abertura nos vídeos com baixa retenção\",\n",
        "            \"Incorporar gatilhos de autoridade e prova social\",\n",
        "            \"Otimizar timeline de elementos persuasivos\"\n",
        "        ]),\n",
        "        (\"SEMANA 3 - OTIMIZAÇÃO\", [\n",
        "            \"Testar variações de CTAs mais eficazes\",\n",
        "            \"Refinar estruturas narrativas baseadas nos templates\",\n",
        "            \"A/B testing de elementos específicos\"\n",
        "        ]),\n",
        "        (\"SEMANA 4 - VALIDAÇÃO\", [\n",
        "            \"Medir performance pós-implementação\",\n",
        "            \"Documentar novos padrões de sucesso identificados\",\n",
        "            \"Atualizar biblioteca de templates comprovados\"\n",
        "        ])\n",
        "    ]\n",
        "\n",
        "    for semana_titulo, acoes in plano_30_dias:\n",
        "        ws[f\"A{row}\"] = semana_titulo\n",
        "        ws[f\"A{row}\"].font = Font(bold=True, color=\"1F4E79\", size=11)\n",
        "        row += 1\n",
        "\n",
        "        for acao in acoes:\n",
        "            ws[f\"B{row}\"] = f\"• {acao}\"\n",
        "            row += 1\n",
        "\n",
        "        row += 1\n",
        "\n",
        "    # KPIs de acompanhamento\n",
        "    row += 2\n",
        "    ws.merge_cells(f\"A{row}:F{row}\")\n",
        "    kpis_header = ws[f\"A{row}\"]\n",
        "    kpis_header.value = \"📊 KPIs DE ACOMPANHAMENTO - MÉTRICAS DE SUCESSO\"\n",
        "    kpis_header.fill = PatternFill(start_color=\"7030A0\", end_color=\"7030A0\", fill_type=\"solid\")\n",
        "    kpis_header.font = Font(color=\"FFFFFF\", bold=True, size=12)\n",
        "    row += 2\n",
        "\n",
        "    kpis = [\n",
        "        (\"Score de Persuasão Médio\", \"Aumento de 20% em 30 dias\", \"Mensal\"),\n",
        "        (\"Taxa de CTAs Implementados\", \"100% dos vídeos com pelo menos 1 CTA\", \"Imediato\"),\n",
        "        (\"Variedade de Ganchos\", \"3+ tipos diferentes por vídeo\", \"Por vídeo\"),\n",
        "        (\"Diversidade de Gatilhos\", \"4+ gatilhos mentais por vídeo\", \"Por vídeo\"),\n",
        "        (\"Templates Ativos\", \"5+ estruturas replicáveis em uso\", \"Mensal\"),\n",
        "        (\"Taxa de Otimização\", \"80% das recomendações críticas aplicadas\", \"Semanal\")\n",
        "    ]\n",
        "\n",
        "    headers_kpi = [\"KPI\", \"Meta\", \"Frequência de Medição\"]\n",
        "    for col, header in enumerate(headers_kpi, 1):\n",
        "        cell = ws.cell(row=row, column=col)\n",
        "        cell.value = header\n",
        "        cell.font = Font(bold=True)\n",
        "        cell.fill = PatternFill(start_color=\"E2EFDA\", end_color=\"E2EFDA\", fill_type=\"solid\")\n",
        "    row += 1\n",
        "\n",
        "    for kpi_nome, meta, frequencia in kpis:\n",
        "        ws.cell(row=row, column=1, value=kpi_nome)\n",
        "        ws.cell(row=row, column=2, value=meta)\n",
        "        ws.cell(row=row, column=3, value=frequencia)\n",
        "        row += 1\n",
        "\n",
        "    # Próximos passos imediatos\n",
        "    row += 3\n",
        "    ws[f\"A{row}\"] = \"🎯 PRÓXIMOS PASSOS IMEDIATOS (HOJE)\"\n",
        "    ws[f\"A{row}\"].font = Font(bold=True, color=\"C5504B\", size=12)\n",
        "    row += 1\n",
        "\n",
        "    proximos_passos = gerar_proximos_passos_imediatos(dados[\"copywriting\"])\n",
        "\n",
        "    for i, passo in enumerate(proximos_passos, 1):\n",
        "        ws[f\"A{row}\"] = f\"{i}. {passo}\"\n",
        "        ws[f\"A{row}\"].font = Font(bold=True)\n",
        "        row += 1\n",
        "\n",
        "    # Ajustar larguras\n",
        "    for col, width in [(\"A\", 20), (\"B\", 40), (\"C\", 15), (\"D\", 30), (\"E\", 15), (\"F\", 15)]:\n",
        "        ws.column_dimensions[col].width = width\n",
        "\n",
        "def gerar_acao_especifica(categoria):\n",
        "    \"\"\"Gera ação específica baseada na categoria da recomendação\"\"\"\n",
        "    acoes = {\n",
        "        \"GANCHOS\": \"Revisar primeiros 5 segundos e adicionar pergunta ou curiosidade\",\n",
        "        \"GATILHOS\": \"Incorporar elementos de autoridade, prova social ou reciprocidade\",\n",
        "        \"CTA\": \"Adicionar call-to-action claro nos últimos 3-5 segundos\",\n",
        "        \"ESTRUTURA\": \"Aplicar template identificado mais próximo do nicho\",\n",
        "        \"PERSUASÃO\": \"Combinar múltiplos elementos persuasivos em sequência lógica\"\n",
        "    }\n",
        "    return acoes.get(categoria, \"Revisar e otimizar elementos específicos mencionados\")\n",
        "\n",
        "def gerar_proximos_passos_imediatos(videos_copy):\n",
        "    \"\"\"Gera lista de ações imediatas baseadas na análise\"\"\"\n",
        "    passos = []\n",
        "\n",
        "    # Verificar vídeos sem CTA\n",
        "    videos_sem_cta = [v for v in videos_copy if not v.get(\"ctas_detectados\")]\n",
        "    if videos_sem_cta:\n",
        "        passos.append(f\"CRÍTICO: Adicionar CTAs em {len(videos_sem_cta)} vídeo(s): {', '.join([v['video_id'] for v in videos_sem_cta[:3]])}\")\n",
        "\n",
        "    # Verificar scores baixos\n",
        "    videos_score_baixo = [v for v in videos_copy if v.get(\"score_persuasao\", 0) < 30]\n",
        "    if videos_score_baixo:\n",
        "        passos.append(f\"Revisar {len(videos_score_baixo)} vídeo(s) com score crítico < 30\")\n",
        "\n",
        "    # Templates a aplicar\n",
        "    templates_identificados = []\n",
        "    for video in videos_copy:\n",
        "        templates_identificados.extend(video.get(\"templates_identificados\", []))\n",
        "\n",
        "    if templates_identificados:\n",
        "        template_mais_comum = max(set(t[\"nome\"] for t in templates_identificados),\n",
        "                                 key=lambda x: sum(1 for t in templates_identificados if t[\"nome\"] == x))\n",
        "        passos.append(f\"Aplicar template '{template_mais_comum.replace('_', ' ')}' em novos vídeos\")\n",
        "\n",
        "    # Ações gerais\n",
        "    passos.extend([\n",
        "        \"Backup dos vídeos atuais antes das modificações\",\n",
        "        \"Priorizar implementações por ordem de impacto (CTAs primeiro)\",\n",
        "        \"Documentar mudanças para acompanhar resultados\"\n",
        "    ])\n",
        "\n",
        "    return passos[:6]  # Limitar a 6 passos\n",
        "\n",
        "def atualizar_aba_principal_com_copy(wb, dados):\n",
        "    \"\"\"Atualiza a aba principal existente com métricas de copywriting\"\"\"\n",
        "    # Tentar encontrar aba principal (pode ter nomes diferentes)\n",
        "    aba_principal = None\n",
        "    possiveis_nomes = [\"Dashboard Principal\", \"Executive Summary\", \"Summary\", \"Principal\"]\n",
        "\n",
        "    for nome in wb.sheetnames:\n",
        "        if any(possivel in nome for possivel in possiveis_nomes):\n",
        "            aba_principal = wb[nome]\n",
        "            break\n",
        "\n",
        "    if not aba_principal:\n",
        "        # Se não encontrou, usar a primeira aba\n",
        "        aba_principal = wb.worksheets[0]\n",
        "\n",
        "    # Encontrar próxima linha vazia para adicionar seção de copywriting\n",
        "    next_row = 1\n",
        "    for row in range(1, 100):\n",
        "        if aba_principal[f\"A{row}\"].value is None:\n",
        "            next_row = row\n",
        "            break\n",
        "\n",
        "    # Adicionar seção de copywriting\n",
        "    from openpyxl.styles import Font, PatternFill\n",
        "\n",
        "    # Título da seção\n",
        "    aba_principal.merge_cells(f\"A{next_row}:H{next_row}\")\n",
        "    titulo_copy = aba_principal[f\"A{next_row}\"]\n",
        "    titulo_copy.value = \"📝 ANÁLISE DE COPYWRITING - RESUMO EXECUTIVO\"\n",
        "    titulo_copy.fill = PatternFill(start_color=\"7030A0\", end_color=\"7030A0\", fill_type=\"solid\")\n",
        "    titulo_copy.font = Font(color=\"FFFFFF\", bold=True, size=12)\n",
        "    next_row += 2\n",
        "\n",
        "    # Métricas resumidas\n",
        "    videos_copy = dados[\"copywriting\"]\n",
        "\n",
        "    if videos_copy:\n",
        "        scores = [v.get(\"score_persuasao\", 0) for v in videos_copy]\n",
        "        score_medio = sum(scores) / len(scores)\n",
        "        videos_sem_cta = len([v for v in videos_copy if not v.get(\"ctas_detectados\")])\n",
        "        templates_total = sum(len(v.get(\"templates_identificados\", [])) for v in videos_copy)\n",
        "\n",
        "        metricas_resumo = [\n",
        "            (\"Score de Persuasão Médio:\", f\"{score_medio:.1f}/100\"),\n",
        "            (\"Vídeos sem CTA:\", f\"{videos_sem_cta} (CRÍTICO)\" if videos_sem_cta > 0 else \"0 ✅\"),\n",
        "            (\"Templates Identificados:\", str(templates_total)),\n",
        "            (\"Status Geral:\", \"Otimização necessária\" if score_medio < 60 or videos_sem_cta > 0 else \"Performance boa\")\n",
        "        ]\n",
        "\n",
        "        for metrica, valor in metricas_resumo:\n",
        "            aba_principal[f\"A{next_row}\"] = metrica\n",
        "            aba_principal[f\"B{next_row}\"] = valor\n",
        "            aba_principal[f\"A{next_row}\"].font = Font(bold=True)\n",
        "\n",
        "            if \"CRÍTICO\" in valor:\n",
        "                aba_principal[f\"B{next_row}\"].font = Font(color=\"FF0000\", bold=True)\n",
        "            elif \"✅\" in valor:\n",
        "                aba_principal[f\"B{next_row}\"].font = Font(color=\"70AD47\", bold=True)\n",
        "\n",
        "            next_row += 1\n",
        "\n",
        "    else:\n",
        "        aba_principal[f\"A{next_row}\"] = \"⚠️ Execute a análise de copywriting (Célula 2.4) para ver métricas\"\n",
        "        aba_principal[f\"A{next_row}\"].font = Font(color=\"FFC000\", bold=True)\n",
        "\n",
        "def gerar_relatorios_copywriting_individuais(dados):\n",
        "    \"\"\"Gera relatórios individuais de texto para cada vídeo\"\"\"\n",
        "    print(\"  📄 Gerando relatórios individuais de copywriting...\")\n",
        "\n",
        "    pasta_relatorios = os.path.join(PASTA_TRABALHO, \"relatorios_copywriting\")\n",
        "    os.makedirs(pasta_relatorios, exist_ok=True)\n",
        "\n",
        "    for video_copy in dados[\"copywriting\"]:\n",
        "        video_id = video_copy[\"video_id\"]\n",
        "\n",
        "        relatorio_path = os.path.join(pasta_relatorios, f\"{video_id}_copywriting_completo.txt\")\n",
        "\n",
        "        with open(relatorio_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"=\"*60 + \"\\n\")\n",
        "            f.write(\"RELATÓRIO COMPLETO DE ANÁLISE DE COPYWRITING\\n\")\n",
        "            f.write(\"=\"*60 + \"\\n\\n\")\n",
        "\n",
        "            f.write(f\"📹 Vídeo ID: {video_id}\\n\")\n",
        "            f.write(f\"🎯 Score de Persuasão: {video_copy.get('score_persuasao', 0)}/100\\n\")\n",
        "            f.write(f\"📝 Total de Palavras: {video_copy.get('total_palavras', 0)}\\n\\n\")\n",
        "\n",
        "            # Texto completo\n",
        "            f.write(\"TRANSCRIÇÃO COMPLETA:\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            f.write(video_copy.get(\"texto_completo\", \"Transcrição não disponível\") + \"\\n\\n\")\n",
        "\n",
        "            # Ganchos\n",
        "            f.write(\"🎣 GANCHOS DETECTADOS:\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            ganchos = video_copy.get(\"ganchos_detectados\", {})\n",
        "            if ganchos:\n",
        "                for tipo, dados in ganchos.items():\n",
        "                    f.write(f\"• {tipo.replace('_', ' ').title()}: {dados['count']} ocorrência(s)\\n\")\n",
        "                    for exemplo in dados.get(\"exemplos\", [])[:2]:\n",
        "                        f.write(f\"  - \\\"{exemplo}\\\"\\n\")\n",
        "                    f.write(\"\\n\")\n",
        "            else:\n",
        "                f.write(\"❌ Nenhum gancho detectado - OPORTUNIDADE DE MELHORIA\\n\\n\")\n",
        "\n",
        "            # Gatilhos\n",
        "            f.write(\"🧠 GATILHOS MENTAIS DETECTADOS:\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            gatilhos = video_copy.get(\"gatilhos_mentais_detectados\", {})\n",
        "            if gatilhos:\n",
        "                for tipo, dados in gatilhos.items():\n",
        "                    f.write(f\"• {tipo.replace('_', ' ').title()}: {dados['count']} ocorrência(s)\\n\")\n",
        "                    for exemplo in dados.get(\"exemplos\", [])[:2]:\n",
        "                        f.write(f\"  - \\\"{exemplo}\\\"\\n\")\n",
        "                    f.write(\"\\n\")\n",
        "            else:\n",
        "                f.write(\"❌ Nenhum gatilho mental detectado - ADICIONAR URGENTEMENTE\\n\\n\")\n",
        "\n",
        "            # CTAs\n",
        "            f.write(\"📢 CALLS-TO-ACTION DETECTADOS:\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            ctas = video_copy.get(\"ctas_detectados\", {})\n",
        "            if ctas:\n",
        "                for tipo, dados in ctas.items():\n",
        "                    f.write(f\"• {tipo.replace('_', ' ').title()}: {dados['count']} ocorrência(s)\\n\")\n",
        "                    for exemplo in dados.get(\"exemplos\", [])[:2]:\n",
        "                        f.write(f\"  - \\\"{exemplo}\\\"\\n\")\n",
        "                    f.write(\"\\n\")\n",
        "            else:\n",
        "                f.write(\"🚨 CRÍTICO: Nenhum CTA detectado - IMPLEMENTAR IMEDIATAMENTE\\n\\n\")\n",
        "\n",
        "            # Templates\n",
        "            f.write(\"📋 TEMPLATES IDENTIFICADOS:\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            templates = video_copy.get(\"templates_identificados\", [])\n",
        "            if templates:\n",
        "                for template in templates:\n",
        "                    f.write(f\"• {template['nome'].replace('_', ' ')}\\n\")\n",
        "                    f.write(f\"  Estrutura: {template['estrutura']}\\n\")\n",
        "                    f.write(f\"  Eficácia: {template['eficacia']}\\n\")\n",
        "                    f.write(f\"  Uso: {template['uso_recomendado']}\\n\\n\")\n",
        "            else:\n",
        "                f.write(\"📝 Nenhum template específico identificado\\n\\n\")\n",
        "\n",
        "            # Recomendações\n",
        "            f.write(\"🎯 RECOMENDAÇÕES ESTRATÉGICAS:\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            recomendacoes = video_copy.get(\"recomendacoes_estrategicas\", [])\n",
        "            if recomendacoes:\n",
        "                for i, rec in enumerate(recomendacoes, 1):\n",
        "                    f.write(f\"{i}. [{rec['prioridade']}] {rec['categoria']}\\n\")\n",
        "                    f.write(f\"   {rec['recomendacao']}\\n\\n\")\n",
        "            else:\n",
        "                f.write(\"✅ Nenhuma recomendação crítica - vídeo bem otimizado\\n\\n\")\n",
        "\n",
        "            # Timeline resumida\n",
        "            f.write(\"⏰ TIMELINE DE ELEMENTOS (RESUMIDA):\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            timeline_ganchos = video_copy.get(\"timestamp\", {}).get(\"ganchos_timeline\", [])\n",
        "            timeline_ctas = video_copy.get(\"timestamp\", {}).get(\"ctas_timeline\", [])\n",
        "\n",
        "            todos_elementos = []\n",
        "            for item in timeline_ganchos:\n",
        "                todos_elementos.append((item[\"minuto\"], item[\"segundo\"], \"GANCHO\", item[\"tipo\"]))\n",
        "            for item in timeline_ctas:\n",
        "                todos_elementos.append((item[\"minuto\"], item[\"segundo\"], \"CTA\", item[\"tipo\"]))\n",
        "\n",
        "            todos_elementos.sort()\n",
        "\n",
        "            if todos_elementos:\n",
        "                for minuto, segundo, categoria, tipo in todos_elementos:\n",
        "                    f.write(f\"[{minuto:02d}:{segundo:02d}] {categoria}: {tipo.replace('_', ' ').title()}\\n\")\n",
        "            else:\n",
        "                f.write(\"Nenhum elemento temporal mapeado\\n\")\n",
        "\n",
        "            f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "            f.write(\"Relatório gerado pelo sistema de engenharia reversa\\n\")\n",
        "            f.write(\"Para implementar as recomendações, consulte o dashboard principal\\n\")\n",
        "            f.write(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    print(f\"  ✅ {len(dados['copywriting'])} relatórios individuais gerados\")\n",
        "\n",
        "# Função principal de execução\n",
        "def executar_integracao_copywriting_dashboard():\n",
        "    \"\"\"Função principal para executar a integração\"\"\"\n",
        "    print(\"🚀 EXECUTANDO INTEGRAÇÃO DE COPYWRITING NO DASHBOARD EXISTENTE\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    try:\n",
        "        dashboard_atualizado = integrar_copywriting_dashboard_existente()\n",
        "\n",
        "        if dashboard_atualizado:\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(\"✅ INTEGRAÇÃO CONCLUÍDA COM SUCESSO!\")\n",
        "            print(\"=\"*70)\n",
        "            print(f\"📊 Dashboard atualizado: {os.path.basename(dashboard_atualizado)}\")\n",
        "            print(\"\\n📋 ABAS ADICIONADAS:\")\n",
        "            print(\"  • Copywriting Estratégico - Análise completa por vídeo\")\n",
        "            print(\"  • Templates Replicáveis - Estruturas identificadas\")\n",
        "            print(\"  • Timeline Persuasão - Mapeamento temporal\")\n",
        "            print(\"  • Recomendações Copy - Plano de ação 30 dias\")\n",
        "            print(\"  • Dashboard Principal - Atualizada com métricas\")\n",
        "\n",
        "            print(f\"\\n🎯 PRÓXIMOS PASSOS:\")\n",
        "            print(\"1. Abra o dashboard e revise a aba 'Copywriting Estratégico'\")\n",
        "            print(\"2. Identifique vídeos com score < 50 para otimização\")\n",
        "            print(\"3. Implemente CTAs nos vídeos marcados como CRÍTICO\")\n",
        "            print(\"4. Aplique templates identificados em novos vídeos\")\n",
        "            print(\"5. Siga o plano de ação de 30 dias na aba 'Recomendações Copy'\")\n",
        "\n",
        "        else:\n",
        "            print(\"\\n❌ Falha na integração - verifique os pré-requisitos\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Erro de Execução: {type(e).__name__}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Executar a integração\n",
        "if __name__ == \"__main__\":\n",
        "    executar_integracao_copywriting_dashboard()"
      ],
      "metadata": {
        "id": "GlbVqMZ-yhI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LAYER 2.4: GERAÇÃO DE LEGENDAS E ANÁLISE DE COPYWRITING - VERSÃO FINAL\n",
        "# ============================================================================\n",
        "\n",
        "import re\n",
        "from datetime import timedelta, datetime\n",
        "from collections import Counter\n",
        "import json\n",
        "import os\n",
        "\n",
        "def processar_copywriting_todos_videos_adaptado():\n",
        "    \"\"\"Processa análise de copywriting adaptada para o sistema existente\"\"\"\n",
        "    print(\"🔄 Iniciando processamento de copywriting adaptado...\")\n",
        "\n",
        "    # Verificar pré-requisitos baseado na estrutura existente\n",
        "    if not \"PASTA_TRABALHO\" in globals():\n",
        "        print(\"❌ Variáveis globais não encontradas. Execute a CÉLULA 1.2 primeiro.\")\n",
        "        return\n",
        "\n",
        "    pasta_dados = os.path.join(PASTA_TRABALHO, \"dados\")\n",
        "    if not os.path.exists(pasta_dados):\n",
        "        print(\"❌ Pasta de dados não encontrada. Execute as células anteriores primeiro.\")\n",
        "        return\n",
        "\n",
        "    # Buscar dados de decomposição (nome correto do arquivo)\n",
        "    decomposicao_path = os.path.join(pasta_dados, \"decomposicao_completa.json\")\n",
        "\n",
        "    if not os.path.exists(decomposicao_path):\n",
        "        print(\"❌ Dados de decomposição não encontrados. Execute a CÉLULA 2.3 primeiro.\")\n",
        "        print(f\"Procurando arquivo: {decomposicao_path}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        with open(decomposicao_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            decomposicoes_data = json.load(f)\n",
        "\n",
        "        print(f\"✅ Dados de decomposição carregados: {len(decomposicoes_data)} vídeos encontrados\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao carregar dados de decomposição: {e}\")\n",
        "        return\n",
        "\n",
        "    # Filtrar apenas vídeos com status \"decomposto\" e que tenham transcrição\n",
        "    videos_validos = []\n",
        "    for decomposicao in decomposicoes_data:\n",
        "        if (decomposicao.get(\"status\") == \"decomposto\" and\n",
        "            decomposicao.get(\"audio_transcrito\") and\n",
        "            len(decomposicao.get(\"audio_transcrito\", \"\").strip()) > 10):\n",
        "            videos_validos.append(decomposicao)\n",
        "\n",
        "    if not videos_validos:\n",
        "        print(\"❌ Nenhum vídeo com transcrição válida encontrado.\")\n",
        "        print(\"Verifique se a CÉLULA 2.3 foi executada com sucesso e se os vídeos possuem áudio.\")\n",
        "        return\n",
        "\n",
        "    print(f\"📊 Processando {len(videos_validos)} vídeos com transcrição válida...\")\n",
        "\n",
        "    analises_copywriting = []\n",
        "    legendas_geradas = []\n",
        "\n",
        "    for i, decomposicao in enumerate(videos_validos, 1):\n",
        "        video_id = decomposicao[\"video_id\"]\n",
        "        audio_transcrito = decomposicao[\"audio_transcrito\"]\n",
        "\n",
        "        print(f\"[{i}/{len(videos_validos)}] Processando copywriting para: {video_id}\")\n",
        "\n",
        "        try:\n",
        "            # Estimar duração do vídeo baseado na análise de áudio\n",
        "            duracao_segundos = decomposicao.get(\"audio_analise\", {}).get(\"duracao_audio_segundos\", 30)\n",
        "\n",
        "            # Criar info do vídeo para compatibilidade\n",
        "            video_info = {\n",
        "                \"id\": video_id,\n",
        "                \"duracao_segundos\": duracao_segundos\n",
        "            }\n",
        "\n",
        "            # Gerar legendas\n",
        "            legendas_data, srt_path, txt_path = gerar_legendas_com_timestamps(video_info, decomposicao)\n",
        "\n",
        "            if legendas_data:\n",
        "                legendas_info = {\n",
        "                    \"video_id\": video_id,\n",
        "                    \"srt_path\": srt_path,\n",
        "                    \"txt_path\": txt_path,\n",
        "                    \"total_segmentos\": len(legendas_data),\n",
        "                    \"duracao_total\": duracao_segundos,\n",
        "                    \"legendas_data\": legendas_data\n",
        "                }\n",
        "                legendas_geradas.append(legendas_info)\n",
        "\n",
        "                # Análise de copywriting\n",
        "                analise_copy = analisar_copywriting_estrategico(legendas_data, video_id)\n",
        "                analises_copywriting.append(analise_copy)\n",
        "\n",
        "                print(f\"  ✅ Copywriting analisado: Score {analise_copy['score_persuasao']}/100\")\n",
        "            else:\n",
        "                print(f\"  ❌ Falha na geração de legendas para {video_id}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ❌ Erro no processamento de copywriting para {video_id}: {e}\")\n",
        "\n",
        "    if not analises_copywriting:\n",
        "        print(\"❌ Nenhuma análise de copywriting foi gerada. Verifique os dados de entrada.\")\n",
        "        return\n",
        "\n",
        "    # Salvar dados de copywriting\n",
        "    copywriting_path = os.path.join(pasta_dados, \"analises_copywriting_completas.json\")\n",
        "    with open(copywriting_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(analises_copywriting, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"💾 Análises de copywriting salvas em: {copywriting_path}\")\n",
        "\n",
        "    # Salvar dados de legendas\n",
        "    legendas_path = os.path.join(pasta_dados, \"legendas_geradas.json\")\n",
        "    with open(legendas_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(legendas_geradas, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"💾 Dados de legendas salvos em: {legendas_path}\")\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    if os.path.exists(config_path):\n",
        "        try:\n",
        "            with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                config = json.load(f)\n",
        "\n",
        "            config[\"status_etapas\"][\"copywriting_analysis\"] = True\n",
        "\n",
        "            with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "        except:\n",
        "            print(\"⚠️ Não foi possível atualizar o arquivo de configuração\")\n",
        "\n",
        "    print(f\"\\n✅ ANÁLISE DE COPYWRITING CONCLUÍDA!\")\n",
        "    print(f\"Total de vídeos com copywriting analisado: {len(analises_copywriting)}\")\n",
        "    print(f\"Total de legendas geradas: {len(legendas_geradas)}\")\n",
        "    print(f\"\\n➡️ PRÓXIMA CÉLULA: 4.3 - INTEGRAÇÃO COM DASHBOARD\")\n",
        "\n",
        "def gerar_legendas_com_timestamps(video_info, decomposicao_data):\n",
        "    \"\"\"Gera legendas SRT e TXT com timestamps precisos a partir da transcrição\"\"\"\n",
        "    print(\"  🔄 Gerando legendas com timestamps...\")\n",
        "\n",
        "    video_id = video_info[\"id\"]\n",
        "    audio_transcrito = decomposicao_data.get(\"audio_transcrito\", \"\")\n",
        "\n",
        "    if not audio_transcrito.strip():\n",
        "        print(\"    ❌ Erro: Transcrição de áudio vazia\")\n",
        "        return None, None, None\n",
        "\n",
        "    # Calcular duração do vídeo\n",
        "    duracao_segundos = video_info.get(\"duracao_segundos\", 30)  # Default 30s se não informado\n",
        "\n",
        "    # Dividir texto em segmentos baseados em pontuação e pausas naturais\n",
        "    segmentos = dividir_texto_em_segmentos(audio_transcrito)\n",
        "\n",
        "    if not segmentos:\n",
        "        print(\"    ❌ Erro: Não foi possível segmentar o texto\")\n",
        "        return None, None, None\n",
        "\n",
        "    # Calcular timestamps para cada segmento\n",
        "    legendas_data = []\n",
        "    duracao_por_segmento = duracao_segundos / len(segmentos) if segmentos else 1\n",
        "\n",
        "    for i, segmento in enumerate(segmentos):\n",
        "        inicio_segundos = i * duracao_por_segmento\n",
        "        fim_segundos = (i + 1) * duracao_por_segmento\n",
        "\n",
        "        legenda_item = {\n",
        "            \"id\": i + 1,\n",
        "            \"inicio\": segundos_para_timestamp(inicio_segundos),\n",
        "            \"fim\": segundos_para_timestamp(fim_segundos),\n",
        "            \"texto\": segmento.strip(),\n",
        "            \"inicio_segundos\": inicio_segundos,\n",
        "            \"fim_segundos\": fim_segundos\n",
        "        }\n",
        "        legendas_data.append(legenda_item)\n",
        "\n",
        "    # Gerar arquivos SRT e TXT\n",
        "    pasta_legendas = os.path.join(PASTA_TRABALHO, \"legendas\")\n",
        "    os.makedirs(pasta_legendas, exist_ok=True)\n",
        "\n",
        "    # Arquivo SRT\n",
        "    srt_path = os.path.join(pasta_legendas, f\"{video_id}_legendas.srt\")\n",
        "    gerar_arquivo_srt(legendas_data, srt_path)\n",
        "\n",
        "    # Arquivo TXT com timestamps\n",
        "    txt_path = os.path.join(pasta_legendas, f\"{video_id}_legendas_timestamped.txt\")\n",
        "    gerar_arquivo_txt_timestamped(legendas_data, txt_path)\n",
        "\n",
        "    print(f\"    ✅ Legendas SRT geradas: {srt_path}\")\n",
        "    print(f\"    ✅ Legendas TXT com timestamps geradas: {txt_path}\")\n",
        "\n",
        "    return legendas_data, srt_path, txt_path\n",
        "\n",
        "def dividir_texto_em_segmentos(texto, max_chars=50):\n",
        "    \"\"\"Divide o texto em segmentos lógicos para legendas\"\"\"\n",
        "    # Dividir por frases primeiro\n",
        "    frases = re.split(r'[.!?]+', texto)\n",
        "    segmentos = []\n",
        "\n",
        "    for frase in frases:\n",
        "        if not frase.strip():\n",
        "            continue\n",
        "\n",
        "        # Se a frase é muito longa, dividir por vírgulas ou conjunções\n",
        "        if len(frase) > max_chars:\n",
        "            sub_segmentos = re.split(r'[,;]|(?:\\s+(?:e|mas|então|porque|que)\\s+)', frase)\n",
        "            for sub in sub_segmentos:\n",
        "                if sub.strip() and len(sub.strip()) > 3:\n",
        "                    segmentos.append(sub.strip())\n",
        "        else:\n",
        "            if frase.strip() and len(frase.strip()) > 3:\n",
        "                segmentos.append(frase.strip())\n",
        "\n",
        "    # Se ainda houver segmentos muito longos, dividir por palavras\n",
        "    segmentos_finais = []\n",
        "    for seg in segmentos:\n",
        "        if len(seg) > max_chars:\n",
        "            palavras = seg.split()\n",
        "            temp_seg = \"\"\n",
        "            for palavra in palavras:\n",
        "                if len(temp_seg + \" \" + palavra) <= max_chars:\n",
        "                    temp_seg += \" \" + palavra if temp_seg else palavra\n",
        "                else:\n",
        "                    if temp_seg:\n",
        "                        segmentos_finais.append(temp_seg.strip())\n",
        "                    temp_seg = palavra\n",
        "            if temp_seg:\n",
        "                segmentos_finais.append(temp_seg.strip())\n",
        "        else:\n",
        "            segmentos_finais.append(seg)\n",
        "\n",
        "    return segmentos_finais\n",
        "\n",
        "def segundos_para_timestamp(segundos):\n",
        "    \"\"\"Converte segundos para formato timestamp SRT (HH:MM:SS,mmm)\"\"\"\n",
        "    horas = int(segundos // 3600)\n",
        "    minutos = int((segundos % 3600) // 60)\n",
        "    segundos_restantes = segundos % 60\n",
        "    milissegundos = int((segundos_restantes - int(segundos_restantes)) * 1000)\n",
        "\n",
        "    return f\"{horas:02d}:{minutos:02d}:{int(segundos_restantes):02d},{milissegundos:03d}\"\n",
        "\n",
        "def gerar_arquivo_srt(legendas_data, srt_path):\n",
        "    \"\"\"Gera arquivo SRT\"\"\"\n",
        "    with open(srt_path, 'w', encoding='utf-8') as f:\n",
        "        for legenda in legendas_data:\n",
        "            f.write(f\"{legenda['id']}\\n\")\n",
        "            f.write(f\"{legenda['inicio']} --> {legenda['fim']}\\n\")\n",
        "            f.write(f\"{legenda['texto']}\\n\\n\")\n",
        "\n",
        "def gerar_arquivo_txt_timestamped(legendas_data, txt_path):\n",
        "    \"\"\"Gera arquivo TXT com timestamps\"\"\"\n",
        "    with open(txt_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"TRANSCRIÇÃO COM TIMESTAMPS\\n\")\n",
        "        f.write(\"=\"*50 + \"\\n\\n\")\n",
        "\n",
        "        for legenda in legendas_data:\n",
        "            minutos_inicio = int(legenda['inicio_segundos'] // 60)\n",
        "            segundos_inicio = int(legenda['inicio_segundos'] % 60)\n",
        "            minutos_fim = int(legenda['fim_segundos'] // 60)\n",
        "            segundos_fim = int(legenda['fim_segundos'] % 60)\n",
        "\n",
        "            f.write(f\"[{minutos_inicio:02d}:{segundos_inicio:02d}-{minutos_fim:02d}:{segundos_fim:02d}] {legenda['texto']}\\n\")\n",
        "\n",
        "def analisar_copywriting_estrategico(legendas_data, video_id):\n",
        "    \"\"\"Análise estratégica de copywriting com base nas legendas\"\"\"\n",
        "    print(\"    🔄 Analisando copywriting...\")\n",
        "\n",
        "    # Combinar todo o texto para análise completa\n",
        "    texto_completo = \" \".join([legenda[\"texto\"] for legenda in legendas_data])\n",
        "\n",
        "    # Dicionários de padrões de copywriting\n",
        "    ganchos_patterns = {\n",
        "        \"pergunta_retorica\": [r\"\\b(?:você|tu)\\s+(?:já|nunca|sempre|realmente|acha|imagina|sabe|quer|precisa)\",\n",
        "                            r\"(?:como|por que|quando|onde|o que).*\\?\"],\n",
        "        \"urgencia\": [r\"\\b(?:agora|hoje|urgente|rápido|imediato|última chance|só hoje|apenas|restam)\",\n",
        "                     r\"\\b(?:não perca|aproveite|garante já|corre|últimas vagas)\"],\n",
        "        \"escassez\": [r\"\\b(?:limitado|exclusivo|poucos|restam|última|única|especial|VIP)\",\n",
        "                     r\"\\b(?:só para|apenas para|somente|limitado a)\"],\n",
        "        \"autoridade\": [r\"\\b(?:especialista|expert|profissional|anos de experiência|comprovado|testado)\",\n",
        "                       r\"\\b(?:pesquisas mostram|estudos comprovam|cientificamente)\"],\n",
        "        \"prova_social\": [r\"\\b(?:milhares|centenas|todos|muitas pessoas|clientes|depoimentos)\",\n",
        "                         r\"\\b(?:já conseguiram|transformaram|mudaram|aprovaram)\"],\n",
        "        \"curiosidade\": [r\"\\b(?:segredo|descoberta|revelação|método|técnica|estratégia|fórmula)\",\n",
        "                        r\"\\b(?:ninguém te conta|poucos sabem|descobri que)\"],\n",
        "        \"problema_dor\": [r\"\\b(?:problema|dificuldade|frustração|sofre|dor|preocupa|bloqueia)\",\n",
        "                         r\"\\b(?:cansado de|chega de|pare de|não aguenta mais)\"],\n",
        "        \"solucao_resultado\": [r\"\\b(?:solução|resolve|elimina|transforma|muda|resultado|sucesso)\",\n",
        "                              r\"\\b(?:conseguir|alcançar|realizar|conquistar|atingir)\"]\n",
        "    }\n",
        "\n",
        "    gatilhos_patterns = {\n",
        "        \"reciprocidade\": [r\"\\b(?:grátis|de graça|presente|bônus|oferta|sem custo)\",\n",
        "                          r\"\\b(?:vou te dar|vou ensinar|vou mostrar|compartilhar com você)\"],\n",
        "        \"comprometimento\": [r\"\\b(?:compromisso|prometo|garanto|palavra|juro)\",\n",
        "                            r\"\\b(?:pode confiar|tenho certeza|assumo|responsabilizo)\"],\n",
        "        \"aprovacao_social\": [r\"\\b(?:aprovado por|recomendado|indicado|usado por|preferido)\",\n",
        "                             r\"\\b(?:famosos|influencers|especialistas|médicos|profissionais)\"],\n",
        "        \"aversao_perda\": [r\"\\b(?:perder|perdendo|vai ficar de fora|não vai conseguir)\",\n",
        "                          r\"\\b(?:sair perdendo|ficar para trás|oportunidade perdida)\"],\n",
        "        \"autoridade_especialista\": [r\"\\b(?:Dr|Dra|Professor|Mestre|PhD|especialista em)\",\n",
        "                                    r\"\\b(?:formado em|pós-graduado|anos estudando)\"],\n",
        "        \"emocional_medo\": [r\"\\b(?:medo|receio|preocupação|insegurança|ansiedade)\",\n",
        "                           r\"\\b(?:não conseguir|fracassar|dar errado|prejudicar)\"],\n",
        "        \"emocional_esperanca\": [r\"\\b(?:sonho|esperança|desejo|objetivo|meta|futuro melhor)\",\n",
        "                                r\"\\b(?:realizar|conquistar|alcançar|transformar|mudar vida)\"]\n",
        "    }\n",
        "\n",
        "    ctas_patterns = {\n",
        "        \"acao_imediata\": [r\"\\b(?:clica|clique|acesse|baixe|faça|compre|adquira|garanta)\",\n",
        "                          r\"\\b(?:não perca|aproveite|corre|vai|vem|participe)\"],\n",
        "        \"link_bio\": [r\"\\b(?:link na bio|bio|biografia|perfil|stories|direct)\",\n",
        "                     r\"\\b(?:DM|chama no WhatsApp|manda mensagem)\"],\n",
        "        \"engajamento\": [r\"\\b(?:comenta|compartilha|marca|salva|curte|like|segue)\",\n",
        "                        r\"\\b(?:conta nos comentários|deixa um|comenta aqui)\"],\n",
        "        \"inscricao\": [r\"\\b(?:inscreve|se inscreva|ativa|ativar|sino|notificação)\",\n",
        "                      r\"\\b(?:cadastra|cadastre-se|registra|assine)\"],\n",
        "        \"contato_vendas\": [r\"\\b(?:WhatsApp|telefone|ligue|chama|fala comigo|contato)\",\n",
        "                           r\"\\b(?:agende|marque|consulta|reunião|conversa)\"]\n",
        "    }\n",
        "\n",
        "    # Análise dos padrões\n",
        "    ganchos_encontrados = {}\n",
        "    gatilhos_encontrados = {}\n",
        "    ctas_encontrados = {}\n",
        "\n",
        "    # Analisar ganchos\n",
        "    for tipo, patterns in ganchos_patterns.items():\n",
        "        matches = []\n",
        "        for pattern in patterns:\n",
        "            matches.extend(re.finditer(pattern, texto_completo, re.IGNORECASE))\n",
        "        if matches:\n",
        "            ganchos_encontrados[tipo] = {\n",
        "                \"count\": len(matches),\n",
        "                \"exemplos\": [m.group() for m in matches[:3]],  # Top 3 exemplos\n",
        "                \"timestamps\": encontrar_timestamps_matches(matches, legendas_data, texto_completo)\n",
        "            }\n",
        "\n",
        "    # Analisar gatilhos\n",
        "    for tipo, patterns in gatilhos_patterns.items():\n",
        "        matches = []\n",
        "        for pattern in patterns:\n",
        "            matches.extend(re.finditer(pattern, texto_completo, re.IGNORECASE))\n",
        "        if matches:\n",
        "            gatilhos_encontrados[tipo] = {\n",
        "                \"count\": len(matches),\n",
        "                \"exemplos\": [m.group() for m in matches[:3]],\n",
        "                \"timestamps\": encontrar_timestamps_matches(matches, legendas_data, texto_completo)\n",
        "            }\n",
        "\n",
        "    # Analisar CTAs\n",
        "    for tipo, patterns in ctas_patterns.items():\n",
        "        matches = []\n",
        "        for pattern in patterns:\n",
        "            matches.extend(re.finditer(pattern, texto_completo, re.IGNORECASE))\n",
        "        if matches:\n",
        "            ctas_encontrados[tipo] = {\n",
        "                \"count\": len(matches),\n",
        "                \"exemplos\": [m.group() for m in matches[:3]],\n",
        "                \"timestamps\": encontrar_timestamps_matches(matches, legendas_data, texto_completo)\n",
        "            }\n",
        "\n",
        "    # Análise de estrutura narrativa\n",
        "    estrutura_narrativa = analisar_estrutura_narrativa(legendas_data)\n",
        "\n",
        "    # Análise de poder de persuasão\n",
        "    score_persuasao = calcular_score_persuasao(ganchos_encontrados, gatilhos_encontrados, ctas_encontrados)\n",
        "\n",
        "    analise_copywriting = {\n",
        "        \"video_id\": video_id,\n",
        "        \"texto_completo\": texto_completo,\n",
        "        \"total_palavras\": len(texto_completo.split()),\n",
        "        \"ganchos_detectados\": ganchos_encontrados,\n",
        "        \"gatilhos_mentais_detectados\": gatilhos_encontrados,\n",
        "        \"ctas_detectados\": ctas_encontrados,\n",
        "        \"estrutura_narrativa\": estrutura_narrativa,\n",
        "        \"score_persuasao\": score_persuasao,\n",
        "        \"recomendacoes_estrategicas\": gerar_recomendacoes_copywriting(ganchos_encontrados, gatilhos_encontrados, ctas_encontrados),\n",
        "        \"templates_identificados\": identificar_templates_replicaveis(ganchos_encontrados, gatilhos_encontrados, ctas_encontrados),\n",
        "        \"timestamp\": {\n",
        "            \"ganchos_timeline\": mapear_timeline_elementos(ganchos_encontrados, legendas_data),\n",
        "            \"gatilhos_timeline\": mapear_timeline_elementos(gatilhos_encontrados, legendas_data),\n",
        "            \"ctas_timeline\": mapear_timeline_elementos(ctas_encontrados, legendas_data)\n",
        "        },\n",
        "        \"data_analise\": datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    return analise_copywriting\n",
        "\n",
        "def encontrar_timestamps_matches(matches, legendas_data, texto_completo):\n",
        "    \"\"\"Encontra os timestamps correspondentes aos matches encontrados\"\"\"\n",
        "    timestamps = []\n",
        "\n",
        "    for match in matches[:3]:  # Limitar a 3 exemplos\n",
        "        posicao = match.start()\n",
        "        char_count = 0\n",
        "\n",
        "        for legenda in legendas_data:\n",
        "            texto_legenda = legenda[\"texto\"]\n",
        "            if char_count <= posicao < char_count + len(texto_legenda):\n",
        "                timestamps.append({\n",
        "                    \"minuto\": int(legenda[\"inicio_segundos\"] // 60),\n",
        "                    \"segundo\": int(legenda[\"inicio_segundos\"] % 60),\n",
        "                    \"texto_contexto\": texto_legenda\n",
        "                })\n",
        "                break\n",
        "            char_count += len(texto_legenda) + 1  # +1 para o espaço entre legendas\n",
        "\n",
        "    return timestamps\n",
        "\n",
        "def analisar_estrutura_narrativa(legendas_data):\n",
        "    \"\"\"Analisa a estrutura narrativa do vídeo\"\"\"\n",
        "    total_segmentos = len(legendas_data)\n",
        "\n",
        "    if total_segmentos < 3:\n",
        "        return {\n",
        "            \"abertura\": {\"segmentos\": total_segmentos, \"elementos\": []},\n",
        "            \"desenvolvimento\": {\"segmentos\": 0, \"elementos\": []},\n",
        "            \"fechamento\": {\"segmentos\": 0, \"elementos\": []}\n",
        "        }\n",
        "\n",
        "    # Dividir em terços para análise\n",
        "    primeiro_terco = legendas_data[:total_segmentos//3]\n",
        "    segundo_terco = legendas_data[total_segmentos//3:2*total_segmentos//3]\n",
        "    ultimo_terco = legendas_data[2*total_segmentos//3:]\n",
        "\n",
        "    estrutura = {\n",
        "        \"abertura\": {\n",
        "            \"segmentos\": len(primeiro_terco),\n",
        "            \"elementos\": analisar_elementos_abertura(primeiro_terco)\n",
        "        },\n",
        "        \"desenvolvimento\": {\n",
        "            \"segmentos\": len(segundo_terco),\n",
        "            \"elementos\": analisar_elementos_desenvolvimento(segundo_terco)\n",
        "        },\n",
        "        \"fechamento\": {\n",
        "            \"segmentos\": len(ultimo_terco),\n",
        "            \"elementos\": analisar_elementos_fechamento(ultimo_terco)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return estrutura\n",
        "\n",
        "def analisar_elementos_abertura(segmentos):\n",
        "    \"\"\"Analisa elementos da abertura\"\"\"\n",
        "    texto = \" \".join([s[\"texto\"] for s in segmentos])\n",
        "    elementos = []\n",
        "\n",
        "    if re.search(r'\\b(?:você|tu)\\s+(?:já|nunca|sempre)', texto, re.IGNORECASE):\n",
        "        elementos.append(\"pergunta_engajamento\")\n",
        "    if re.search(r'\\b(?:vou te|vou mostrar|vou ensinar)', texto, re.IGNORECASE):\n",
        "        elementos.append(\"promessa_valor\")\n",
        "    if re.search(r'\\b(?:segredo|descoberta|método)', texto, re.IGNORECASE):\n",
        "        elementos.append(\"curiosidade\")\n",
        "\n",
        "    return elementos\n",
        "\n",
        "def analisar_elementos_desenvolvimento(segmentos):\n",
        "    \"\"\"Analisa elementos do desenvolvimento\"\"\"\n",
        "    texto = \" \".join([s[\"texto\"] for s in segmentos])\n",
        "    elementos = []\n",
        "\n",
        "    if re.search(r'\\b(?:porque|pois|isso acontece)', texto, re.IGNORECASE):\n",
        "        elementos.append(\"explicacao\")\n",
        "    if re.search(r'\\b(?:exemplo|caso|situação)', texto, re.IGNORECASE):\n",
        "        elementos.append(\"exemplificacao\")\n",
        "    if re.search(r'\\b(?:resultado|consegui|transformou)', texto, re.IGNORECASE):\n",
        "        elementos.append(\"prova_resultado\")\n",
        "\n",
        "    return elementos\n",
        "\n",
        "def analisar_elementos_fechamento(segmentos):\n",
        "    \"\"\"Analisa elementos do fechamento\"\"\"\n",
        "    texto = \" \".join([s[\"texto\"] for s in segmentos])\n",
        "    elementos = []\n",
        "\n",
        "    if re.search(r'\\b(?:clica|clique|acesse|faça)', texto, re.IGNORECASE):\n",
        "        elementos.append(\"call_to_action\")\n",
        "    if re.search(r'\\b(?:link|bio|WhatsApp)', texto, re.IGNORECASE):\n",
        "        elementos.append(\"direcionamento\")\n",
        "    if re.search(r'\\b(?:comenta|compartilha|segue)', texto, re.IGNORECASE):\n",
        "        elementos.append(\"engajamento\")\n",
        "\n",
        "    return elementos\n",
        "\n",
        "def calcular_score_persuasao(ganchos, gatilhos, ctas):\n",
        "    \"\"\"Calcula score de persuasão baseado nos elementos encontrados\"\"\"\n",
        "    score = 0\n",
        "\n",
        "    # Pontuação por variedade de ganchos\n",
        "    score += len(ganchos) * 10\n",
        "\n",
        "    # Pontuação por variedade de gatilhos\n",
        "    score += len(gatilhos) * 15\n",
        "\n",
        "    # Pontuação por presença de CTAs\n",
        "    score += len(ctas) * 20\n",
        "\n",
        "    # Bônus por combinações poderosas\n",
        "    if \"urgencia\" in ganchos and \"aversao_perda\" in gatilhos:\n",
        "        score += 25\n",
        "\n",
        "    if \"autoridade\" in ganchos and \"autoridade_especialista\" in gatilhos:\n",
        "        score += 20\n",
        "\n",
        "    if \"curiosidade\" in ganchos and any(cta in ctas for cta in [\"acao_imediata\", \"link_bio\"]):\n",
        "        score += 30\n",
        "\n",
        "    return min(score, 100)  # Limitar a 100\n",
        "\n",
        "def gerar_recomendacoes_copywriting(ganchos, gatilhos, ctas):\n",
        "    \"\"\"Gera recomendações estratégicas baseadas na análise\"\"\"\n",
        "    recomendacoes = []\n",
        "\n",
        "    # Recomendações para ganchos\n",
        "    if len(ganchos) < 2:\n",
        "        recomendacoes.append({\n",
        "            \"categoria\": \"GANCHOS\",\n",
        "            \"prioridade\": \"ALTA\",\n",
        "            \"recomendacao\": \"Adicione mais ganchos na abertura. Use perguntas retóricas ou desperte curiosidade nos primeiros 3 segundos.\"\n",
        "        })\n",
        "\n",
        "    if \"pergunta_retorica\" not in ganchos:\n",
        "        recomendacoes.append({\n",
        "            \"categoria\": \"GANCHOS\",\n",
        "            \"prioridade\": \"MÉDIA\",\n",
        "            \"recomendacao\": \"Inicie com uma pergunta que faça o viewer refletir sobre sua situação atual.\"\n",
        "        })\n",
        "\n",
        "    # Recomendações para gatilhos\n",
        "    if len(gatilhos) < 3:\n",
        "        recomendacoes.append({\n",
        "            \"categoria\": \"GATILHOS\",\n",
        "            \"prioridade\": \"ALTA\",\n",
        "            \"recomendacao\": \"Incorpore mais gatilhos mentais. Combine autoridade + prova social para maior credibilidade.\"\n",
        "        })\n",
        "\n",
        "    if \"reciprocidade\" not in gatilhos:\n",
        "        recomendacoes.append({\n",
        "            \"categoria\": \"GATILHOS\",\n",
        "            \"prioridade\": \"MÉDIA\",\n",
        "            \"recomendacao\": \"Ofereça valor gratuito para ativar o gatilho da reciprocidade.\"\n",
        "        })\n",
        "\n",
        "    # Recomendações para CTAs\n",
        "    if len(ctas) == 0:\n",
        "        recomendacoes.append({\n",
        "            \"categoria\": \"CTA\",\n",
        "            \"prioridade\": \"CRÍTICA\",\n",
        "            \"recomendacao\": \"URGENTE: Adicione pelo menos um Call-to-Action claro. Sem CTA, não há conversão.\"\n",
        "        })\n",
        "\n",
        "    if \"acao_imediata\" not in ctas and \"link_bio\" not in ctas:\n",
        "        recomendacoes.append({\n",
        "            \"categoria\": \"CTA\",\n",
        "            \"prioridade\": \"ALTA\",\n",
        "            \"recomendacao\": \"Termine com um CTA direto: 'Clica no link da bio' ou 'Chama no WhatsApp'.\"\n",
        "        })\n",
        "\n",
        "    return recomendacoes\n",
        "\n",
        "def identificar_templates_replicaveis(ganchos, gatilhos, ctas):\n",
        "    \"\"\"Identifica templates e estruturas replicáveis\"\"\"\n",
        "    templates = []\n",
        "\n",
        "    # Template: Pergunta + Autoridade + CTA\n",
        "    if \"pergunta_retorica\" in ganchos and \"autoridade\" in ganchos and len(ctas) > 0:\n",
        "        templates.append({\n",
        "            \"nome\": \"PERGUNTA_AUTORIDADE_CTA\",\n",
        "            \"estrutura\": \"Pergunta Retórica → Estabelecer Autoridade → Call-to-Action\",\n",
        "            \"eficacia\": \"ALTA\",\n",
        "            \"uso_recomendado\": \"Vídeos educativos e de expertise\"\n",
        "        })\n",
        "\n",
        "    # Template: Problema + Solução + Prova Social\n",
        "    if \"problema_dor\" in ganchos and \"solucao_resultado\" in ganchos and \"aprovacao_social\" in gatilhos:\n",
        "        templates.append({\n",
        "            \"nome\": \"PROBLEMA_SOLUCAO_PROVA\",\n",
        "            \"estrutura\": \"Identificar Problema → Apresentar Solução → Mostrar Prova Social\",\n",
        "            \"eficacia\": \"MUITO ALTA\",\n",
        "            \"uso_recomendado\": \"Vídeos de vendas e transformação\"\n",
        "        })\n",
        "\n",
        "    # Template: Curiosidade + Urgência + CTA\n",
        "    if \"curiosidade\" in ganchos and \"urgencia\" in ganchos and \"acao_imediata\" in ctas:\n",
        "        templates.append({\n",
        "            \"nome\": \"CURIOSIDADE_URGENCIA_ACAO\",\n",
        "            \"estrutura\": \"Despertar Curiosidade → Criar Urgência → Ação Imediata\",\n",
        "            \"eficacia\": \"ALTA\",\n",
        "            \"uso_recomendado\": \"Vídeos de lançamento e ofertas limitadas\"\n",
        "        })\n",
        "\n",
        "    return templates\n",
        "\n",
        "def mapear_timeline_elementos(elementos_detectados, legendas_data):\n",
        "    \"\"\"Mapeia os elementos detectados na timeline do vídeo\"\"\"\n",
        "    timeline = []\n",
        "\n",
        "    for tipo, dados in elementos_detectados.items():\n",
        "        for timestamp in dados.get(\"timestamps\", []):\n",
        "            timeline.append({\n",
        "                \"tipo\": tipo,\n",
        "                \"minuto\": timestamp[\"minuto\"],\n",
        "                \"segundo\": timestamp[\"segundo\"],\n",
        "                \"contexto\": timestamp[\"texto_contexto\"]\n",
        "            })\n",
        "\n",
        "    # Ordenar por tempo\n",
        "    timeline.sort(key=lambda x: (x[\"minuto\"], x[\"segundo\"]))\n",
        "\n",
        "    return timeline\n",
        "\n",
        "# Executar o processamento\n",
        "try:\n",
        "    processar_copywriting_todos_videos_adaptado()\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERRO de Execução: {type(e).__name__}: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "id": "p-wM_X9W5nZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CÉLULA 2.4: GERAÇÃO DE LEGENDAS E ANÁLISE DE COPYWRITING\n",
        "# ============================================================================\n",
        "\n",
        "# Definir a variável global PASTA_TRABALHO se ainda não estiver definida\n",
        "# Certifique-se de que esta variável esteja definida corretamente em uma célula anterior (ex: Célula 1.2)\n",
        "# Exemplo: PASTA_TRABALHO = \"/content/drive/MyDrive/Videos Dona Done/_engenharia_reversa\"\n",
        "\n",
        "# Executar a função principal da Layer 2.4\n",
        "if 'PASTA_TRABALHO' in globals():\n",
        "    print(\"Iniciando a Layer 2.4: Geração de Legendas e Análise de Copywriting...\")\n",
        "    processar_copywriting_todos_videos_adaptado()\n",
        "else:\n",
        "    print(\"ERRO: A variável PASTA_TRABALHO não está definida. Certifique-se de executar a Célula 1.2 ou equivalente.\")"
      ],
      "metadata": {
        "id": "UfcEs533582H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CÉLULA 4.3: DASHBOARD MASTER EXECUTIVO INTELIGENTE APRIMORADO\n",
        "# ============================================================================\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "from openpyxl.styles import Font, Alignment, PatternFill\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def log_progress(message):\n",
        "    \"\"\"Log de progresso em tempo real\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
        "    print(f\"[{timestamp}] {message}\")\n",
        "\n",
        "def calculate_viral_score(row):\n",
        "    \"\"\"Calcula score de viralidade baseado em múltiplos fatores\"\"\"\n",
        "    try:\n",
        "        score = 0\n",
        "\n",
        "        # Fator 1: Ritmo (cortes por segundo) - peso 25%\n",
        "        if pd.notna(row['duracao_segundos']) and row['duracao_segundos'] > 0:\n",
        "            cortes_por_seg = row['cortes_detectados_count'] / row['duracao_segundos']\n",
        "            if cortes_por_seg > 20: score += 25\n",
        "            elif cortes_por_seg > 10: score += 20\n",
        "            elif cortes_por_seg > 5: score += 15\n",
        "            else: score += 10\n",
        "\n",
        "        # Fator 2: Complexidade Visual - peso 20%\n",
        "        if pd.notna(row['complexidade_visual_media']):\n",
        "            if row['complexidade_visual_media'] > 600: score += 20\n",
        "            elif row['complexidade_visual_media'] > 400: score += 15\n",
        "            else: score += 10\n",
        "\n",
        "        # Fator 3: Presença de Texto (OCR) - peso 15%\n",
        "        if pd.notna(row['ocr_textos_count']):\n",
        "            if row['ocr_textos_count'] > 10: score += 15\n",
        "            elif row['ocr_textos_count'] > 5: score += 12\n",
        "            elif row['ocr_textos_count'] > 0: score += 8\n",
        "\n",
        "        # Fator 4: Duração Ideal - peso 20%\n",
        "        if pd.notna(row['duracao_segundos']):\n",
        "            if 15 <= row['duracao_segundos'] <= 30: score += 20\n",
        "            elif 10 <= row['duracao_segundos'] <= 45: score += 15\n",
        "            else: score += 10\n",
        "\n",
        "        # Fator 5: Gatilhos Psicológicos - peso 20%\n",
        "        gatilhos = str(row['gatilhos_psicologicos']).lower()\n",
        "        if 'urgência' in gatilhos or 'escassez' in gatilhos: score += 8\n",
        "        if 'estímulo' in gatilhos: score += 7\n",
        "        if 'atenção' in gatilhos: score += 5\n",
        "\n",
        "        return min(score, 100)\n",
        "    except:\n",
        "        return 50\n",
        "\n",
        "def calculate_technical_score(row):\n",
        "    \"\"\"Score técnico baseado em qualidade de produção\"\"\"\n",
        "    try:\n",
        "        score = 0\n",
        "\n",
        "        if pd.notna(row['brilho_medio']):\n",
        "            if 120 <= row['brilho_medio'] <= 180: score += 25\n",
        "            elif 100 <= row['brilho_medio'] <= 200: score += 20\n",
        "            else: score += 10\n",
        "\n",
        "        formato = str(row['formato_detectado'])\n",
        "        if 'vertical_9_16' in formato: score += 25\n",
        "        elif 'horizontal_16_9' in formato: score += 20\n",
        "        else: score += 15\n",
        "\n",
        "        if row['tem_audio']: score += 25\n",
        "        else: score += 5\n",
        "\n",
        "        if pd.notna(row['total_frames']) and row['total_frames'] > 0:\n",
        "            if row['total_frames'] > 300: score += 25\n",
        "            elif row['total_frames'] > 150: score += 20\n",
        "            else: score += 15\n",
        "\n",
        "        return min(score, 100)\n",
        "    except:\n",
        "        return 50\n",
        "\n",
        "def calculate_content_score(row):\n",
        "    \"\"\"Score de conteúdo baseado em riqueza informacional\"\"\"\n",
        "    try:\n",
        "        score = 0\n",
        "\n",
        "        ocr_count = row['ocr_textos_count'] if pd.notna(row['ocr_textos_count']) else 0\n",
        "        audio_len = row['audio_transcrito_len'] if pd.notna(row['audio_transcrito_len']) else 0\n",
        "\n",
        "        if ocr_count > 5 or audio_len > 100: score += 30\n",
        "        elif ocr_count > 2 or audio_len > 50: score += 20\n",
        "        elif ocr_count > 0 or audio_len > 0: score += 15\n",
        "        else: score += 5\n",
        "\n",
        "        if pd.notna(row['bpm_audio']):\n",
        "            if 120 <= row['bpm_audio'] <= 140: score += 35\n",
        "            elif 100 <= row['bpm_audio'] <= 160: score += 25\n",
        "            else: score += 15\n",
        "\n",
        "        if pd.notna(row['duracao_segundos']) and row['duracao_segundos'] > 0:\n",
        "            densidade = (ocr_count + audio_len/10) / row['duracao_segundos']\n",
        "            if densidade > 2: score += 35\n",
        "            elif densidade > 1: score += 25\n",
        "            else: score += 15\n",
        "\n",
        "        return min(score, 100)\n",
        "    except:\n",
        "        return 50\n",
        "\n",
        "def generate_insights_from_data(df):\n",
        "    \"\"\"Gera insights inteligentes baseados nos dados\"\"\"\n",
        "    insights = []\n",
        "\n",
        "    try:\n",
        "        best_performing = df.nlargest(3, 'viral_score')\n",
        "        avg_duration = best_performing['duracao_segundos'].mean()\n",
        "        insights.append(f\"DURAÇÃO VENCEDORA: Seus top 3 vídeos têm duração média de {avg_duration:.1f}s. Este é seu sweet spot comprovado.\")\n",
        "\n",
        "        avg_cuts_per_sec = (best_performing['cortes_detectados_count'] / best_performing['duracao_segundos']).mean()\n",
        "        insights.append(f\"RITMO IDEAL: {avg_cuts_per_sec:.1f} cortes por segundo é sua fórmula de edição mais eficaz.\")\n",
        "\n",
        "        formato_winner = df['formato_detectado'].mode()[0] if not df['formato_detectado'].empty else 'N/A'\n",
        "        formato_count = df['formato_detectado'].value_counts().iloc[0] if not df['formato_detectado'].empty else 0\n",
        "        insights.append(f\"FORMATO DOMINANTE: {formato_count} vídeos em {formato_winner}. Este é seu formato de maior alcance.\")\n",
        "\n",
        "        high_viral = df[df['viral_score'] > 70]\n",
        "        if not high_viral.empty:\n",
        "            avg_complexity = high_viral['complexidade_visual_media'].mean()\n",
        "            insights.append(f\"COMPLEXIDADE VISUAL ÓTIMA: Vídeos com score viral alto têm complexidade média de {avg_complexity:.0f}. Use como referência.\")\n",
        "\n",
        "        text_heavy = df[df['ocr_textos_count'] > 5]\n",
        "        if not text_heavy.empty:\n",
        "            insights.append(f\"ESTRATÉGIA DE TEXTO: {len(text_heavy)} vídeos com muito texto têm score médio de {text_heavy['viral_score'].mean():.0f}. Texto na tela impacta performance.\")\n",
        "\n",
        "        # CORRIGIDO: bpm_audio em vez de bmp_audio\n",
        "        if df['bpm_audio'].notna().any():\n",
        "            successful_bpm = df[df['viral_score'] > 60]['bpm_audio'].mean()\n",
        "            insights.append(f\"BPM DE SUCESSO: {successful_bpm:.0f} BPM é o ritmo de áudio dos seus vídeos mais virais.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        log_progress(f\"Erro ao gerar insights: {e}\")\n",
        "        insights.append(\"Insights parciais disponíveis devido a limitações nos dados.\")\n",
        "\n",
        "    return insights\n",
        "\n",
        "def add_data_to_sheet(ws, data, start_row=1, start_col=1, headers=None):\n",
        "    \"\"\"Adiciona dados a uma planilha de forma segura\"\"\"\n",
        "    current_row = start_row\n",
        "\n",
        "    # Adicionar cabeçalhos se fornecidos\n",
        "    if headers:\n",
        "        for col_idx, header in enumerate(headers):\n",
        "            cell = ws.cell(row=current_row, column=start_col + col_idx)\n",
        "            cell.value = header\n",
        "            cell.font = Font(bold=True)\n",
        "        current_row += 1\n",
        "\n",
        "    # Adicionar dados\n",
        "    for row_data in data:\n",
        "        for col_idx, value in enumerate(row_data):\n",
        "            cell = ws.cell(row=current_row, column=start_col + col_idx)\n",
        "            cell.value = value\n",
        "        current_row += 1\n",
        "\n",
        "    return current_row\n",
        "\n",
        "def create_enhanced_dashboard_master(csv_path, json_path, output_path):\n",
        "    \"\"\"Cria dashboard master executivo aprimorado\"\"\"\n",
        "\n",
        "    log_progress(\"INICIANDO CRIAÇÃO DO DASHBOARD MASTER EXECUTIVO INTELIGENTE\")\n",
        "\n",
        "    try:\n",
        "        # Carregar dados\n",
        "        log_progress(\"Carregando dados consolidados...\")\n",
        "        df_consolidado = pd.read_csv(csv_path, encoding='utf-8')\n",
        "\n",
        "        with open(json_path, 'r', encoding='utf-8') as f:\n",
        "            dados_detalhados = json.load(f)\n",
        "\n",
        "        log_progress(f\"Dados carregados: {len(df_consolidado)} vídeos encontrados\")\n",
        "\n",
        "        # Pré-processamento inteligente\n",
        "        log_progress(\"Processando inteligência artificial dos dados...\")\n",
        "\n",
        "        # Limpar e converter dados\n",
        "        try:\n",
        "            df_consolidado['emocoes_predominantes'] = df_consolidado['emocoes_predominantes'].apply(\n",
        "                lambda x: json.loads(x.replace(\"'\", '\"')) if pd.notna(x) and x != '{}' else {}\n",
        "            )\n",
        "        except:\n",
        "            df_consolidado['emocoes_predominantes'] = [{}] * len(df_consolidado)\n",
        "\n",
        "        # Calcular scores inteligentes\n",
        "        log_progress(\"Calculando scores de performance...\")\n",
        "        df_consolidado['viral_score'] = df_consolidado.apply(calculate_viral_score, axis=1)\n",
        "        df_consolidado['technical_score'] = df_consolidado.apply(calculate_technical_score, axis=1)\n",
        "        df_consolidado['content_score'] = df_consolidado.apply(calculate_content_score, axis=1)\n",
        "        df_consolidado['overall_score'] = (df_consolidado['viral_score'] + df_consolidado['technical_score'] + df_consolidado['content_score']) / 3\n",
        "\n",
        "        # Calcular métricas avançadas\n",
        "        df_consolidado['cortes_por_segundo'] = df_consolidado['cortes_detectados_count'] / df_consolidado['duracao_segundos'].replace(0, 1)\n",
        "        df_consolidado['densidade_texto'] = df_consolidado['ocr_textos_count'] / df_consolidado['duracao_segundos'].replace(0, 1)\n",
        "        df_consolidado['eficiencia_audio'] = df_consolidado['audio_transcrito_len'] / df_consolidado['duracao_segundos'].replace(0, 1)\n",
        "\n",
        "        log_progress(\"Gerando insights estratégicos...\")\n",
        "        insights = generate_insights_from_data(df_consolidado)\n",
        "\n",
        "        # Criar workbook\n",
        "        log_progress(\"Criando estrutura do dashboard...\")\n",
        "        wb = Workbook()\n",
        "\n",
        "        # === ABA 1: EXECUTIVE SUMMARY ===\n",
        "        log_progress(\"Criando Executive Summary...\")\n",
        "        ws_summary = wb.active\n",
        "        ws_summary.title = 'Executive Summary'\n",
        "\n",
        "        # Header principal\n",
        "        header_cell = ws_summary.cell(row=1, column=1)\n",
        "        header_cell.value = 'DASHBOARD MASTER EXECUTIVO - ENGENHARIA REVERSA DE VÍDEOS'\n",
        "        header_cell.font = Font(bold=True, size=18, color='FFFFFF')\n",
        "        header_cell.fill = PatternFill(start_color='1F4E79', end_color='1F4E79', fill_type='solid')\n",
        "        header_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
        "\n",
        "        # Expandir header manualmente\n",
        "        for col in range(2, 9):\n",
        "            cell = ws_summary.cell(row=1, column=col)\n",
        "            cell.fill = PatternFill(start_color='1F4E79', end_color='1F4E79', fill_type='solid')\n",
        "\n",
        "        # KPIs Principais\n",
        "        kpi_cell = ws_summary.cell(row=3, column=1)\n",
        "        kpi_cell.value = 'INDICADORES DE PERFORMANCE PRINCIPAIS'\n",
        "        kpi_cell.font = Font(bold=True, size=14)\n",
        "        kpi_cell.fill = PatternFill(start_color='E7E6E6', end_color='E7E6E6', fill_type='solid')\n",
        "\n",
        "        kpis_data = [\n",
        "            ['Total de Vídeos Analisados', len(df_consolidado)],\n",
        "            ['Score Viral Médio', f\"{df_consolidado['viral_score'].mean():.1f}/100\"],\n",
        "            ['Score Técnico Médio', f\"{df_consolidado['technical_score'].mean():.1f}/100\"],\n",
        "            ['Score de Conteúdo Médio', f\"{df_consolidado['content_score'].mean():.1f}/100\"],\n",
        "            ['Duração Média Otimizada', f\"{df_consolidado['duracao_segundos'].mean():.1f}s\"],\n",
        "            ['Ritmo Médio de Cortes', f\"{df_consolidado['cortes_por_segundo'].mean():.1f}/seg\"],\n",
        "        ]\n",
        "\n",
        "        add_data_to_sheet(ws_summary, kpis_data, start_row=4, start_col=1)\n",
        "\n",
        "        # Top 3 Vídeos\n",
        "        top3_cell = ws_summary.cell(row=3, column=4)\n",
        "        top3_cell.value = 'TOP 3 VÍDEOS POR PERFORMANCE'\n",
        "        top3_cell.font = Font(bold=True, size=14)\n",
        "        top3_cell.fill = PatternFill(start_color='E7E6E6', end_color='E7E6E6', fill_type='solid')\n",
        "\n",
        "        top3 = df_consolidado.nlargest(3, 'overall_score')[['nome_arquivo', 'overall_score', 'viral_score', 'technical_score', 'content_score']]\n",
        "\n",
        "        top3_data = []\n",
        "        for _, video in top3.iterrows():\n",
        "            nome_curto = video['nome_arquivo'][:30] + \"...\" if len(video['nome_arquivo']) > 30 else video['nome_arquivo']\n",
        "            top3_data.append([\n",
        "                nome_curto,\n",
        "                f\"{video['overall_score']:.1f}\",\n",
        "                f\"{video['viral_score']:.1f}\",\n",
        "                f\"{video['technical_score']:.1f}\",\n",
        "                f\"{video['content_score']:.1f}\"\n",
        "            ])\n",
        "\n",
        "        top3_headers = ['Vídeo', 'Score Geral', 'Viral', 'Técnico', 'Conteúdo']\n",
        "        add_data_to_sheet(ws_summary, top3_data, start_row=4, start_col=4, headers=top3_headers)\n",
        "\n",
        "        # Insights Estratégicos\n",
        "        insights_cell = ws_summary.cell(row=12, column=1)\n",
        "        insights_cell.value = 'INSIGHTS ESTRATÉGICOS BASEADOS EM IA'\n",
        "        insights_cell.font = Font(bold=True, size=14, color='FFFFFF')\n",
        "        insights_cell.fill = PatternFill(start_color='C5504B', end_color='C5504B', fill_type='solid')\n",
        "        insights_cell.alignment = Alignment(horizontal='center')\n",
        "\n",
        "        # Adicionar insights\n",
        "        for i, insight in enumerate(insights, 13):\n",
        "            insight_cell = ws_summary.cell(row=i, column=1)\n",
        "            insight_cell.value = f\"• {insight}\"\n",
        "            insight_cell.alignment = Alignment(wrap_text=True)\n",
        "\n",
        "        # === ABA 2: ANÁLISE DE PERFORMANCE ===\n",
        "        log_progress(\"Criando Análise de Performance...\")\n",
        "        ws_performance = wb.create_sheet('Análise de Performance')\n",
        "\n",
        "        perf_header = ws_performance.cell(row=1, column=1)\n",
        "        perf_header.value = 'ANÁLISE DETALHADA DE PERFORMANCE'\n",
        "        perf_header.font = Font(bold=True, size=16)\n",
        "        perf_header.alignment = Alignment(horizontal='center')\n",
        "\n",
        "        # Ranking completo\n",
        "        ranking_data = df_consolidado[['nome_arquivo', 'overall_score', 'viral_score', 'technical_score', 'content_score',\n",
        "                                     'duracao_segundos', 'cortes_por_segundo', 'formato_detectado']].sort_values('overall_score', ascending=False)\n",
        "\n",
        "        ranking_list = []\n",
        "        for _, video in ranking_data.iterrows():\n",
        "            nome_curto = video['nome_arquivo'][:40] + \"...\" if len(video['nome_arquivo']) > 40 else video['nome_arquivo']\n",
        "            ranking_list.append([\n",
        "                nome_curto,\n",
        "                f\"{video['overall_score']:.1f}\",\n",
        "                f\"{video['viral_score']:.1f}\",\n",
        "                f\"{video['technical_score']:.1f}\",\n",
        "                f\"{video['content_score']:.1f}\",\n",
        "                f\"{video['duracao_segundos']:.1f}s\",\n",
        "                f\"{video['cortes_por_segundo']:.1f}\",\n",
        "                video['formato_detectado']\n",
        "            ])\n",
        "\n",
        "        ranking_headers = ['Vídeo', 'Score Geral', 'Viral', 'Técnico', 'Conteúdo', 'Duração', 'Cortes/s', 'Formato']\n",
        "        add_data_to_sheet(ws_performance, ranking_list, start_row=3, start_col=1, headers=ranking_headers)\n",
        "\n",
        "        # === ABA 3: INTELIGÊNCIA TÉCNICA ===\n",
        "        log_progress(\"Criando Inteligência Técnica...\")\n",
        "        ws_tecnica = wb.create_sheet('Inteligência Técnica')\n",
        "\n",
        "        tec_header = ws_tecnica.cell(row=1, column=1)\n",
        "        tec_header.value = 'ANÁLISE TÉCNICA AVANÇADA'\n",
        "        tec_header.font = Font(bold=True, size=16)\n",
        "        tec_header.alignment = Alignment(horizontal='center')\n",
        "\n",
        "        # Análise de correlações\n",
        "        corr_header = ws_tecnica.cell(row=3, column=1)\n",
        "        corr_header.value = 'CORRELAÇÕES DESCOBERTAS'\n",
        "        corr_header.font = Font(bold=True, size=12)\n",
        "\n",
        "        correlations_data = [\n",
        "            ['Duração vs Score Viral', f\"{df_consolidado['duracao_segundos'].corr(df_consolidado['viral_score']):.3f}\", 'CORRELAÇÃO MODERADA'],\n",
        "            ['Cortes/s vs Score Viral', f\"{df_consolidado['cortes_por_segundo'].corr(df_consolidado['viral_score']):.3f}\", 'CORRELAÇÃO MODERADA'],\n",
        "            ['Complexidade Visual vs Performance', f\"{df_consolidado['complexidade_visual_media'].corr(df_consolidado['overall_score']):.3f}\", 'CORRELAÇÃO FRACA'],\n",
        "            ['BPM vs Engajamento', f\"{df_consolidado['bpm_audio'].corr(df_consolidado['viral_score']) if df_consolidado['bpm_audio'].notna().any() else 0:.3f}\", 'CORRELAÇÃO FRACA'],\n",
        "        ]\n",
        "\n",
        "        corr_headers = ['Métrica', 'Correlação', 'Classificação']\n",
        "        add_data_to_sheet(ws_tecnica, correlations_data, start_row=4, start_col=1, headers=corr_headers)\n",
        "\n",
        "        # === ABA 4: BLUEPRINT DE PRODUÇÃO ===\n",
        "        log_progress(\"Criando Blueprint de Produção...\")\n",
        "        ws_blueprint = wb.create_sheet('Blueprint de Produção')\n",
        "\n",
        "        bp_header = ws_blueprint.cell(row=1, column=1)\n",
        "        bp_header.value = 'BLUEPRINT ESTRATÉGICO DE PRODUÇÃO'\n",
        "        bp_header.font = Font(bold=True, size=16, color='FFFFFF')\n",
        "        bp_header.fill = PatternFill(start_color='1F4E79', end_color='1F4E79', fill_type='solid')\n",
        "        bp_header.alignment = Alignment(horizontal='center')\n",
        "\n",
        "        # Receita de sucesso baseada nos top performers\n",
        "        top_performers = df_consolidado[df_consolidado['overall_score'] > df_consolidado['overall_score'].quantile(0.7)]\n",
        "\n",
        "        blueprint_data = [\n",
        "            ['DURAÇÃO IDEAL', f\"{top_performers['duracao_segundos'].mean():.1f} segundos (±{top_performers['duracao_segundos'].std():.1f}s)\"],\n",
        "            ['RITMO DE EDIÇÃO', f\"{top_performers['cortes_por_segundo'].mean():.1f} cortes por segundo\"],\n",
        "            ['FORMATO VENCEDOR', top_performers['formato_detectado'].mode()[0] if not top_performers.empty else 'N/A'],\n",
        "            ['COMPLEXIDADE VISUAL', f\"Nível {top_performers['complexidade_visual_media'].mean():.0f} (escala de estímulo)\"],\n",
        "            ['BPM RECOMENDADO', f\"{top_performers['bpm_audio'].mean():.0f} BPM\" if top_performers['bpm_audio'].notna().any() else 'N/A'],\n",
        "            ['DENSIDADE DE TEXTO', f\"{top_performers['densidade_texto'].mean():.1f} textos por segundo\"],\n",
        "        ]\n",
        "\n",
        "        bp_sub_header = ws_blueprint.cell(row=3, column=1)\n",
        "        bp_sub_header.value = 'FÓRMULA DE SUCESSO BASEADA EM DADOS'\n",
        "        bp_sub_header.font = Font(bold=True, size=12)\n",
        "\n",
        "        add_data_to_sheet(ws_blueprint, blueprint_data, start_row=4, start_col=1)\n",
        "\n",
        "        # === ABA 5: RECOMENDAÇÕES ESTRATÉGICAS ===\n",
        "        log_progress(\"Criando Recomendações Estratégicas...\")\n",
        "        ws_recomendacoes = wb.create_sheet('Recomendações Estratégicas')\n",
        "\n",
        "        rec_header = ws_recomendacoes.cell(row=1, column=1)\n",
        "        rec_header.value = 'RECOMENDAÇÕES ESTRATÉGICAS BASEADAS EM IA'\n",
        "        rec_header.font = Font(bold=True, size=16, color='FFFFFF')\n",
        "        rec_header.fill = PatternFill(start_color='C5504B', end_color='C5504B', fill_type='solid')\n",
        "        rec_header.alignment = Alignment(horizontal='center')\n",
        "\n",
        "        # Recomendações inteligentes baseadas nos dados\n",
        "        recommendations = []\n",
        "\n",
        "        # Análise de duração\n",
        "        if df_consolidado['duracao_segundos'].mean() > 60:\n",
        "            recommendations.append(['DURAÇÃO', 'REDUZA DURAÇÃO', 'Seus vídeos estão longos demais. Vídeos de 15-30s têm melhor performance.', 'ALTA'])\n",
        "        elif df_consolidado['duracao_segundos'].mean() < 15:\n",
        "            recommendations.append(['DURAÇÃO', 'AUMENTE DURAÇÃO', 'Vídeos muito curtos podem não transmitir valor suficiente.', 'MÉDIA'])\n",
        "\n",
        "        # Análise de ritmo\n",
        "        avg_cuts_per_sec = df_consolidado['cortes_por_segundo'].mean()\n",
        "        if avg_cuts_per_sec < 5:\n",
        "            recommendations.append(['EDIÇÃO', 'ACELERE O RITMO', 'Aumente o número de cortes para manter atenção. Meta: 8-12 cortes/segundo.', 'ALTA'])\n",
        "        elif avg_cuts_per_sec > 20:\n",
        "            recommendations.append(['EDIÇÃO', 'DIMINUA CORTES', 'Muitos cortes podem causar fadiga visual. Encontre o equilíbrio.', 'MÉDIA'])\n",
        "\n",
        "        # Análise de formato\n",
        "        formato_dominante = df_consolidado['formato_detectado'].mode()[0] if not df_consolidado['formato_detectado'].empty else 'N/A'\n",
        "        if 'horizontal' in formato_dominante.lower():\n",
        "            recommendations.append(['FORMATO', 'FOQUE EM VERTICAL', 'Formato vertical (9:16) tem melhor performance em redes sociais.', 'ALTA'])\n",
        "\n",
        "        # Análise de texto\n",
        "        if df_consolidado['densidade_texto'].mean() < 1:\n",
        "            recommendations.append(['CONTEÚDO', 'ADICIONE MAIS TEXTO', 'Textos na tela aumentam retenção e acessibilidade.', 'MÉDIA'])\n",
        "\n",
        "        rec_headers = ['Categoria', 'Ação', 'Justificativa', 'Prioridade']\n",
        "        add_data_to_sheet(ws_recomendacoes, recommendations, start_row=3, start_col=1, headers=rec_headers)\n",
        "\n",
        "        # Salvar arquivo\n",
        "        log_progress(\"Salvando dashboard...\")\n",
        "        wb.save(output_path)\n",
        "\n",
        "        log_progress(\"DASHBOARD MASTER EXECUTIVO CRIADO COM SUCESSO!\")\n",
        "        log_progress(f\"Arquivo salvo em: {output_path}\")\n",
        "        log_progress(f\"{len(df_consolidado)} vídeos analisados\")\n",
        "        log_progress(f\"{len(insights)} insights estratégicos gerados\")\n",
        "        log_progress(f\"{len(recommendations)} recomendações criadas\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        log_progress(f\"ERRO CRÍTICO: {e}\")\n",
        "        log_progress(\"Verifique os arquivos de entrada e tente novamente\")\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    \"\"\"Função principal de execução\"\"\"\n",
        "    log_progress(\"INICIANDO SISTEMA DE DASHBOARD INTELIGENTE\")\n",
        "\n",
        "    # Configurar caminhos\n",
        "    BASE_PATH = \"/content/drive/MyDrive/Videos Dona Done/_engenharia_reversa\"\n",
        "    CSV_PATH = os.path.join(BASE_PATH, \"dashboard\", \"dados_consolidados.csv\")\n",
        "    JSON_PATH = os.path.join(BASE_PATH, \"dashboard\", \"dados_detalhados.json\")\n",
        "    OUTPUT_PATH = os.path.join(BASE_PATH, \"dashboard\", \"DASHBOARD_MASTER_EXECUTIVO_INTELIGENTE.xlsx\")\n",
        "\n",
        "    # Verificar se arquivos existem\n",
        "    if not os.path.exists(CSV_PATH):\n",
        "        log_progress(f\"ERRO: Arquivo CSV não encontrado: {CSV_PATH}\")\n",
        "        return False\n",
        "\n",
        "    if not os.path.exists(JSON_PATH):\n",
        "        log_progress(f\"ERRO: Arquivo JSON não encontrado: {JSON_PATH}\")\n",
        "        return False\n",
        "\n",
        "    # Executar criação do dashboard\n",
        "    success = create_enhanced_dashboard_master(CSV_PATH, JSON_PATH, OUTPUT_PATH)\n",
        "\n",
        "    if success:\n",
        "        log_progress(\"PROCESSO CONCLUÍDO COM SUCESSO!\")\n",
        "        log_progress(\"Dashboard inteligente pronto para uso estratégico\")\n",
        "    else:\n",
        "        log_progress(\"PROCESSO FALHOU - Verifique os logs acima\")\n",
        "\n",
        "    return success\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "NUeniUqRJLuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LAYER 4.3: INTEGRAÇÃO DE COPYWRITING NO DASHBOARD EXISTENTE\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from openpyxl import load_workbook\n",
        "from openpyxl.styles import Font, PatternFill, Alignment\n",
        "\n",
        "def integrar_copywriting_dashboard_existente():\n",
        "    \"\"\"Integra análise de copywriting no dashboard master existente\"\"\"\n",
        "    print(\"🔄 Iniciando integração de copywriting no dashboard existente...\")\n",
        "\n",
        "    # Verificar pré-requisitos\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa('copywriting_analysis')\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Localizar dashboard existente\n",
        "    pasta_dashboard = os.path.join(PASTA_TRABALHO, \"dashboard\")\n",
        "    dashboard_existente = None\n",
        "\n",
        "    # Procurar arquivo de dashboard existente\n",
        "    if os.path.exists(pasta_dashboard):\n",
        "        arquivos = os.listdir(pasta_dashboard)\n",
        "        for arquivo in arquivos:\n",
        "            if \"DASHBOARD_MASTER_EXECUTIVO_INTELIGENTE\" in arquivo and arquivo.endswith(\".xlsx\"):\n",
        "                dashboard_existente = os.path.join(pasta_dashboard, arquivo)\n",
        "                break\n",
        "\n",
        "    if not dashboard_existente:\n",
        "        print(\"❌ Dashboard master existente não encontrado!\")\n",
        "        print(\"Execute primeiro a célula 4.2 (Blueprint Final) para criar o dashboard base.\")\n",
        "        return\n",
        "\n",
        "    print(f\"  📊 Dashboard encontrado: {os.path.basename(dashboard_existente)}\")\n",
        "\n",
        "    # Carregar dados de copywriting\n",
        "    dados_copywriting = carregar_dados_copywriting()\n",
        "    if not dados_copywriting:\n",
        "        return\n",
        "\n",
        "    # Abrir workbook existente\n",
        "    try:\n",
        "        wb = load_workbook(dashboard_existente)\n",
        "        print(f\"  ✅ Dashboard carregado com {len(wb.sheetnames)} abas existentes\")\n",
        "\n",
        "        # Adicionar novas abas de copywriting\n",
        "        adicionar_aba_copywriting_estrategico(wb, dados_copywriting)\n",
        "        adicionar_aba_templates_copy(wb, dados_copywriting)\n",
        "        adicionar_aba_timeline_copy(wb, dados_copywriting)\n",
        "        adicionar_aba_recomendacoes_copy(wb, dados_copywriting)\n",
        "\n",
        "        # Atualizar aba principal com métricas de copywriting\n",
        "        atualizar_aba_principal_com_copy(wb, dados_copywriting)\n",
        "\n",
        "        # Salvar dashboard atualizado\n",
        "        wb.save(dashboard_existente)\n",
        "\n",
        "        print(f\"✅ Dashboard atualizado com análise de copywriting!\")\n",
        "        print(f\"📊 Arquivo: {dashboard_existente}\")\n",
        "        print(f\"📋 Novas abas adicionadas:\")\n",
        "        print(\"  • Copywriting Estratégico\")\n",
        "        print(\"  • Templates Replicáveis\")\n",
        "        print(\"  • Timeline Persuasão\")\n",
        "        print(\"  • Recomendações Copy\")\n",
        "        print(\"  • Dashboard Principal (atualizada)\")\n",
        "\n",
        "        # Gerar relatórios complementares\n",
        "        gerar_relatorios_copywriting_individuais(dados_copywriting)\n",
        "\n",
        "        # Atualizar config\n",
        "        config[\"status_etapas\"][\"dashboard_copywriting_integrado\"] = True\n",
        "        config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "        with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        return dashboard_existente\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao atualizar dashboard: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "def verificar_prerequisito_etapa(etapa):\n",
        "    \"\"\"Verifica se uma etapa foi executada\"\"\"\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "\n",
        "    if not os.path.exists(config_path):\n",
        "        print(f\"❌ Arquivo de configuração não encontrado: {config_path}\")\n",
        "        return False, None\n",
        "\n",
        "    try:\n",
        "        with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "        if not config.get(\"status_etapas\", {}).get(etapa, False):\n",
        "            print(f\"❌ Pré-requisito não atendido: {etapa}\")\n",
        "            print(\"Execute primeiro a célula correspondente.\")\n",
        "            return False, None\n",
        "\n",
        "        return True, config\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao verificar pré-requisitos: {e}\")\n",
        "        return False, None\n",
        "\n",
        "def carregar_dados_copywriting():\n",
        "    \"\"\"Carrega dados de copywriting e outros dados necessários\"\"\"\n",
        "    print(\"  📊 Carregando dados de copywriting...\")\n",
        "\n",
        "    try:\n",
        "        # Dados de copywriting\n",
        "        copywriting_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_copywriting_completas.json\")\n",
        "        with open(copywriting_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            copywriting_data = json.load(f)\n",
        "\n",
        "        # Dados de legendas\n",
        "        legendas_path = os.path.join(PASTA_TRABALHO, \"dados\", \"legendas_geradas.json\")\n",
        "        with open(legendas_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            legendas_data = json.load(f)\n",
        "\n",
        "        # Tentar carregar outros dados (podem não existir ainda)\n",
        "        outros_dados = {}\n",
        "\n",
        "        try:\n",
        "            padroes_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_padroes_completas.json\")\n",
        "            with open(padroes_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                outros_dados[\"padroes\"] = json.load(f)\n",
        "        except:\n",
        "            outros_dados[\"padroes\"] = []\n",
        "\n",
        "        try:\n",
        "            videos_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_completos.json\")\n",
        "            with open(videos_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                outros_dados[\"videos\"] = json.load(f)\n",
        "        except:\n",
        "            outros_dados[\"videos\"] = []\n",
        "\n",
        "        print(f\"  ✅ Dados carregados: {len(copywriting_data)} análises de copywriting\")\n",
        "\n",
        "        return {\n",
        "            \"copywriting\": copywriting_data,\n",
        "            \"legendas\": legendas_data,\n",
        "            **outros_dados\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Erro ao carregar dados de copywriting: {e}\")\n",
        "        return None\n",
        "\n",
        "def adicionar_aba_copywriting_estrategico(wb, dados):\n",
        "    \"\"\"Adiciona aba principal de análise de copywriting\"\"\"\n",
        "    # Criar nova aba\n",
        "    ws = wb.create_sheet(\"Copywriting Estratégico\")\n",
        "\n",
        "    # Título principal\n",
        "    ws.merge_cells(\"A1:H1\")\n",
        "    titulo = ws[\"A1\"]\n",
        "    titulo.value = \"ANÁLISE ESTRATÉGICA DE COPYWRITING - ENGENHARIA REVERSA\"\n",
        "    titulo.fill = PatternFill(start_color=\"1F4E79\", end_color=\"1F4E79\", fill_type=\"solid\")\n",
        "    titulo.font = Font(color=\"FFFFFF\", bold=True, size=14)\n",
        "    titulo.alignment = Alignment(horizontal=\"center\")\n",
        "\n",
        "    row = 3\n",
        "\n",
        "    # Métricas executivas\n",
        "    ws[f\"A{row}\"] = \"MÉTRICAS EXECUTIVAS DE COPYWRITING\"\n",
        "    ws[f\"A{row}\"].font = Font(bold=True, size=12, color=\"C5504B\")\n",
        "    row += 2\n",
        "\n",
        "    # Calcular métricas\n",
        "    videos_copy = dados[\"copywriting\"]\n",
        "\n",
        "    if videos_copy:\n",
        "        # Score médio\n",
        "        scores = [v.get(\"score_persuasao\", 0) for v in videos_copy]\n",
        "        score_medio = sum(scores) / len(scores) if scores else 0\n",
        "\n",
        "        # Contadores\n",
        "        total_ganchos = sum(len(v.get(\"ganchos_detectados\", {})) for v in videos_copy)\n",
        "        total_gatilhos = sum(len(v.get(\"gatilhos_mentais_detectados\", {})) for v in videos_copy)\n",
        "        total_ctas = sum(len(v.get(\"ctas_detectados\", {})) for v in videos_copy)\n",
        "        videos_sem_cta = len([v for v in videos_copy if not v.get(\"ctas_detectados\")])\n",
        "        total_templates = sum(len(v.get(\"templates_identificados\", [])) for v in videos_copy)\n",
        "\n",
        "        # Exibir métricas\n",
        "        metricas = [\n",
        "            (\"Score Persuasão Médio:\", f\"{score_medio:.1f}/100\", \"Meta: 70+ para alta conversão\"),\n",
        "            (\"Vídeos Analisados:\", len(videos_copy), \"Base completa da análise\"),\n",
        "            (\"Total de Ganchos:\", total_ganchos, f\"Média: {total_ganchos/len(videos_copy):.1f} por vídeo\"),\n",
        "            (\"Total de Gatilhos:\", total_gatilhos, f\"Média: {total_gatilhos/len(videos_copy):.1f} por vídeo\"),\n",
        "            (\"Total de CTAs:\", total_ctas, f\"Média: {total_ctas/len(videos_copy):.1f} por vídeo\"),\n",
        "            (\"🚨 Vídeos sem CTA:\", videos_sem_cta, \"CRÍTICO: Implementar imediatamente\" if videos_sem_cta > 0 else \"✅ Todos têm CTA\"),\n",
        "            (\"Templates Identificados:\", total_templates, \"Estruturas replicáveis encontradas\")\n",
        "        ]\n",
        "\n",
        "        for metrica, valor, descricao in metricas:\n",
        "            ws[f\"A{row}\"] = metrica\n",
        "            ws[f\"B{row}\"] = valor\n",
        "            ws[f\"C{row}\"] = descricao\n",
        "\n",
        "            ws[f\"A{row}\"].font = Font(bold=True)\n",
        "            if \"🚨\" in metrica and videos_sem_cta > 0:\n",
        "                ws[f\"B{row}\"].font = Font(bold=True, color=\"FF0000\")\n",
        "            elif isinstance(valor, (int, float)) and valor > 0:\n",
        "                ws[f\"B{row}\"].font = Font(bold=True, color=\"70AD47\")\n",
        "\n",
        "            row += 1\n",
        "\n",
        "        row += 2\n",
        "\n",
        "        # Ranking de performance\n",
        "        ws[f\"A{row}\"] = \"🏆 RANKING DE PERFORMANCE POR SCORE DE PERSUASÃO\"\n",
        "        ws[f\"A{row}\"].font = Font(bold=True, size=12, color=\"1F4E79\")\n",
        "        row += 2\n",
        "\n",
        "        # Headers\n",
        "        headers = [\"Posição\", \"Vídeo ID\", \"Score\", \"Ganchos\", \"Gatilhos\", \"CTAs\", \"Status\"]\n",
        "        for col, header in enumerate(headers, 1):\n",
        "            cell = ws.cell(row=row, column=col)\n",
        "            cell.value = header\n",
        "            cell.font = Font(bold=True)\n",
        "            cell.fill = PatternFill(start_color=\"D9E2F3\", end_color=\"D9E2F3\", fill_type=\"solid\")\n",
        "        row += 1\n",
        "\n",
        "        # Top performers\n",
        "        top_videos = sorted(videos_copy, key=lambda x: x.get(\"score_persuasao\", 0), reverse=True)\n",
        "\n",
        "        for i, video in enumerate(top_videos, 1):\n",
        "            ws.cell(row=row, column=1, value=f\"{i}º\")\n",
        "            ws.cell(row=row, column=2, value=video[\"video_id\"])\n",
        "            ws.cell(row=row, column=3, value=f\"{video.get('score_persuasao', 0)}/100\")\n",
        "            ws.cell(row=row, column=4, value=len(video.get(\"ganchos_detectados\", {})))\n",
        "            ws.cell(row=row, column=5, value=len(video.get(\"gatilhos_mentais_detectados\", {})))\n",
        "            ws.cell(row=row, column=6, value=len(video.get(\"ctas_detectados\", {})))\n",
        "\n",
        "            # Status baseado no score\n",
        "            score = video.get(\"score_persuasao\", 0)\n",
        "            if score >= 70:\n",
        "                status = \"🟢 ÓTIMO\"\n",
        "                status_color = \"70AD47\"\n",
        "            elif score >= 50:\n",
        "                status = \"🟡 BOM\"\n",
        "                status_color = \"FFC000\"\n",
        "            else:\n",
        "                status = \"🔴 PRECISA OTIMIZAR\"\n",
        "                status_color = \"C5504B\"\n",
        "\n",
        "            cell_status = ws.cell(row=row, column=7, value=status)\n",
        "            cell_status.font = Font(color=status_color, bold=True)\n",
        "\n",
        "            # Destacar top 3\n",
        "            if i <= 3:\n",
        "                for col in range(1, 8):\n",
        "                    ws.cell(row=row, column=col).fill = PatternFill(start_color=\"FFF2CC\", end_color=\"FFF2CC\", fill_type=\"solid\")\n",
        "\n",
        "            row += 1\n",
        "\n",
        "    # Ajustar larguras das colunas\n",
        "    for col, width in [(\"A\", 25), (\"B\", 15), (\"C\", 40), (\"D\", 10), (\"E\", 10), (\"F\", 10), (\"G\", 20), (\"H\", 15)]:\n",
        "        ws.column_dimensions[col].width = width\n",
        "\n",
        "def adicionar_aba_templates_copy(wb, dados):\n",
        "    \"\"\"Adiciona aba de templates replicáveis\"\"\"\n",
        "    ws = wb.create_sheet(\"Templates Replicáveis\")\n",
        "\n",
        "    # Título\n",
        "    ws.merge_cells(\"A1:F1\")\n",
        "    titulo = ws[\"A1\"]\n",
        "    titulo.value = \"TEMPLATES E ESTRUTURAS REPLICÁVEIS DE COPYWRITING\"\n",
        "    titulo.fill = PatternFill(start_color=\"70AD47\", end_color=\"70AD47\", fill_type=\"solid\")\n",
        "    titulo.font = Font(color=\"FFFFFF\", bold=True, size=14)\n",
        "    titulo.alignment = Alignment(horizontal=\"center\")\n",
        "\n",
        "    row = 3\n",
        "\n",
        "    # Coletar todos os templates\n",
        "    todos_templates = []\n",
        "    for video in dados[\"copywriting\"]:\n",
        "        templates = video.get(\"templates_identificados\", [])\n",
        "        for template in templates:\n",
        "            template[\"video_id\"] = video[\"video_id\"]\n",
        "            todos_templates.append(template)\n",
        "\n",
        "    if todos_templates:\n",
        "        # Agrupar templates por tipo\n",
        "        templates_agrupados = {}\n",
        "        for template in todos_templates:\n",
        "            nome = template[\"nome\"]\n",
        "            if nome not in templates_agrupados:\n",
        "                templates_agrupados[nome] = {\n",
        "                    \"estrutura\": template[\"estrutura\"],\n",
        "                    \"eficacia\": template[\"eficacia\"],\n",
        "                    \"uso_recomendado\": template[\"uso_recomendado\"],\n",
        "                    \"videos_exemplo\": []\n",
        "                }\n",
        "            templates_agrupados[nome][\"videos_exemplo\"].append(template[\"video_id\"])\n",
        "\n",
        "        # Exibir templates\n",
        "        for nome_template, dados_template in templates_agrupados.items():\n",
        "            ws.merge_cells(f\"A{row}:F{row}\")\n",
        "            template_header = ws[f\"A{row}\"]\n",
        "            template_header.value = f\"📋 TEMPLATE: {nome_template.replace('_', ' ')}\"\n",
        "            template_header.fill = PatternFill(start_color=\"E2EFDA\", end_color=\"E2EFDA\", fill_type=\"solid\")\n",
        "            template_header.font = Font(bold=True, size=11)\n",
        "            row += 1\n",
        "\n",
        "            ws[f\"A{row}\"] = \"Estrutura:\"\n",
        "            ws[f\"B{row}\"] = dados_template[\"estrutura\"]\n",
        "            ws[f\"A{row}\"].font = Font(bold=True)\n",
        "            row += 1\n",
        "\n",
        "            ws[f\"A{row}\"] = \"Eficácia:\"\n",
        "            ws[f\"B{row}\"] = dados_template[\"eficacia\"]\n",
        "            ws[f\"A{row}\"].font = Font(bold=True)\n",
        "            if dados_template[\"eficacia\"] == \"MUITO ALTA\":\n",
        "                ws[f\"B{row}\"].font = Font(color=\"70AD47\", bold=True)\n",
        "            elif dados_template[\"eficacia\"] == \"ALTA\":\n",
        "                ws[f\"B{row}\"].font = Font(color=\"C5504B\", bold=True)\n",
        "            row += 1\n",
        "\n",
        "            ws[f\"A{row}\"] = \"Uso Recomendado:\"\n",
        "            ws[f\"B{row}\"] = dados_template[\"uso_recomendado\"]\n",
        "            ws[f\"A{row}\"].font = Font(bold=True)\n",
        "            row += 1\n",
        "\n",
        "            ws[f\"A{row}\"] = \"Vídeos Exemplo:\"\n",
        "            ws[f\"B{row}\"] = \", \".join(dados_template[\"videos_exemplo\"][:3])\n",
        "            ws[f\"A{row}\"].font = Font(bold=True)\n",
        "            row += 2\n",
        "\n",
        "    # Ajustar larguras\n",
        "    for col, width in [(\"A\", 20), (\"B\", 50), (\"C\", 15), (\"D\", 15), (\"E\", 15), (\"F\", 15)]:\n",
        "        ws.column_dimensions[col].width = width\n",
        "\n",
        "def adicionar_aba_timeline_copy(wb, dados):\n",
        "    \"\"\"Adiciona aba de timeline de elementos persuasivos\"\"\"\n",
        "    ws = wb.create_sheet(\"Timeline Persuasão\")\n",
        "\n",
        "    # Título\n",
        "    ws.merge_cells(\"A1:G1\")\n",
        "    titulo = ws[\"A1\"]\n",
        "    titulo.value = \"TIMELINE DE ELEMENTOS PERSUASIVOS - ANÁLISE TEMPORAL\"\n",
        "    titulo.fill = PatternFill(start_color=\"FFC000\", end_color=\"FFC000\", fill_type=\"solid\")\n",
        "    titulo.font = Font(color=\"FFFFFF\", bold=True, size=14)\n",
        "    titulo.alignment = Alignment(horizontal=\"center\")\n",
        "\n",
        "    row = 3\n",
        "\n",
        "    # Para cada vídeo, mostrar timeline\n",
        "    for video in dados[\"copywriting\"]:\n",
        "        video_id = video[\"video_id\"]\n",
        "\n",
        "        ws[f\"A{row}\"] = f\"📹 VÍDEO: {video_id}\"\n",
        "        ws[f\"A{row}\"].font = Font(bold=True, size=11, color=\"1F4E79\")\n",
        "        row += 2\n",
        "\n",
        "        # Headers da timeline\n",
        "        headers = [\"Tempo\", \"Minuto\", \"Segundo\", \"Elemento\", \"Posição\", \"Impacto\", \"Análise\"]\n",
        "        for col, header in enumerate(headers, 1):\n",
        "            cell = ws.cell(row=row, column=col)\n",
        "            cell.value = header\n",
        "            cell.font = Font(bold=True)\n",
        "            cell.fill = PatternFill(start_color=\"F2F2F2\", end_color=\"F2F2F2\", fill_type=\"solid\")\n",
        "        row += 1\n",
        "\n",
        "        # Coletar todos os elementos temporais\n",
        "        elementos_temporais = []\n",
        "\n",
        "        # Ganchos\n",
        "        for tipo, dados in video.get(\"ganchos_detectados\", {}).items():\n",
        "            for timestamp in dados.get(\"timestamps\", []):\n",
        "                elementos_temporais.append({\n",
        "                    \"categoria\": \"GANCHO\",\n",
        "                    \"tipo\": tipo,\n",
        "                    \"minuto\": timestamp[\"minuto\"],\n",
        "                    \"segundo\": timestamp[\"segundo\"],\n",
        "                    \"contexto\": timestamp[\"texto_contexto\"]\n",
        "                })\n",
        "\n",
        "        # Gatilhos\n",
        "        for tipo, dados in video.get(\"gatilhos_mentais_detectados\", {}).items():\n",
        "            for timestamp in dados.get(\"timestamps\", []):\n",
        "                elementos_temporais.append({\n",
        "                    \"categoria\": \"GATILHO\",\n",
        "                    \"tipo\": tipo,\n",
        "                    \"minuto\": timestamp[\"minuto\"],\n",
        "                    \"segundo\": timestamp[\"segundo\"],\n",
        "                    \"contexto\": timestamp[\"texto_contexto\"]\n",
        "                })\n",
        "\n",
        "        # CTAs\n",
        "        for tipo, dados in video.get(\"ctas_detectados\", {}).items():\n",
        "            for timestamp in dados.get(\"timestamps\", []):\n",
        "                elementos_temporais.append({\n",
        "                    \"categoria\": \"CTA\",\n",
        "                    \"tipo\": tipo,\n",
        "                    \"minuto\": timestamp[\"minuto\"],\n",
        "                    \"segundo\": timestamp[\"segundo\"],\n",
        "                    \"contexto\": timestamp[\"texto_contexto\"]\n",
        "                })\n",
        "\n",
        "        # Ordenar por tempo\n",
        "        elementos_temporais.sort(key=lambda x: (x[\"minuto\"], x[\"segundo\"]))\n",
        "\n",
        "        # Exibir elementos\n",
        "        if elementos_temporais:\n",
        "            for elemento in elementos_temporais:\n",
        "                ws.cell(row=row, column=1, value=f\"{elemento['minuto']:02d}:{elemento['segundo']:02d}\")\n",
        "                ws.cell(row=row, column=2, value=elemento[\"minuto\"])\n",
        "                ws.cell(row=row, column=3, value=elemento[\"segundo\"])\n",
        "                ws.cell(row=row, column=4, value=f\"{elemento['categoria']}: {elemento['tipo']}\")\n",
        "\n",
        "                # Análise de posição\n",
        "                total_segundos = elemento[\"minuto\"] * 60 + elemento[\"segundo\"]\n",
        "                if total_segundos <= 10:\n",
        "                    posicao = \"ABERTURA\"\n",
        "                    posicao_color = \"70AD47\"\n",
        "                elif total_segundos <= 20:\n",
        "                    posicao = \"MEIO\"\n",
        "                    posicao_color = \"FFC000\"\n",
        "                else:\n",
        "                    posicao = \"FINAL\"\n",
        "                    posicao_color = \"C5504B\"\n",
        "\n",
        "                cell_pos = ws.cell(row=row, column=5, value=posicao)\n",
        "                cell_pos.font = Font(color=posicao_color, bold=True)\n",
        "\n",
        "                # Análise de impacto\n",
        "                impacto = analisar_impacto_elemento(elemento[\"categoria\"], posicao)\n",
        "                ws.cell(row=row, column=6, value=impacto[\"score\"])\n",
        "                ws.cell(row=row, column=7, value=impacto[\"analise\"])\n",
        "\n",
        "                if impacto[\"score\"] == \"ALTO\":\n",
        "                    ws.cell(row=row, column=6).font = Font(color=\"70AD47\", bold=True)\n",
        "                elif impacto[\"score\"] == \"BAIXO\":\n",
        "                    ws.cell(row=row, column=6).font = Font(color=\"C5504B\", bold=True)\n",
        "\n",
        "                row += 1\n",
        "        else:\n",
        "            ws.cell(row=row, column=1, value=\"Nenhum elemento temporal mapeado\")\n",
        "            row += 1\n",
        "\n",
        "        row += 2\n",
        "\n",
        "    # Ajustar larguras\n",
        "    for col, width in [(\"A\", 8), (\"B\", 10), (\"C\", 15), (\"D\", 30), (\"E\", 12), (\"F\", 8), (\"G\", 25)]:\n",
        "        ws.column_dimensions[col].width = width\n",
        "\n",
        "def analisar_impacto_elemento(categoria, posicao):\n",
        "    \"\"\"Analisa o impacto de um elemento baseado na posição\"\"\"\n",
        "    impactos = {\n",
        "        (\"GANCHO\", \"ABERTURA\"): {\"score\": \"ALTO\", \"analise\": \"Ideal para capturar atenção\"},\n",
        "        (\"GANCHO\", \"MEIO\"): {\"score\": \"MÉDIO\", \"analise\": \"Melhor no início\"},\n",
        "        (\"GANCHO\", \"FINAL\"): {\"score\": \"BAIXO\", \"analise\": \"Reposicionar para abertura\"},\n",
        "        (\"GATILHO\", \"ABERTURA\"): {\"score\": \"MÉDIO\", \"analise\": \"Bom para credibilidade\"},\n",
        "        (\"GATILHO\", \"MEIO\"): {\"score\": \"ALTO\", \"analise\": \"Posição ideal para persuasão\"},\n",
        "        (\"GATILHO\", \"FINAL\"): {\"score\": \"MÉDIO\", \"analise\": \"Reforça decisão\"},\n",
        "        (\"CTA\", \"ABERTURA\"): {\"score\": \"BAIXO\", \"analise\": \"Muito cedo, construir valor primeiro\"},\n",
        "        (\"CTA\", \"MEIO\"): {\"score\": \"MÉDIO\", \"analise\": \"Considerar mover para final\"},\n",
        "        (\"CTA\", \"FINAL\"): {\"score\": \"ALTO\", \"analise\": \"Posicionamento ideal\"}\n",
        "    }\n",
        "\n",
        "    return impactos.get((categoria, posicao), {\"score\": \"MÉDIO\", \"analise\": \"Analisar contexto específico\"})\n",
        "\n",
        "def adicionar_aba_recomendacoes_copy(wb, dados):\n",
        "    \"\"\"Adiciona aba de recomendações estratégicas consolidadas\"\"\"\n",
        "    ws = wb.create_sheet(\"Recomendações Copy\")\n",
        "\n",
        "    # Título\n",
        "    ws.merge_cells(\"A1:F1\")\n",
        "    titulo = ws[\"A1\"]\n",
        "    titulo.value = \"RECOMENDAÇÕES ESTRATÉGICAS DE COPYWRITING - PLANO DE AÇÃO\"\n",
        "    titulo.fill = PatternFill(start_color=\"C5504B\", end_color=\"C5504B\", fill_type=\"solid\")\n",
        "    titulo.font = Font(color=\"FFFFFF\", bold=True, size=14)\n",
        "    titulo.alignment = Alignment(horizontal=\"center\")\n",
        "\n",
        "    row = 3\n",
        "\n",
        "    # Consolidar recomendações por prioridade\n",
        "    todas_recomendacoes = []\n",
        "    for video in dados[\"copywriting\"]:\n",
        "        recomendacoes_video = video.get(\"recomendacoes_estrategicas\", [])\n",
        "        for rec in recomendacoes_video:\n",
        "            rec[\"video_id\"] = video[\"video_id\"]\n",
        "            todas_recomendacoes.append(rec)\n",
        "\n",
        "    # Agrupar por prioridade\n",
        "    recomendacoes_por_prioridade = {\n",
        "        \"CRÍTICA\": [],\n",
        "        \"ALTA\": [],\n",
        "        \"MÉDIA\": []\n",
        "    }\n",
        "\n",
        "    for rec in todas_recomendacoes:\n",
        "        prioridade = rec.get(\"prioridade\", \"MÉDIA\")\n",
        "        if prioridade in recomendacoes_por_prioridade:\n",
        "            recomendacoes_por_prioridade[prioridade].append(rec)\n",
        "\n",
        "    # Exibir por prioridade\n",
        "    for prioridade in [\"CRÍTICA\", \"ALTA\", \"MÉDIA\"]:\n",
        "        if not recomendacoes_por_prioridade[prioridade]:\n",
        "            continue\n",
        "\n",
        "        ws[f\"A{row}\"] = f\"🚨 PRIORIDADE {prioridade}\"\n",
        "        if prioridade == \"CRÍTICA\":\n",
        "            ws[f\"A{row}\"].font = Font(color=\"FF0000\", bold=True, size=12)\n",
        "        elif prioridade == \"ALTA\":\n",
        "            ws[f\"A{row}\"].font = Font(color=\"C5504B\", bold=True, size=12)\n",
        "        else:\n",
        "            ws[f\"A{row}\"].font = Font(color=\"FFC000\", bold=True, size=12)\n",
        "\n",
        "        row += 2\n",
        "\n",
        "        # Headers\n",
        "        headers = [\"Categoria\", \"Recomendação\", \"Vídeos Afetados\", \"Ação Sugerida\"]\n",
        "        for col, header in enumerate(headers, 1):\n",
        "            cell = ws.cell(row=row, column=col)\n",
        "            cell.value = header\n",
        "            cell.font = Font(bold=True)\n",
        "            cell.fill = PatternFill(start_color=\"F2F2F2\", end_color=\"F2F2F2\", fill_type=\"solid\")\n",
        "        row += 1\n",
        "\n",
        "        # Agrupar recomendações similares da mesma prioridade\n",
        "        grupos = {}\n",
        "        for rec in recomendacoes_por_prioridade[prioridade]:\n",
        "            categoria = rec[\"categoria\"]\n",
        "            if categoria not in grupos:\n",
        "                grupos[categoria] = {\n",
        "                    \"recomendacao\": rec[\"recomendacao\"],\n",
        "                    \"videos\": [],\n",
        "                    \"acao\": gerar_acao_especifica(categoria)\n",
        "                }\n",
        "            grupos[categoria][\"videos\"].append(rec[\"video_id\"])\n",
        "\n",
        "        for categoria, dados_grupo in grupos.items():\n",
        "            ws.cell(row=row, column=1, value=categoria)\n",
        "            ws.cell(row=row, column=2, value=dados_grupo[\"recomendacao\"])\n",
        "            ws.cell(row=row, column=3, value=f\"{len(dados_grupo['videos'])} vídeo(s)\")\n",
        "            ws.cell(row=row, column=4, value=dados_grupo[\"acao\"])\n",
        "            row += 1\n",
        "\n",
        "        row += 2\n",
        "\n",
        "    # Ajustar larguras\n",
        "    for col, width in [(\"A\", 20), (\"B\", 40), (\"C\", 15), (\"D\", 30), (\"E\", 15), (\"F\", 15)]:\n",
        "        ws.column_dimensions[col].width = width\n",
        "\n",
        "def gerar_acao_especifica(categoria):\n",
        "    \"\"\"Gera ação específica baseada na categoria da recomendação\"\"\"\n",
        "    acoes = {\n",
        "        \"GANCHOS\": \"Revisar primeiros 5 segundos e adicionar pergunta ou curiosidade\",\n",
        "        \"GATILHOS\": \"Incorporar elementos de autoridade, prova social ou reciprocidade\",\n",
        "        \"CTA\": \"Adicionar call-to-action claro nos últimos 3-5 segundos\",\n",
        "        \"ESTRUTURA\": \"Aplicar template identificado mais próximo do nicho\",\n",
        "        \"PERSUASÃO\": \"Combinar múltiplos elementos persuasivos em sequência lógica\"\n",
        "    }\n",
        "    return acoes.get(categoria, \"Revisar e otimizar elementos específicos mencionados\")\n",
        "\n",
        "def atualizar_aba_principal_com_copy(wb, dados):\n",
        "    \"\"\"Atualiza a aba principal existente com métricas de copywriting\"\"\"\n",
        "    # Tentar encontrar aba principal (pode ter nomes diferentes)\n",
        "    aba_principal = None\n",
        "    possiveis_nomes = [\"Dashboard Principal\", \"Executive Summary\", \"Summary\", \"Principal\"]\n",
        "\n",
        "    for nome in wb.sheetnames:\n",
        "        if any(possivel in nome for possivel in possiveis_nomes):\n",
        "            aba_principal = wb[nome]\n",
        "            break\n",
        "\n",
        "    if not aba_principal:\n",
        "        # Se não encontrou, usar a primeira aba\n",
        "        aba_principal = wb.worksheets[0]\n",
        "\n",
        "    # Encontrar próxima linha vazia para adicionar seção de copywriting\n",
        "    next_row = 1\n",
        "    for row in range(1, 100):\n",
        "        if aba_principal[f\"A{row}\"].value is None:\n",
        "            next_row = row\n",
        "            break\n",
        "\n",
        "    # Adicionar seção de copywriting\n",
        "    # Título da seção\n",
        "    aba_principal.merge_cells(f\"A{next_row}:H{next_row}\")\n",
        "    titulo_copy = aba_principal[f\"A{next_row}\"]\n",
        "    titulo_copy.value = \"📝 ANÁLISE DE COPYWRITING - RESUMO EXECUTIVO\"\n",
        "    titulo_copy.fill = PatternFill(start_color=\"7030A0\", end_color=\"7030A0\", fill_type=\"solid\")\n",
        "    titulo_copy.font = Font(color=\"FFFFFF\", bold=True, size=12)\n",
        "    next_row += 2\n",
        "\n",
        "    # Métricas resumidas\n",
        "    videos_copy = dados[\"copywriting\"]\n",
        "\n",
        "    if videos_copy:\n",
        "        scores = [v.get(\"score_persuasao\", 0) for v in videos_copy]\n",
        "        score_medio = sum(scores) / len(scores)\n",
        "        videos_sem_cta = len([v for v in videos_copy if not v.get(\"ctas_detectados\")])\n",
        "        templates_total = sum(len(v.get(\"templates_identificados\", [])) for v in videos_copy)\n",
        "\n",
        "        metricas_resumo = [\n",
        "            (\"Score de Persuasão Médio:\", f\"{score_medio:.1f}/100\"),\n",
        "            (\"Vídeos sem CTA:\", f\"{videos_sem_cta} (CRÍTICO)\" if videos_sem_cta > 0 else \"0 ✅\"),\n",
        "            (\"Templates Identificados:\", str(templates_total)),\n",
        "            (\"Status Geral:\", \"Otimização necessária\" if score_medio < 60 or videos_sem_cta > 0 else \"Performance boa\")\n",
        "        ]\n",
        "\n",
        "        for metrica, valor in metricas_resumo:\n",
        "            aba_principal[f\"A{next_row}\"] = metrica\n",
        "            aba_principal[f\"B{next_row}\"] = valor\n",
        "            aba_principal[f\"A{next_row}\"].font = Font(bold=True)\n",
        "\n",
        "            if \"CRÍTICO\" in valor:\n",
        "                aba_principal[f\"B{next_row}\"].font = Font(color=\"FF0000\", bold=True)\n",
        "            elif \"✅\" in valor:\n",
        "                aba_principal[f\"B{next_row}\"].font = Font(color=\"70AD47\", bold=True)\n",
        "\n",
        "            next_row += 1\n",
        "\n",
        "    else:\n",
        "        aba_principal[f\"A{next_row}\"] = \"⚠️ Execute a análise de copywriting (Célula 2.4) para ver métricas\"\n",
        "        aba_principal[f\"A{next_row}\"].font = Font(color=\"FFC000\", bold=True)\n",
        "\n",
        "def gerar_relatorios_copywriting_individuais(dados):\n",
        "    \"\"\"Gera relatórios individuais de texto para cada vídeo\"\"\"\n",
        "    print(\"  📄 Gerando relatórios individuais de copywriting...\")\n",
        "\n",
        "    pasta_relatorios = os.path.join(PASTA_TRABALHO, \"relatorios_copywriting\")\n",
        "    os.makedirs(pasta_relatorios, exist_ok=True)\n",
        "\n",
        "    for video_copy in dados[\"copywriting\"]:\n",
        "        video_id = video_copy[\"video_id\"]\n",
        "\n",
        "        relatorio_path = os.path.join(pasta_relatorios, f\"{video_id}_copywriting_completo.txt\")\n",
        "\n",
        "        with open(relatorio_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"=\"*60 + \"\\n\")\n",
        "            f.write(\"RELATÓRIO COMPLETO DE ANÁLISE DE COPYWRITING\\n\")\n",
        "            f.write(\"=\"*60 + \"\\n\\n\")\n",
        "\n",
        "            f.write(f\"📹 Vídeo ID: {video_id}\\n\")\n",
        "            f.write(f\"🎯 Score de Persuasão: {video_copy.get('score_persuasao', 0)}/100\\n\")\n",
        "            f.write(f\"📝 Total de Palavras: {video_copy.get('total_palavras', 0)}\\n\\n\")\n",
        "\n",
        "            # Texto completo\n",
        "            f.write(\"TRANSCRIÇÃO COMPLETA:\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            f.write(video_copy.get(\"texto_completo\", \"Transcrição não disponível\") + \"\\n\\n\")\n",
        "\n",
        "            # Ganchos\n",
        "            f.write(\"🎣 GANCHOS DETECTADOS:\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            ganchos = video_copy.get(\"ganchos_detectados\", {})\n",
        "            if ganchos:\n",
        "                for tipo, dados in ganchos.items():\n",
        "                    f.write(f\"• {tipo.upper()}: {dados['count']} ocorrências\\n\")\n",
        "                    f.write(f\"  Exemplos: {', '.join(dados['exemplos'])}\\n\")\n",
        "            else:\n",
        "                f.write(\"Nenhum gancho detectado.\\n\")\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "            # Gatilhos\n",
        "            f.write(\"🧠 GATILHOS MENTAIS DETECTADOS:\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            gatilhos = video_copy.get(\"gatilhos_mentais_detectados\", {})\n",
        "            if gatilhos:\n",
        "                for tipo, dados in gatilhos.items():\n",
        "                    f.write(f\"• {tipo.upper()}: {dados['count']} ocorrências\\n\")\n",
        "                    f.write(f\"  Exemplos: {', '.join(dados['exemplos'])}\\n\")\n",
        "            else:\n",
        "                f.write(\"Nenhum gatilho mental detectado.\\n\")\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "            # CTAs\n",
        "            f.write(\"📢 CALLS-TO-ACTION DETECTADOS:\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            ctas = video_copy.get(\"ctas_detectados\", {})\n",
        "            if ctas:\n",
        "                for tipo, dados in ctas.items():\n",
        "                    f.write(f\"• {tipo.upper()}: {dados['count']} ocorrências\\n\")\n",
        "                    f.write(f\"  Exemplos: {', '.join(dados['exemplos'])}\\n\")\n",
        "            else:\n",
        "                f.write(\"Nenhum CTA detectado.\\n\")\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "            # Recomendações\n",
        "            f.write(\"💡 RECOMENDAÇÕES ESTRATÉGICAS:\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            recomendacoes = video_copy.get(\"recomendacoes_estrategicas\", [])\n",
        "            if recomendacoes:\n",
        "                for rec in recomendacoes:\n",
        "                    f.write(f\"• [{rec['prioridade']}] {rec['categoria']}: {rec['recomendacao']}\\n\")\n",
        "            else:\n",
        "                f.write(\"Nenhuma recomendação específica.\\n\")\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "            # Templates\n",
        "            f.write(\"📋 TEMPLATES IDENTIFICADOS:\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            templates = video_copy.get(\"templates_identificados\", [])\n",
        "            if templates:\n",
        "                for template in templates:\n",
        "                    f.write(f\"• {template['nome']}: {template['estrutura']}\\n\")\n",
        "                    f.write(f\"  Eficácia: {template['eficacia']}\\n\")\n",
        "                    f.write(f\"  Uso: {template['uso_recomendado']}\\n\\n\")\n",
        "            else:\n",
        "                f.write(\"Nenhum template específico identificado.\\n\")\n",
        "\n",
        "    print(f\"  ✅ Relatórios individuais gerados em: {pasta_relatorios}\")\n",
        "\n",
        "# Executar integração\n",
        "try:\n",
        "    integrar_copywriting_dashboard_existente()\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERRO de Execução: {type(e).__name__}: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ],
      "metadata": {
        "id": "6ixFPocx6m8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CÉLULA 4.3: INTEGRAÇÃO DE COPYWRITING NO DASHBOARD EXISTENTE\n",
        "# ============================================================================\n",
        "\n",
        "# Definir a variável global PASTA_TRABALHO se ainda não estiver definida\n",
        "# Certifique-se de que esta variável esteja definida corretamente em uma célula anterior (ex: Célula 1.2)\n",
        "# Exemplo: PASTA_TRABALHO = \"/content/drive/MyDrive/Videos Dona Done/_engenharia_reversa\"\n",
        "\n",
        "# Executar a função principal da Layer 4.3\n",
        "if 'PASTA_TRABALHO' in globals():\n",
        "    print(\"Iniciando a Layer 4.3: Integração de Copywriting no Dashboard...\")\n",
        "    integrar_copywriting_dashboard_existente()\n",
        "else:\n",
        "    print(\"ERRO: A variável PASTA_TRABALHO não está definida. Certifique-se de executar a Célula 1.2 ou equivalente.\")"
      ],
      "metadata": {
        "id": "fvmDo8Iw61G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# LAYER 5/6 — IA LOCAL + DASHBOARD HUMANIZADA (Fusão, sem consultas externas)\n",
        "# ============================================================\n",
        "\n",
        "# Instalar dependências (todas offline-friendly; Whisper usa pesos locais)\n",
        "!pip -q install faster-whisper==1.0.3 mediapipe==0.10.14 scikit-learn==1.5.1 openpyxl==3.1.2 xlsxwriter==3.2.0\n",
        "\n",
        "import os, re, json, cv2, numpy as np, pandas as pd\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from collections import Counter\n",
        "from sklearn.cluster import KMeans\n",
        "import mediapipe as mp\n",
        "from faster_whisper import WhisperModel\n",
        "from openpyxl import load_workbook, Workbook\n",
        "from openpyxl.utils import get_column_letter\n",
        "from openpyxl.styles import Font, Alignment, PatternFill\n",
        "\n",
        "# --------- Conexão com SEU notebook (usa as variáveis já definidas) ----------\n",
        "assert 'PASTA_TRABALHO' in globals(), \"PASTA_TRABALHO não está definido. Execute as células de configuração antes.\"\n",
        "\n",
        "# Fallback para OUTPUT_PATH se ainda não foi definido pelo seu fluxo\n",
        "if 'OUTPUT_PATH' not in globals():\n",
        "    OUTPUT_PATH = os.path.join(PASTA_TRABALHO, \"dashboard\", \"DASHBOARD_MASTER_EXECUTIVO_INTELIGENTE.xlsx\")\n",
        "    print(f\"⚠️ OUTPUT_PATH não estava definido, criei automático: {OUTPUT_PATH}\")\n",
        "\n",
        "AI_ASSETS_DIR = os.path.join(PASTA_TRABALHO, \"ai_insights\")\n",
        "os.makedirs(AI_ASSETS_DIR, exist_ok=True)\n",
        "\n",
        "# Pesos locais do Whisper (CTranslate2). Estrutura esperada:\n",
        "# PASTA_TRABALHO/modelos/whisper/tiny/ (coloque os arquivos do modelo aqui)\n",
        "WHISPER_LOCAL_DIR = os.path.join(PASTA_TRABALHO, \"modelos\", \"whisper\", \"tiny\")\n",
        "WHISPER_DEVICE = \"cuda\" if cv2.cuda.getCudaEnabledDeviceCount() > 0 else \"cpu\"\n",
        "WHISPER_COMPUTE = \"float16\" if WHISPER_DEVICE == \"cuda\" else \"int8\"\n",
        "\n",
        "# ============================================================\n",
        "# Utilitários de IA (OFFLINE)\n",
        "# ============================================================\n",
        "\n",
        "def ai_transcrever_offline(video_path, out_dir):\n",
        "    \"\"\"Transcreve com Whisper local se os pesos existirem; senão, pula com aviso.\"\"\"\n",
        "    try:\n",
        "        if not os.path.isdir(WHISPER_LOCAL_DIR):\n",
        "            print(f\"⚠️ Whisper OFFLINE não encontrado em {WHISPER_LOCAL_DIR}. Pulando transcrição.\")\n",
        "            return \"\"\n",
        "        model = WhisperModel(WHISPER_LOCAL_DIR, device=WHISPER_DEVICE, compute_type=WHISPER_COMPUTE)\n",
        "        # extrai wav 16k mono (sem internet)\n",
        "        audio_path = os.path.join(out_dir, \"audio_16k.wav\")\n",
        "        os.system(f'ffmpeg -y -i \"{video_path}\" -ac 1 -ar 16000 -vn \"{audio_path}\" -loglevel error')\n",
        "        segments, _ = model.transcribe(audio_path, language=\"pt\", vad_filter=True, vad_parameters={\"min_silence_duration_ms\": 500})\n",
        "        lines, srt_lines = [], []\n",
        "        for i, seg in enumerate(segments):\n",
        "            lines.append(seg.text.strip())\n",
        "            def ts(x):\n",
        "                h=int(x//3600); m=int((x%3600)//60); s=x%60\n",
        "                return f\"{h:02}:{m:02}:{s:06.3f}\".replace('.',',')\n",
        "            srt_lines.append(f\"{i+1}\\n{ts(seg.start)} --> {ts(seg.end)}\\n{seg.text.strip()}\\n\")\n",
        "        with open(os.path.join(out_dir,\"transcript.txt\"),\"w\",encoding=\"utf-8\") as f:\n",
        "            f.write(\" \".join(lines))\n",
        "        with open(os.path.join(out_dir,\"subtitles.srt\"),\"w\",encoding=\"utf-8\") as f:\n",
        "            f.write(\"\".join(srt_lines))\n",
        "        return \" \".join(lines)\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro no Whisper local: {e}. Pulando transcrição.\")\n",
        "        return \"\"\n",
        "\n",
        "def ai_keyframes_por_tempo(video_path, out_dir, intervalo_seg=2):\n",
        "    \"\"\"Extrai frames a cada N segundos para OCR, paleta e thumbs.\"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
        "    frame_interval = int(max(1, fps*intervalo_seg))\n",
        "    idx=0; frames=[]\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "        fno = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
        "        if fno % frame_interval == 0:\n",
        "            fp = os.path.join(out_dir, f\"frame_{idx:04d}.jpg\")\n",
        "            cv2.imwrite(fp, frame); frames.append(fp); idx+=1\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "def ai_ocr(frames):\n",
        "    \"\"\"OCR local em frames (Tesseract).\"\"\"\n",
        "    textos=[]\n",
        "    for fp in frames:\n",
        "        try:\n",
        "            txt = pytesseract.image_to_string(Image.open(fp), lang=\"por+eng\").strip()\n",
        "            if txt: textos.append(txt)\n",
        "        except:\n",
        "            pass\n",
        "    return textos\n",
        "\n",
        "def ai_paleta(frames, n=5):\n",
        "    \"\"\"Paleta dominante via KMeans sobre o primeiro frame (rápido e consistente).\"\"\"\n",
        "    if not frames: return []\n",
        "    img = Image.open(frames[0]).convert(\"RGB\").resize((256,256))\n",
        "    X = np.array(img).reshape(-1,3).astype(np.float32)\n",
        "    km = KMeans(n_clusters=n, n_init=3, random_state=42).fit(X)\n",
        "    return [\"#%02x%02x%02x\"%tuple(map(int,c)) for c in km.cluster_centers_]\n",
        "\n",
        "def ai_emocoes(video_path, sample_rate=15):\n",
        "    \"\"\"\n",
        "    Heurística leve com Mediapipe FaceMesh:\n",
        "    Marca 'surpresa' se boca muito aberta; senão 'neutro/sorriso'.\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fm = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n",
        "    emos=[]; frame_idx=0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "        if frame_idx % sample_rate == 0:\n",
        "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            res = fm.process(rgb)\n",
        "            if res.multi_face_landmarks:\n",
        "                for lm in res.multi_face_landmarks:\n",
        "                    mouth = lm.landmark[13].y - lm.landmark[14].y\n",
        "                    emos.append(\"surpresa\" if mouth>0.03 else \"neutro/sorriso\")\n",
        "        frame_idx+=1\n",
        "    cap.release()\n",
        "    return dict(Counter(emos)) if emos else {}\n",
        "\n",
        "def ai_hook_score(texto_transcrito, ocr_primeiros_frames):\n",
        "    \"\"\"Pontua o gancho nos ~3–5s iniciais via padrões simples (sem internet).\"\"\"\n",
        "    early = (texto_transcrito[:220] + \" \" + \" \".join(ocr_primeiros_frames[:2])).lower()\n",
        "    score=0\n",
        "    for pat in [r\"\\?\", r\"\\bcomo\\b\", r\"\\bnunca\\b\", r\"\\bsempre\\b\", r\"\\bem\\s+\\d+\\s+passos\\b\", r\"\\b\\d+\\b\"]:\n",
        "        if re.search(pat, early):\n",
        "            score += 16\n",
        "    return min(score, 100)\n",
        "\n",
        "def ai_templates_recomendacoes(hook, ocr_count, emoc):\n",
        "    \"\"\"Gera recomendações humanizadas + templates estratégicos.\"\"\"\n",
        "    recs=[]\n",
        "    if hook<50:\n",
        "        recs.append(\"Melhore o HOOK nos 3s: use pergunta direta ou número específico.\")\n",
        "    if ocr_count==0:\n",
        "        recs.append(\"Inclua texto na tela logo no início (quem assiste no mudo entende a promessa).\")\n",
        "    if \"surpresa\" in emoc:\n",
        "        recs.append(\"Use um frame de 'surpresa' como thumbnail para maior CTR.\")\n",
        "    if not recs:\n",
        "        recs.append(\"Boa base! Teste variações de abertura e CTA para escalar.\")\n",
        "\n",
        "    templates=[\n",
        "        (\"Hook — Pergunta\", \"Você sabia que [X]? Em [3 passos], você faz [Y]!\"),\n",
        "        (\"Hook — Número\", \"Em apenas [5 minutos], aprenda a [benefício prático].\"),\n",
        "        (\"Hook — Proibição\", \"Nunca faça [erro comum] se quiser [resultado].\"),\n",
        "        (\"CTA — Final\", \"Se curtiu, compartilhe e me siga pra ver a parte 2 🚀\"),\n",
        "    ]\n",
        "    return recs, templates\n",
        "\n",
        "# ============================================================\n",
        "# Núcleo: processa todos os vídeos já catalogados pelo seu notebook\n",
        "# (usa .../dados/metadados_completos.json)\n",
        "# ============================================================\n",
        "\n",
        "def processar_ai_insights():\n",
        "    metapath = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_completos.json\")\n",
        "    if not os.path.exists(metapath):\n",
        "        print(f\"❌ Não encontrei {metapath}. Rode suas etapas até gerar metadados antes.\")\n",
        "        return []\n",
        "    with open(metapath, \"r\", encoding=\"utf-8\") as f:\n",
        "        metadados = json.load(f)\n",
        "\n",
        "    relatorios = []\n",
        "    for i, meta in enumerate(metadados, 1):\n",
        "        video_id = meta.get(\"id\")\n",
        "        video_path = meta.get(\"caminho_completo\")\n",
        "        if not (video_id and video_path and os.path.exists(video_path)):\n",
        "            print(f\"[{i}/{len(metadados)}] Pulando {video_id} (path inválido).\")\n",
        "            continue\n",
        "\n",
        "        out_dir = os.path.join(AI_ASSETS_DIR, video_id)\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "        print(f\"[{i}/{len(metadados)}] IA → {video_id}\")\n",
        "\n",
        "        # 1) Transcrição (opcional/offline)\n",
        "        transcript = ai_transcrever_offline(video_path, out_dir)\n",
        "\n",
        "        # 2) Keyframes + OCR + Paleta\n",
        "        frames = ai_keyframes_por_tempo(video_path, out_dir, intervalo_seg=2)\n",
        "        ocr_texts = ai_ocr(frames)\n",
        "        palette = ai_paleta(frames, n=5)\n",
        "        # salvar thumbs básicos\n",
        "        for j, fp in enumerate(frames[:3]):\n",
        "            try:\n",
        "                Image.open(fp).save(os.path.join(out_dir, f\"thumb_{j}.jpg\"), quality=95)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # 3) Emoções faciais (heurística leve)\n",
        "        emotions = ai_emocoes(video_path, sample_rate=15)\n",
        "\n",
        "        # 4) Hook Score\n",
        "        hook = ai_hook_score(transcript, ocr_texts)\n",
        "\n",
        "        # 5) Recomendações + Templates\n",
        "        recs, templates = ai_templates_recomendacoes(hook, len(ocr_texts), emotions)\n",
        "\n",
        "        # Agrega relatório por vídeo\n",
        "        rep = {\n",
        "            \"video_id\": video_id,\n",
        "            \"nome_arquivo\": meta.get(\"nome_arquivo\"),\n",
        "            \"hook_score\": hook,\n",
        "            \"emocoes_predominantes\": emotions,\n",
        "            \"ocr_textos_count\": len(ocr_texts),\n",
        "            \"paleta_cores\": palette,\n",
        "            \"transcript_excerpt\": (transcript[:300] if transcript else \"\")\n",
        "        }\n",
        "        # Persistência por vídeo\n",
        "        with open(os.path.join(out_dir, \"ai_report.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(rep, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        # Para dashboard humanizada\n",
        "        rep[\"_recomendacoes\"] = recs\n",
        "        rep[\"_templates\"] = templates\n",
        "        relatorios.append(rep)\n",
        "\n",
        "    # Consolida JSON master\n",
        "    master_path = os.path.join(PASTA_TRABALHO, \"dados\", \"ai_insights_completos.json\")\n",
        "    with open(master_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(relatorios, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"\\n💾 AI insights consolidados: {master_path}\")\n",
        "    return relatorios\n",
        "\n",
        "# ============================================================\n",
        "# Dashboard em Excel (humanizada) — usa SEU OUTPUT_PATH\n",
        "# ============================================================\n",
        "\n",
        "def escrever_linha(ws, row, values, bold=False, wrap=False):\n",
        "    for col, val in enumerate(values, 1):\n",
        "        cell = ws.cell(row=row, column=col, value=val)\n",
        "        if bold: cell.font = Font(bold=True)\n",
        "        if wrap: cell.alignment = Alignment(wrap_text=True)\n",
        "\n",
        "def ajustar_larguras(ws, larguras):\n",
        "    for col_idx, width in enumerate(larguras, 1):\n",
        "        ws.column_dimensions[get_column_letter(col_idx)].width = width\n",
        "\n",
        "def atualizar_dashboard_humanizado(relatorios):\n",
        "    # Garante pasta do dashboard\n",
        "    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
        "    # Carrega workbook existente (do seu fluxo) ou cria novo\n",
        "    if os.path.exists(OUTPUT_PATH):\n",
        "        wb = load_workbook(OUTPUT_PATH)\n",
        "    else:\n",
        "        wb = Workbook()\n",
        "\n",
        "    # --- ABA 1: AI Insights (Resumo) ---\n",
        "    if \"AI Insights (Resumo)\" in wb.sheetnames:\n",
        "        del wb[\"AI Insights (Resumo)\"]\n",
        "    ws_resumo = wb.create_sheet(\"AI Insights (Resumo)\")\n",
        "\n",
        "    escrever_linha(ws_resumo, 1, [\"Vídeo\", \"Hook (0-100)\", \"Emoções\", \"OCR textos\", \"Paleta\", \"Trecho do Transcript\"], bold=True)\n",
        "    for i, r in enumerate(relatorios, start=2):\n",
        "        emo_k = \", \".join([f\"{k}:{v}\" for k,v in r[\"emocoes_predominantes\"].items()]) if r[\"emocoes_predominantes\"] else \"-\"\n",
        "        pal = \" \".join(r[\"paleta_cores\"]) if r[\"paleta_cores\"] else \"-\"\n",
        "        escrever_linha(ws_resumo, i, [\n",
        "            r.get(\"nome_arquivo\", r[\"video_id\"]),\n",
        "            r[\"hook_score\"],\n",
        "            emo_k,\n",
        "            r[\"ocr_textos_count\"],\n",
        "            pal,\n",
        "            r[\"transcript_excerpt\"]\n",
        "        ], wrap=True)\n",
        "    ajustar_larguras(ws_resumo, [36, 14, 28, 12, 28, 80])\n",
        "\n",
        "    # --- ABA 2: Recomendações (Humanizadas) ---\n",
        "    if \"Recomendações (Humanizadas)\" in wb.sheetnames:\n",
        "        del wb[\"Recomendações (Humanizadas)\"]\n",
        "    ws_recs = wb.create_sheet(\"Recomendações (Humanizadas)\")\n",
        "    escrever_linha(ws_recs, 1, [\"Vídeo\", \"Recomendações práticas\"], bold=True)\n",
        "    row = 2\n",
        "    for r in relatorios:\n",
        "        if r[\"_recomendacoes\"]:\n",
        "            escrever_linha(ws_recs, row, [r.get(\"nome_arquivo\", r[\"video_id\"]), \" • \" + \"\\n • \".join(r[\"_recomendacoes\"])], wrap=True)\n",
        "            row += 1\n",
        "    ajustar_larguras(ws_recs, [36, 100])\n",
        "\n",
        "    # --- ABA 3: Templates Estratégicos ---\n",
        "    if \"Templates (Estratégia)\" in wb.sheetnames:\n",
        "        del wb[\"Templates (Estratégia)\"]\n",
        "    ws_tpl = wb.create_sheet(\"Templates (Estratégia)\")\n",
        "    escrever_linha(ws_tpl, 1, [\"Tipo\", \"Template\"], bold=True)\n",
        "    # Deduplica templates\n",
        "    vistos=set(); row=2\n",
        "    for r in relatorios:\n",
        "        for tipo, tpl in r[\"_templates\"]:\n",
        "            key=(tipo, tpl)\n",
        "            if key in vistos:\n",
        "                continue\n",
        "            vistos.add(key)\n",
        "            escrever_linha(ws_tpl, row, [tipo, tpl], wrap=True); row+=1\n",
        "    ajustar_larguras(ws_tpl, [28, 100])\n",
        "\n",
        "    # Estiliza cabeçalho das abas\n",
        "    for nome in [\"AI Insights (Resumo)\", \"Recomendações (Humanizadas)\", \"Templates (Estratégia)\"]:\n",
        "        ws = wb[nome]\n",
        "        cell = ws.cell(row=1, column=1)\n",
        "        cell.font = Font(bold=True, size=14, color=\"FFFFFF\")\n",
        "        cell.fill = PatternFill(start_color=\"3F6AB3\", end_color=\"3F6AB3\", fill_type=\"solid\")\n",
        "\n",
        "    wb.save(OUTPUT_PATH)\n",
        "    print(f\"✅ Dashboard humanizada atualizada em: {OUTPUT_PATH}\")\n",
        "\n",
        "# ============================================================\n",
        "# EXECUÇÃO (chame após a Layer 4 do seu notebook)\n",
        "# ============================================================\n",
        "\n",
        "def rodar_layer_5_6_ai():\n",
        "    rel = processar_ai_insights()\n",
        "    if rel:\n",
        "        atualizar_dashboard_humanizado(rel)\n",
        "    else:\n",
        "        print(\"Sem relatórios para escrever no Excel. Verifique se metadados_completos.json existe.\")\n",
        "\n",
        "# Exemplo de chamada:\n",
        "# rodar_layer_5_6_ai()\n"
      ],
      "metadata": {
        "id": "Ns9Xl0Uk7_Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rodar_layer_5_6_ai()"
      ],
      "metadata": {
        "id": "v_QVY6i-8qLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# LAYER 7 — IA ONLINE (FREE) • Análise semântica avançada\n",
        "# - Sem likes / comentários / views.\n",
        "# - Usa Hugging Face Inference API (grátis com token).\n",
        "# - Respeita PASTA_TRABALHO e OUTPUT_PATH do seu projeto.\n",
        "# ============================================================\n",
        "\n",
        "!pip -q install openpyxl==3.1.2 requests==2.32.3\n",
        "\n",
        "import os, re, json, time, math\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Any\n",
        "from openpyxl import load_workbook, Workbook\n",
        "from openpyxl.utils import get_column_letter\n",
        "from openpyxl.styles import Font, Alignment, PatternFill\n",
        "\n",
        "# ---------- Conexão com seu notebook ----------\n",
        "assert 'PASTA_TRABALHO' in globals(), \"PASTA_TRABALHO não está definido. Rode as células de configuração.\"\n",
        "if 'OUTPUT_PATH' not in globals():\n",
        "    OUTPUT_PATH = os.path.join(PASTA_TRABALHO, \"dashboard\", \"DASHBOARD_MASTER_EXECUTIVO_INTELIGENTE.xlsx\")\n",
        "    print(f\"⚠️ OUTPUT_PATH não estava definido; criando automático: {OUTPUT_PATH}\")\n",
        "\n",
        "DADOS_DIR = os.path.join(PASTA_TRABALHO, \"dados\")\n",
        "AI_ONLINE_DIR = os.path.join(PASTA_TRABALHO, \"ai_online\")\n",
        "os.makedirs(DADOS_DIR, exist_ok=True)\n",
        "os.makedirs(AI_ONLINE_DIR, exist_ok=True)\n",
        "\n",
        "META_PATH = os.path.join(DADOS_DIR, \"metadados_completos.json\")\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = \"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\"   # coloque seu token\n",
        "# ---------- Config da IA Online (FREE) ----------\n",
        "# Cadastre-se grátis na Hugging Face e crie um Access Token (Settings > Access Tokens).\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\", \"\").strip()\n",
        "if not HF_TOKEN:\n",
        "    print(\"⚠️ Defina seu token gratuito da Hugging Face em os.environ['HF_TOKEN'] para ativar a IA online.\")\n",
        "\n",
        "# Modelo público e gratuito (ajuste se quiser)\n",
        "# Recomendo um instruído e leve para PT/ES/EN; Mistral 7B Instruct costuma funcionar bem:\n",
        "HF_MODEL = os.environ.get(\"HF_MODEL_ID\", \"mistralai/Mistral-7B-Instruct-v0.3\")\n",
        "HF_URL = f\"https://api-inference.huggingface.co/models/{HF_MODEL}\"\n",
        "\n",
        "def hf_generate(prompt: str, max_new_tokens=650, temperature=0.3, top_p=0.9, retries=2) -> str:\n",
        "    \"\"\"\n",
        "    Chama o endpoint de geração da Hugging Face (gratuito com token).\n",
        "    Retorna string gerada (sem garantias de JSON formatado — faremos parsing).\n",
        "    \"\"\"\n",
        "    if not HF_TOKEN:\n",
        "        raise RuntimeError(\"HF_TOKEN não definido. Configure os.environ['HF_TOKEN'] com seu token gratuito.\")\n",
        "    headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
        "    payload = {\n",
        "        \"inputs\": prompt,\n",
        "        \"parameters\": {\n",
        "            \"max_new_tokens\": max_new_tokens,\n",
        "            \"temperature\": temperature,\n",
        "            \"top_p\": top_p,\n",
        "            \"return_full_text\": False\n",
        "        }\n",
        "    }\n",
        "    for _ in range(retries):\n",
        "        r = requests.post(HF_URL, headers=headers, json=payload, timeout=90)\n",
        "        if r.status_code == 200:\n",
        "            try:\n",
        "                out = r.json()\n",
        "                if isinstance(out, list) and out and \"generated_text\" in out[0]:\n",
        "                    return out[0][\"generated_text\"]\n",
        "                if isinstance(out, dict) and \"generated_text\" in out:\n",
        "                    return out[\"generated_text\"]\n",
        "                # alguns servidores retornam str direta\n",
        "                if isinstance(out, str):\n",
        "                    return out\n",
        "            except Exception:\n",
        "                return r.text\n",
        "        time.sleep(2)\n",
        "    # retorna texto cru (pode conter erro do modelo)\n",
        "    return r.text\n",
        "\n",
        "def try_json_extract(text: str) -> Any:\n",
        "    \"\"\"\n",
        "    Extrai o primeiro JSON válido de uma string. Robustifica contra respostas com texto extra.\n",
        "    \"\"\"\n",
        "    start = text.find(\"{\")\n",
        "    end   = text.rfind(\"}\")\n",
        "    if start == -1 or end == -1 or end <= start:\n",
        "        return None\n",
        "    snippet = text[start:end+1]\n",
        "    try:\n",
        "        return json.loads(snippet)\n",
        "    except Exception:\n",
        "        # tentativa: aspas simples -> duplas\n",
        "        snippet2 = snippet.replace(\"'\", '\"')\n",
        "        try:\n",
        "            return json.loads(snippet2)\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "# ---------- Utilitários de I/O ----------\n",
        "def ler_metadados() -> List[Dict[str,Any]]:\n",
        "    if not os.path.exists(META_PATH):\n",
        "        print(f\"❌ Não encontrei {META_PATH}. Rode as camadas anteriores.\")\n",
        "        return []\n",
        "    with open(META_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def encontrar_transcricao(video_id: str) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Procura transcript/srt da sua Layer 5:\n",
        "      - PASTA_TRABALHO/ai_insights/<video_id>/transcript.txt\n",
        "      - PASTA_TRABALHO/ai_insights/<video_id>/subtitles.srt\n",
        "    Retorna dict com 'plain' e 'srt' (quando houver).\n",
        "    \"\"\"\n",
        "    base = os.path.join(PASTA_TRABALHO, \"ai_insights\", video_id)\n",
        "    out = {\"plain\": \"\", \"srt\": \"\"}\n",
        "    if os.path.isdir(base):\n",
        "        pt = os.path.join(base, \"transcript.txt\")\n",
        "        ps = os.path.join(base, \"subtitles.srt\")\n",
        "        if os.path.exists(pt):\n",
        "            out[\"plain\"] = Path(pt).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "        if os.path.exists(ps):\n",
        "            out[\"srt\"] = Path(ps).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "    return out\n",
        "\n",
        "def srt_para_blocos(srt_text: str, janela_seg=20, max_blocos=6) -> List[Dict[str,Any]]:\n",
        "    \"\"\"\n",
        "    Junta legendas em blocos de ~janela_seg segundos (até max_blocos) para análise por cena.\n",
        "    \"\"\"\n",
        "    if not srt_text.strip():\n",
        "        return []\n",
        "    # parse simples\n",
        "    entries = []\n",
        "    for chunk in re.split(r\"\\n\\s*\\n\", srt_text.strip()):\n",
        "        lines = [l.strip() for l in chunk.splitlines() if l.strip()]\n",
        "        if len(lines) >= 2:\n",
        "            ts = lines[1]\n",
        "            m = re.match(r\"(\\d{2}):(\\d{2}):(\\d{2}),\\d+\\s*-->\\s*(\\d{2}):(\\d{2}):(\\d{2}),\\d+\", ts)\n",
        "            if not m:\n",
        "                continue\n",
        "            h1,m1,s1, h2,m2,s2 = map(int, m.groups())\n",
        "            start = h1*3600+m1*60+s1\n",
        "            end   = h2*3600+m2*60+s2\n",
        "            text  = \" \".join(lines[2:])\n",
        "            entries.append((start, end, text))\n",
        "    # agrega em janelas\n",
        "    if not entries:\n",
        "        return []\n",
        "    t0 = entries[0][0]\n",
        "    blocos = []\n",
        "    cur_t0 = t0\n",
        "    cur_txt = []\n",
        "    for st, en, txt in entries:\n",
        "        if (en - cur_t0) <= janela_seg:\n",
        "            cur_txt.append(txt)\n",
        "        else:\n",
        "            blocos.append({\"inicio_seg\": cur_t0, \"fim_seg\": en, \"texto\": \" \".join(cur_txt)})\n",
        "            cur_t0 = en\n",
        "            cur_txt = [txt]\n",
        "    if cur_txt:\n",
        "        blocos.append({\"inicio_seg\": cur_t0, \"fim_seg\": entries[-1][1], \"texto\": \" \".join(cur_txt)})\n",
        "    return blocos[:max_blocos]\n",
        "\n",
        "# ---------- Prompts ----------\n",
        "PROMPT_MACRO = \"\"\"Você é um analista sênior de roteiro e comunicação em pt-BR.\n",
        "Analise a TRANSCRIÇÃO a seguir e produza apenas um JSON com os campos:\n",
        "\n",
        "{\n",
        "  \"tema_central\": \"\",\n",
        "  \"tese\": \"\",\n",
        "  \"promessa\": \"\",\n",
        "  \"publico_alvo\": \"\",\n",
        "  \"dor_principal\": \"\",\n",
        "  \"ganho_principal\": \"\",\n",
        "  \"mecanismo_unico\": \"\",\n",
        "  \"provas_apoio\": [\"\", \"\"],\n",
        "  \"tom_de_voz\": [\"\", \"\"],\n",
        "  \"frameworks_copy\": [\"AIDA\",\"PAS\",\"FAB\",\"Story\",\"Lista\",\"How-To\"],\n",
        "  \"estrutura_geral\": [\n",
        "    {\"bloco\": 1, \"objetivo\": \"\", \"ideias_chave\": [\"\",\"\",\"\"], \"frases_de_efeito\": [\"\",\"\"]}\n",
        "  ],\n",
        "  \"objeções_previstas\": [\"\",\"\",\"\"],\n",
        "  \"oportunidades_melhoria\": [\"\",\"\",\"\"],\n",
        "  \"analogias_recomendadas\": [\"\",\"\",\"\"],\n",
        "  \"cta_detectadas\": [\"\",\"\",\"\"]\n",
        "}\n",
        "\n",
        "TRANSCRIÇÃO:\n",
        "\"\"\"\n",
        "\n",
        "PROMPT_SUGESTOES = \"\"\"Você é um roteirista sênior para vídeos curtos em pt-BR.\n",
        "Usando a TRANSCRIÇÃO (e os insights macro abaixo), gere apenas um JSON:\n",
        "\n",
        "INSIGHTS_MACRO:\n",
        "{macro}\n",
        "\n",
        "TRANSCRIÇÃO:\n",
        "{transc}\n",
        "\n",
        "JSON com:\n",
        "{\n",
        "  \"hooks_reativos\": [\"5 variações objetivas, curtas, com números ou pergunta\"],\n",
        "  \"texto_na_tela_3s\": [\"3 frases de 5–7 palavras para aparecer em 3s\"],\n",
        "  \"roteiro_15s\": [\"linha-a-linha do que dizer/fazer\", \"...\"],\n",
        "  \"roteiro_30s\": [\"linha-a-linha do que dizer/fazer\", \"...\"],\n",
        "  \"analogias\": [\"3 ideias de analogias concretas\"],\n",
        "  \"oportunidades\": [\"3 oportunidades específicas de melhoria do roteiro\"]\n",
        "}\n",
        "Responda só com JSON.\n",
        "\"\"\"\n",
        "\n",
        "PROMPT_CENA = \"\"\"Você é um editor-chefe. Para o trecho abaixo, devolva JSON:\n",
        "\n",
        "TRECHO:\n",
        "{trecho}\n",
        "\n",
        "JSON:\n",
        "{\n",
        "  \"objetivo_do_trecho\": \"\",\n",
        "  \"ponto_principal\": \"\",\n",
        "  \"melhorias_de_copy\": [\"\",\"\",\"\"],\n",
        "  \"texto_na_tela_sugerido\": [\"\",\"\"],\n",
        "  \"cta_sugerida\": \"\"\n",
        "}\n",
        "Responda só JSON.\n",
        "\"\"\"\n",
        "\n",
        "# ---------- Execução por vídeo ----------\n",
        "def analisar_video_online(video_id: str, nome_arquivo: str) -> Dict[str,Any]:\n",
        "    out_dir = os.path.join(AI_ONLINE_DIR, video_id)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # Carrega transcrição\n",
        "    tr = encontrar_transcricao(video_id)\n",
        "    texto = tr[\"plain\"] or \"\"\n",
        "    srt  = tr[\"srt\"] or \"\"\n",
        "    if not (texto or srt):\n",
        "        print(f\"⚠️ {video_id}: sem transcript/srt. Pulei IA online.\")\n",
        "        return {}\n",
        "\n",
        "    # 1) Macro\n",
        "    macro_prompt = PROMPT_MACRO + (texto[:6000] if texto else srt[:6000])\n",
        "    macro_raw = hf_generate(macro_prompt, max_new_tokens=700, temperature=0.25) if HF_TOKEN else \"{}\"\n",
        "    macro = try_json_extract(macro_raw) or {}\n",
        "\n",
        "    # 2) Sugestões (usa texto e macro)\n",
        "    sug_prompt = PROMPT_SUGESTOES.format(macro=json.dumps(macro, ensure_ascii=False), transc=(texto[:4000] if texto else srt[:4000]))\n",
        "    sug_raw = hf_generate(sug_prompt, max_new_tokens=700, temperature=0.4) if HF_TOKEN else \"{}\"\n",
        "    sugestoes = try_json_extract(sug_raw) or {}\n",
        "\n",
        "    # 3) Cenas (usa SRT em blocos)\n",
        "    cenas = []\n",
        "    blocos = srt_para_blocos(srt, janela_seg=20, max_blocos=6)\n",
        "    for b in blocos:\n",
        "        p = PROMPT_CENA.format(trecho=b[\"texto\"][:1200])\n",
        "        raw = hf_generate(p, max_new_tokens=350, temperature=0.35) if HF_TOKEN else \"{}\"\n",
        "        j = try_json_extract(raw) or {}\n",
        "        cenas.append({\n",
        "            \"inicio_seg\": b[\"inicio_seg\"], \"fim_seg\": b[\"fim_seg\"], **j\n",
        "        })\n",
        "\n",
        "    # Salva JSON e MD por vídeo\n",
        "    pack = {\n",
        "        \"video_id\": video_id,\n",
        "        \"nome_arquivo\": nome_arquivo,\n",
        "        \"macro\": macro,\n",
        "        \"sugestoes\": sugestoes,\n",
        "        \"cenas\": cenas\n",
        "    }\n",
        "    Path(os.path.join(out_dir, \"online_llm_report.json\")).write_text(json.dumps(pack, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "    md = [\n",
        "        f\"# IA Online — {video_id}\",\n",
        "        \"## Macro\",\n",
        "        json.dumps(macro, ensure_ascii=False, indent=2),\n",
        "        \"## Sugestões\",\n",
        "        json.dumps(sugestoes, ensure_ascii=False, indent=2),\n",
        "        \"## Cenas\",\n",
        "        json.dumps(cenas, ensure_ascii=False, indent=2),\n",
        "    ]\n",
        "    Path(os.path.join(out_dir, \"online_llm_report.md\")).write_text(\"\\n\\n\".join(md), encoding=\"utf-8\")\n",
        "\n",
        "    return pack\n",
        "\n",
        "# ---------- Atualiza Excel ----------\n",
        "def _xl_set_width(ws, widths):\n",
        "    for i,w in enumerate(widths,1):\n",
        "        ws.column_dimensions[get_column_letter(i)].width = w\n",
        "\n",
        "def atualizar_excel_online(pacotes: List[Dict[str,Any]]):\n",
        "    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
        "    wb = load_workbook(OUTPUT_PATH) if os.path.exists(OUTPUT_PATH) else Workbook()\n",
        "\n",
        "    # --- Aba 1: IA Online — Macro ---\n",
        "    if \"IA Online — Macro\" in wb.sheetnames: del wb[\"IA Online — Macro\"]\n",
        "    ws1 = wb.create_sheet(\"IA Online — Macro\")\n",
        "    header1 = [\"Vídeo\",\"Tema\",\"Tese\",\"Promessa\",\"Público\",\"Dor\",\"Ganho\",\"Mecanismo único\",\"Provas\",\"Tom\",\"Frameworks\",\"Objeções\",\"Oportunidades\",\"Analogias\",\"CTAs\",\"Estrutura (blocos)\"]\n",
        "    for c,h in enumerate(header1,1):\n",
        "        cell = ws1.cell(row=1, column=c, value=h); cell.font=Font(bold=True)\n",
        "    row=2\n",
        "    for p in pacotes:\n",
        "        m = p.get(\"macro\", {})\n",
        "        ws1.cell(row=row, column=1, value=p.get(\"nome_arquivo\", p.get(\"video_id\")))\n",
        "        ws1.cell(row=row, column=2, value=m.get(\"tema_central\"))\n",
        "        ws1.cell(row=row, column=3, value=m.get(\"tese\"))\n",
        "        ws1.cell(row=row, column=4, value=m.get(\"promessa\"))\n",
        "        ws1.cell(row=row, column=5, value=m.get(\"publico_alvo\"))\n",
        "        ws1.cell(row=row, column=6, value=m.get(\"dor_principal\"))\n",
        "        ws1.cell(row=row, column=7, value=m.get(\"ganho_principal\"))\n",
        "        ws1.cell(row=row, column=8, value=m.get(\"mecanismo_unico\"))\n",
        "        ws1.cell(row=row, column=9, value=\", \".join(m.get(\"provas_apoio\",[]) or []))\n",
        "        ws1.cell(row=row, column=10, value=\", \".join(m.get(\"tom_de_voz\",[]) or []))\n",
        "        ws1.cell(row=row, column=11, value=\", \".join(m.get(\"frameworks_copy\",[]) or []))\n",
        "        ws1.cell(row=row, column=12, value=\", \".join(m.get(\"objeções_previstas\",[]) or []))\n",
        "        ws1.cell(row=row, column=13, value=\", \".join(m.get(\"oportunidades_melhoria\",[]) or []))\n",
        "        ws1.cell(row=row, column=14, value=\", \".join(m.get(\"analogias_recomendadas\",[]) or []))\n",
        "        ws1.cell(row=row, column=15, value=\", \".join(m.get(\"cta_detectadas\",[]) or []))\n",
        "        # estrutura compactada\n",
        "        estrutura = m.get(\"estrutura_geral\", [])\n",
        "        ws1.cell(row=row, column=16, value=json.dumps(estrutura, ensure_ascii=False))\n",
        "        row += 1\n",
        "    _xl_set_width(ws1, [30,18,18,20,18,18,18,20,24,16,16,18,22,18,18,48])\n",
        "\n",
        "    # --- Aba 2: IA Online — Sugestões ---\n",
        "    if \"IA Online — Sugestões\" in wb.sheetnames: del wb[\"IA Online — Sugestões\"]\n",
        "    ws2 = wb.create_sheet(\"IA Online — Sugestões\")\n",
        "    header2 = [\"Vídeo\",\"Hooks (5)\",\"Texto na tela 3s (3)\",\"Roteiro 15s\",\"Roteiro 30s\",\"Analogias\",\"Oportunidades\"]\n",
        "    for c,h in enumerate(header2,1):\n",
        "        ws2.cell(row=1, column=c, value=h).font=Font(bold=True)\n",
        "    row=2\n",
        "    for p in pacotes:\n",
        "        s = p.get(\"sugestoes\", {})\n",
        "        ws2.cell(row=row, column=1, value=p.get(\"nome_arquivo\", p.get(\"video_id\")))\n",
        "        ws2.cell(row=row, column=2, value=\" • \" + \"\\n • \".join(s.get(\"hooks_reativos\",[]) or []))\n",
        "        ws2.cell(row=row, column=3, value=\" • \" + \"\\n • \".join(s.get(\"texto_na_tela_3s\",[]) or []))\n",
        "        ws2.cell(row=row, column=4, value=\" • \" + \"\\n • \".join(s.get(\"roteiro_15s\",[]) or []))\n",
        "        ws2.cell(row=row, column=5, value=\" • \" + \"\\n • \".join(s.get(\"roteiro_30s\",[]) or []))\n",
        "        ws2.cell(row=row, column=6, value=\" • \" + \"\\n • \".join(s.get(\"analogias\",[]) or []))\n",
        "        ws2.cell(row=row, column=7, value=\" • \" + \"\\n • \".join(s.get(\"oportunidades\",[]) or []))\n",
        "        row+=1\n",
        "    _xl_set_width(ws2, [30,54,40,60,60,40,40])\n",
        "\n",
        "    # --- Aba 3: IA Online — Cenas ---\n",
        "    if \"IA Online — Cenas\" in wb.sheetnames: del wb[\"IA Online — Cenas\"]\n",
        "    ws3 = wb.create_sheet(\"IA Online — Cenas\")\n",
        "    header3 = [\"Vídeo\",\"Início (s)\",\"Fim (s)\",\"Objetivo do trecho\",\"Ponto principal\",\"Melhorias de copy\",\"Texto na tela sugerido\",\"CTA sugerida\"]\n",
        "    for c,h in enumerate(header3,1):\n",
        "        ws3.cell(row=1, column=c, value=h).font=Font(bold=True)\n",
        "    row=2\n",
        "    for p in pacotes:\n",
        "        for c in (p.get(\"cenas\") or []):\n",
        "            ws3.cell(row=row, column=1, value=p.get(\"nome_arquivo\", p.get(\"video_id\")))\n",
        "            ws3.cell(row=row, column=2, value=c.get(\"inicio_seg\"))\n",
        "            ws3.cell(row=row, column=3, value=c.get(\"fim_seg\"))\n",
        "            ws3.cell(row=row, column=4, value=c.get(\"objetivo_do_trecho\"))\n",
        "            ws3.cell(row=row, column=5, value=c.get(\"ponto_principal\"))\n",
        "            ws3.cell(row=row, column=6, value=\"; \".join(c.get(\"melhorias_de_copy\",[]) or []))\n",
        "            ws3.cell(row=row, column=7, value=\"; \".join(c.get(\"texto_na_tela_sugerido\",[]) or []))\n",
        "            ws3.cell(row=row, column=8, value=c.get(\"cta_sugerida\"))\n",
        "            row+=1\n",
        "    _xl_set_width(ws3, [30,10,10,40,40,50,40,24])\n",
        "\n",
        "    wb.save(OUTPUT_PATH)\n",
        "    print(f\"✅ Excel atualizado com abas: IA Online — Macro / Sugestões / Cenas → {OUTPUT_PATH}\")\n",
        "\n",
        "# ---------- Orquestração ----------\n",
        "def rodar_layer_7_online_free():\n",
        "    metas = ler_metadados()\n",
        "    if not metas:\n",
        "        return\n",
        "    pacotes = []\n",
        "    for i, m in enumerate(metas, 1):\n",
        "        vid = m.get(\"id\"); nome = m.get(\"nome_arquivo\", vid)\n",
        "        if not vid:\n",
        "            continue\n",
        "        print(f\"[{i}/{len(metas)}] IA Online (FREE) → {vid}\")\n",
        "        try:\n",
        "            p = analisar_video_online(vid, nome)\n",
        "            if p: pacotes.append(p)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Falha em {vid}: {e}\")\n",
        "    if pacotes:\n",
        "        Path(os.path.join(DADOS_DIR, \"ai_online_insights.json\")).write_text(json.dumps(pacotes, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "        atualizar_excel_online(pacotes)\n",
        "    else:\n",
        "        print(\"Nada processado (sem transcrições ou sem token HF).\")\n"
      ],
      "metadata": {
        "id": "qsF_FvEM-26P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rodar_layer_7_online_free()"
      ],
      "metadata": {
        "id": "rlLvaS5wFn5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2teNlxNsFsoK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}