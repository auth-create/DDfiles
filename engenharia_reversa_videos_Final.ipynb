{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/auth-create/DDfiles/blob/main/engenharia_reversa_videos_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SISTEMA MODULAR DE ENGENHARIA REVERSA DE V√çDEOS - VERS√ÉO FINAL OTIMIZADA\n",
        "\n",
        "Este notebook foi aprimorado para oferecer uma experi√™ncia mais intuitiva, organizada e robusta para a engenharia reversa de v√≠deos. Cada etapa √© modular, com valida√ß√µes de pr√©-requisitos e feedback em tempo real para gui√°-lo(a) durante o processo.\n",
        "\n",
        "## COMO USAR:\n",
        "1.  **Execute as c√©lulas em ordem, de cima para baixo.** Cada c√©lula foi projetada para ser executada sequencialmente.\n",
        "2.  **Aten√ß√£o aos feedbacks:** Mensagens claras indicar√£o o sucesso de cada etapa, poss√≠veis erros e qual a **PR√ìXIMA C√âLULA** a ser executada.\n",
        "3.  **Corrija e re-execute:** Se um erro for detectado, uma mensagem explicativa ser√° exibida. Corrija o problema (geralmente um caminho incorreto ou depend√™ncia ausente) e re-execute a c√©lula que falhou.\n",
        "4.  **Progresso Salvo:** O sistema salva automaticamente o progresso e os dados gerados em cada etapa, permitindo que voc√™ retome de onde parou.\n",
        "\n",
        "## ESTRUTURA DO PROCESSO (Layers e Sublayers):\n",
        "Este sistema √© organizado em camadas l√≥gicas para facilitar o entendimento e a execu√ß√£o:\n",
        "\n",
        "### LAYER 1: CONFIGURA√á√ÉO E PREPARA√á√ÉO\n",
        "*   **C√âLULA 1.1: SETUP INICIAL E INSTALA√á√ÉO DE DEPEND√äNCIAS**\n",
        "*   **C√âLULA 1.2: CONFIGURA√á√ÉO INICIAL E VALIDA√á√ÉO DA PASTA DE TRABALHO**\n",
        "\n",
        "### LAYER 2: DESCOBERTA E EXTRA√á√ÉO DE DADOS BRUTOS\n",
        "*   **C√âLULA 2.1: DESCOBERTA E CATALOGA√á√ÉO DE V√çDEOS**\n",
        "*   **C√âLULA 2.2: EXTRA√á√ÉO DE METADADOS DOS V√çDEOS**\n",
        "*   **C√âLULA 2.3: DECOMPOSI√á√ÉO DE V√çDEOS (FRAMES, √ÅUDIO, TEXTO)**\n",
        "\n",
        "### LAYER 3: AN√ÅLISE E PROCESSAMENTO DE DADOS\n",
        "*   **C√âLULA 3.1: AN√ÅLISE DE PADR√ïES (TEMPORAIS, VISUAIS, TEXTO, √ÅUDIO)**\n",
        "*   **C√âLULA 3.2: AN√ÅLISE PSICOL√ìGICA E GATILHOS DE ENGAJAMENTO**\n",
        "\n",
        "### LAYER 4: GERA√á√ÉO DE RELAT√ìRIOS E BLUEPRINT ESTRAT√âGICO\n",
        "*   **C√âLULA 4.1: GERA√á√ÉO DE RELAT√ìRIOS HUMANIZADOS (√ÅUDIO, VISUAL, TEXTO, PSICOL√ìGICO)**\n",
        "*   **C√âLULA 4.2: GERA√á√ÉO DO BLUEPRINT FINAL E DASHBOARD**\n",
        "\n",
        "---\n",
        "\n",
        "*Lembre-se: Este sistema foi projetado para ser executado no Google Colab. Certifique-se de que seu ambiente est√° configurado corretamente.*"
      ],
      "metadata": {
        "id": "zx8sEBm8_yKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LAYER 1: CONFIGURA√á√ÉO E PREPARA√á√ÉO\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# C√âLULA 1.1: SETUP INICIAL E INSTALA√á√ÉO DE DEPEND√äNCIAS\n",
        "# ============================================================================\n",
        "\n",
        "# Instalar depend√™ncias necess√°rias\n",
        "!pip install -q moviepy librosa pytesseract opencv-python pandas openpyxl matplotlib seaborn pillow SpeechRecognition pydub fpdf\n",
        "!apt-get update -qq && apt-get install -y -qq tesseract-ocr tesseract-ocr-por ffmpeg\n",
        "\n",
        "# Imports necess√°rios\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import logging\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "import librosa\n",
        "from moviepy.editor import VideoFileClip\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import speech_recognition as sr # Adicionado import para SpeechRecognition\n",
        "# Montar Google Drive\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"‚úÖ Google Drive montado com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ERRO ao montar Google Drive: {e}. Por favor, verifique sua conex√£o ou permiss√µes.\")\n",
        "\n",
        "print(\n",
        "\"‚úÖ SETUP INICIAL CONCLU√çDO!\")\n",
        "print(\"Todas as depend√™ncias foram instaladas e o Google Drive foi montado.\")\n",
        "print(\"‚û°Ô∏è PR√ìXIMA C√âLULA: 1.2 - CONFIGURA√á√ÉO INICIAL E VALIDA√á√ÉO DA PASTA DE TRABALHO\")"
      ],
      "metadata": {
        "id": "setup_inicial",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "084bc538-0dab-41ec-b075-71b0bb3a987a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Google Drive montado com sucesso!\n",
            "‚úÖ SETUP INICIAL CONCLU√çDO!\n",
            "Todas as depend√™ncias foram instaladas e o Google Drive foi montado.\n",
            "‚û°Ô∏è PR√ìXIMA C√âLULA: 1.2 - CONFIGURA√á√ÉO INICIAL E VALIDA√á√ÉO DA PASTA DE TRABALHO\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# C√âLULA 1.2: CONFIGURA√á√ÉO INICIAL E VALIDA√á√ÉO DA PASTA DE TRABALHO\n",
        "# ============================================================================\n",
        "\n",
        "# ‚ö†Ô∏è **ATEN√á√ÉO:** CONFIGURE SEU CAMINHO AQUI!\n",
        "# Substitua o caminho abaixo pela pasta onde seus v√≠deos est√£o localizados no Google Drive.\n",
        "# Exemplo: \"/content/drive/MyDrive/Meus Videos de Marketing\"\n",
        "CAMINHO_PASTA_VIDEOS = \"/content/drive/MyDrive/Videos Dona Done\" # ‚¨ÖÔ∏è **ALTERE AQUI**\n",
        "\n",
        "class ConfiguradorProjeto:\n",
        "    def __init__(self, caminho_pasta):\n",
        "        self.pasta_videos = self._validar_caminho(caminho_pasta)\n",
        "        self.pasta_trabalho = os.path.join(self.pasta_videos, \"_engenharia_reversa\")\n",
        "        self._criar_estrutura()\n",
        "        self._configurar_logging()\n",
        "\n",
        "    def _validar_caminho(self, caminho):\n",
        "        if caminho == \"/content/drive/MyDrive/Videos Dona Done\" and not os.path.exists(caminho):\n",
        "            raise ValueError(\"‚ùå ERRO: Voc√™ precisa alterar CAMINHO_PASTA_VIDEOS com o caminho real da sua pasta de v√≠deos no Google Drive. O caminho padr√£o n√£o foi encontrado.\")\n",
        "\n",
        "        if not os.path.exists(caminho):\n",
        "            raise ValueError(f\"‚ùå ERRO: Pasta n√£o encontrada: {caminho}. Por favor, verifique se o caminho est√° correto e se o Google Drive est√° montado.\")\n",
        "\n",
        "        return caminho\n",
        "\n",
        "    def _criar_estrutura(self):\n",
        "        # Estrutura de pastas conforme o anexo e requisitos do usu√°rio\n",
        "        estrutura = [\n",
        "            \"config\", \"logs\", \"dados\", \"frames_extraidos\",\n",
        "            \"analise_texto\", \"analise_audio\", \"capturas\",\n",
        "            \"blueprint\", \"temp\", \"dashboard\", \"analise_psicologica\", \"analise_visual\"\n",
        "        ]\n",
        "\n",
        "        os.makedirs(self.pasta_trabalho, exist_ok=True)\n",
        "        for pasta in estrutura:\n",
        "            os.makedirs(os.path.join(self.pasta_trabalho, pasta), exist_ok=True)\n",
        "\n",
        "        # Criar subpastas para frames_extraidos (ex: vid_001_Nome_Do_Video/)\n",
        "        # Esta l√≥gica ser√° implementada na c√©lula de decomposi√ß√£o de v√≠deos (C√âLULA 2.3)\n",
        "\n",
        "    def _configurar_logging(self):\n",
        "        log_file = os.path.join(self.pasta_trabalho, \"logs\", f\"sistema_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        "            handlers=[logging.FileHandler(log_file, encoding='utf-8')]\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def salvar_configuracao(self):\n",
        "        config = {\n",
        "            \"projeto\": {\n",
        "                \"pasta_videos\": self.pasta_videos,\n",
        "                \"pasta_trabalho\": self.pasta_trabalho,\n",
        "                \"criado_em\": datetime.now().isoformat(),\n",
        "                \"versao\": \"modular_v2.0_otimizado\"\n",
        "            },\n",
        "            \"status_etapas\": {\n",
        "                \"configuracao\": True,\n",
        "                \"descoberta_videos\": False,\n",
        "                \"metadados\": False,\n",
        "                \"decomposicao\": False,\n",
        "                \"analise_padroes\": False,\n",
        "                \"analise_psicologica\": False,\n",
        "                \"relatorios_humanizados\": False,\n",
        "                \"blueprint\": False\n",
        "            }\n",
        "        }\n",
        "\n",
        "        config_path = os.path.join(self.pasta_trabalho, \"config\", \"config.json\")\n",
        "        with open(config_path, \"w\", encoding='utf-8') as f:\n",
        "            json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        return config_path\n",
        "\n",
        "# Executar configura√ß√£o\n",
        "try:\n",
        "    configurador = ConfiguradorProjeto(CAMINHO_PASTA_VIDEOS)\n",
        "    config_path = configurador.salvar_configuracao()\n",
        "\n",
        "    print(\"\"\"\n",
        "‚úÖ CONFIGURA√á√ÉO CONCLU√çDA!\"\"\")\n",
        "    print(f\"Pasta de trabalho criada: {configurador.pasta_trabalho}\")\n",
        "    print(f\"Configura√ß√£o salva: {config_path}\")\n",
        "    print(\"\"\"\n",
        "‚û°Ô∏è PR√ìXIMA C√âLULA: 2.1 - DESCOBERTA E CATALOGA√á√ÉO DE V√çDEOS\"\"\")\n",
        "\n",
        "    # Salvar vari√°veis globais para pr√≥ximas c√©lulas\n",
        "    global PASTA_VIDEOS, PASTA_TRABALHO\n",
        "    PASTA_VIDEOS = configurador.pasta_videos\n",
        "    PASTA_TRABALHO = configurador.pasta_trabalho\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\"\"\n",
        "‚ùå ERRO NA CONFIGURA√á√ÉO: {e}\"\"\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "configuracao_inicial",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d706d364-9cd8-40ca-82fa-9b5974001b87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ CONFIGURA√á√ÉO CONCLU√çDA!\n",
            "Pasta de trabalho criada: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa\n",
            "Configura√ß√£o salva: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/config/config.json\n",
            "\n",
            "‚û°Ô∏è PR√ìXIMA C√âLULA: 2.1 - DESCOBERTA E CATALOGA√á√ÉO DE V√çDEOS\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LAYER 2: DESCOBERTA E EXTRA√á√ÉO DE DADOS BRUTOS\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# C√âLULA 2.1: DESCOBERTA E CATALOGA√á√ÉO DE V√çDEOS\n",
        "# ============================================================================\n",
        "\n",
        "def verificar_prerequisito_etapa(etapa_anterior):\n",
        "    \"\"\"Verifica se a etapa anterior foi executada com sucesso\"\"\"\n",
        "    try:\n",
        "        if not \"PASTA_TRABALHO\" in globals():\n",
        "            raise Exception(\"Vari√°veis globais de configura√ß√£o n√£o encontradas. Execute a C√âLULA 1.2 primeiro.\")\n",
        "\n",
        "        config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "        if not os.path.exists(config_path):\n",
        "            raise Exception(\"Arquivo de configura√ß√£o n√£o encontrado. Execute a C√âLULA 1.2 primeiro.\")\n",
        "\n",
        "        with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "        if not config[\"status_etapas\"][etapa_anterior]:\n",
        "            raise Exception(f\"A etapa \\\"{etapa_anterior}\\\" n√£o foi conclu√≠da. Execute a c√©lula correspondente primeiro.\")\n",
        "\n",
        "        return True, config\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå PR√â-REQUISITO N√ÉO ATENDIDO: {e}\")\n",
        "        return False, None\n",
        "\n",
        "def descobrir_catalogar_videos():\n",
        "    \"\"\"Descobre e cataloga todos os v√≠deos na pasta\"\"\"\n",
        "    formatos_aceitos = [\".mp4\", \".mov\", \".avi\", \".mkv\", \".webm\", \".m4v\"]\n",
        "    videos_encontrados = []\n",
        "\n",
        "    print(f\"üîç Iniciando descoberta de v√≠deos na pasta: {PASTA_VIDEOS}\")\n",
        "\n",
        "    for root, dirs, files in os.walk(PASTA_VIDEOS):\n",
        "        if \"_engenharia_reversa\" in root:\n",
        "            continue # Ignorar a pasta de trabalho do sistema\n",
        "\n",
        "        for file in files:\n",
        "            if any(file.lower().endswith(fmt) for fmt in formatos_aceitos):\n",
        "                video_path = os.path.join(root, file)\n",
        "\n",
        "                try:\n",
        "                    stat_info = os.stat(video_path)\n",
        "                    # Gerar ID baseado no nome do arquivo para melhor rastreamento\n",
        "                    video_name_clean = os.path.splitext(file)[0].replace(\" \", \"_\").replace(\".\", \"\")\n",
        "                    video_id = f\"vid_{video_name_clean}\"\n",
        "\n",
        "                    video_info = {\n",
        "                        \"id\": video_id,\n",
        "                        \"nome_arquivo\": file,\n",
        "                        \"caminho_completo\": video_path,\n",
        "                        \"caminho_relativo\": os.path.relpath(video_path, PASTA_VIDEOS),\n",
        "                        \"tamanho_mb\": round(stat_info.st_size / (1024*1024), 2),\n",
        "                        \"data_modificacao\": datetime.fromtimestamp(stat_info.st_mtime).isoformat(),\n",
        "                        \"extensao\": os.path.splitext(file)[1].lower(),\n",
        "                        \"status\": \"descoberto\"\n",
        "                    }\n",
        "\n",
        "                    videos_encontrados.append(video_info)\n",
        "                    print(f\"  ‚úÖ Encontrado: {file}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  ‚ùå Erro ao processar {file}: {e}\")\n",
        "                    continue\n",
        "\n",
        "    return videos_encontrados\n",
        "\n",
        "def salvar_lista_videos(videos):\n",
        "    \"\"\"Salva lista de v√≠deos encontrados\"\"\"\n",
        "    videos_path = os.path.join(PASTA_TRABALHO, \"dados\", \"videos_descobertos.json\")\n",
        "    with open(videos_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(videos, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"descoberta_videos\"] = True\n",
        "    config[\"total_videos_encontrados\"] = len(videos)\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    return videos_path\n",
        "\n",
        "# Executar descoberta\n",
        "prerequisito_ok, _ = verificar_prerequisito_etapa(\"configuracao\")\n",
        "\n",
        "if prerequisito_ok:\n",
        "    try:\n",
        "        videos_encontrados = descobrir_catalogar_videos()\n",
        "\n",
        "        if not videos_encontrados:\n",
        "            print(\"\"\"\n",
        "‚ùå NENHUM V√çDEO ENCONTRADO!\"\"\")\n",
        "            print(f\"Verifique se h√° v√≠deos na pasta configurada: {PASTA_VIDEOS}\")\n",
        "        else:\n",
        "            videos_path = salvar_lista_videos(videos_encontrados)\n",
        "\n",
        "            print(\"\"\"\n",
        "‚úÖ DESCOBERTA DE V√çDEOS CONCLU√çDA!\"\"\")\n",
        "            print(f\"Total de v√≠deos encontrados: {len(videos_encontrados)}\")\n",
        "            print(f\"Lista de v√≠deos salva em: {videos_path}\")\n",
        "\n",
        "            # Mostrar resumo\n",
        "            extensoes = Counter([v[\"extensao\"] for v in videos_encontrados])\n",
        "            print(f\"Formatos encontrados: {dict(extensoes)}\")\n",
        "            print(\"\"\"\n",
        "‚û°Ô∏è PR√ìXIMA C√âLULA: 2.2 - EXTRA√á√ÉO DE METADADOS DOS V√çDEOS\"\"\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\"\"\n",
        "‚ùå ERRO NA DESCOBERTA DE V√çDEOS: {e}\"\"\")\n",
        "        print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "descoberta_videos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f332fe2d-979a-49ad-83d1-d7882369d630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Iniciando descoberta de v√≠deos na pasta: /content/drive/MyDrive/Videos Dona Done\n",
            "  ‚úÖ Encontrado: ate quando voce vai ficar culpando os outros.mp4\n",
            "  ‚úÖ Encontrado: coloque metas em sua vida e se surpreenda.mp4\n",
            "  ‚úÖ Encontrado: a importancia de ser rico antes de ter.mp4\n",
            "  ‚úÖ Encontrado: as treÃÇs fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "  ‚úÖ Encontrado: a melhor saida eÃÅ se afastar de pessoas perversas.mp4\n",
            "\n",
            "‚úÖ DESCOBERTA DE V√çDEOS CONCLU√çDA!\n",
            "Total de v√≠deos encontrados: 5\n",
            "Lista de v√≠deos salva em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dados/videos_descobertos.json\n",
            "Formatos encontrados: {'.mp4': 5}\n",
            "\n",
            "‚û°Ô∏è PR√ìXIMA C√âLULA: 2.2 - EXTRA√á√ÉO DE METADADOS DOS V√çDEOS\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# C√âLULA 2.2: EXTRA√á√ÉO DE METADADOS DOS V√çDEOS\n",
        "# ============================================================================\n",
        "\n",
        "def extrair_metadados_video(video_info):\n",
        "    \"\"\"Extrai metadados t√©cnicos de um v√≠deo\"\"\"\n",
        "    video_path = video_info[\"caminho_completo\"]\n",
        "    video_id = video_info[\"id\"]\n",
        "\n",
        "    print(f\"  ‚öôÔ∏è Extraindo metadados para: {video_info[\"nome_arquivo\"]}\")\n",
        "\n",
        "    # An√°lise com OpenCV\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise Exception(\"N√£o foi poss√≠vel abrir o v√≠deo. Verifique o caminho ou a integridade do arquivo.\")\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    largura = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    altura = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    duracao = frame_count / fps if fps > 0 else 0\n",
        "\n",
        "    # Capturar primeiro frame\n",
        "    ret, primeiro_frame = cap.read()\n",
        "    cap.release()\n",
        "\n",
        "    # An√°lise de √°udio\n",
        "    try:\n",
        "        clip = VideoFileClip(video_path)\n",
        "        tem_audio = clip.audio is not None\n",
        "        clip.close()\n",
        "    except Exception as e:\n",
        "        print(f\"    ‚ö†Ô∏è Aviso: N√£o foi poss√≠vel analisar √°udio para {video_info[\"nome_arquivo\"]}: {e}\")\n",
        "        tem_audio = False\n",
        "\n",
        "    # An√°lise do primeiro frame\n",
        "    analise_frame = {}\n",
        "    if ret:\n",
        "        # Salvar primeiro frame na pasta 'capturas'\n",
        "        capturas_dir = os.path.join(PASTA_TRABALHO, \"capturas\")\n",
        "        frame_path = os.path.join(capturas_dir, f\"{video_id}_primeiro_frame.jpg\")\n",
        "        cv2.imwrite(frame_path, primeiro_frame)\n",
        "\n",
        "        # An√°lises do frame\n",
        "        gray = cv2.cvtColor(primeiro_frame, cv2.COLOR_BGR2GRAY)\n",
        "        complexidade = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "        brilho = np.mean(gray)\n",
        "\n",
        "        analise_frame = {\n",
        "            \"path\": frame_path,\n",
        "            \"complexidade_visual\": float(complexidade),\n",
        "            \"brilho_medio\": float(brilho),\n",
        "            \"tem_muito_texto\": bool(complexidade > 500),\n",
        "            \"e_escuro\": bool(brilho < 100),\n",
        "            \"e_claro\": bool(brilho > 200)\n",
        "        }\n",
        "\n",
        "    # Detectar formato\n",
        "    ratio = largura / altura if altura > 0 else 0\n",
        "    if 0.5 <= ratio <= 0.6:\n",
        "        formato = \"vertical_9_16\" if altura > largura * 1.5 else \"vertical_4_5\"\n",
        "    elif 0.8 <= ratio <= 1.2:\n",
        "        formato = \"quadrado_1_1\"\n",
        "    elif ratio >= 1.3:\n",
        "        formato = \"horizontal_16_9\"\n",
        "    else:\n",
        "        formato = \"personalizado\"\n",
        "\n",
        "    # Compilar metadados - converter todos os valores para tipos b√°sicos Python\n",
        "    metadados = {\n",
        "        **video_info,\n",
        "        \"duracao_segundos\": float(duracao),\n",
        "        \"fps\": float(fps),\n",
        "        \"largura\": int(largura),\n",
        "        \"altura\": int(altura),\n",
        "        \"resolucao\": f\"{largura}x{altura}\",\n",
        "        \"aspect_ratio\": float(ratio),\n",
        "        \"total_frames\": int(frame_count),\n",
        "        \"tem_audio\": bool(tem_audio),\n",
        "        \"formato_detectado\": str(formato),\n",
        "        \"primeiro_frame\": analise_frame,\n",
        "        \"data_analise\": datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    return metadados\n",
        "\n",
        "def processar_metadados_todos_videos():\n",
        "    \"\"\"Processa metadados de todos os v√≠deos\"\"\"\n",
        "    # Carregar lista de v√≠deos\n",
        "    videos_path = os.path.join(PASTA_TRABALHO, \"dados\", \"videos_descobertos.json\")\n",
        "    with open(videos_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        videos_lista = json.load(f)\n",
        "\n",
        "    metadados_completos = []\n",
        "    sucessos = 0\n",
        "\n",
        "    print(f\"Processando metadados de {len(videos_lista)} v√≠deos...\")\n",
        "\n",
        "    for i, video in enumerate(videos_lista, 1):\n",
        "        print(f\"[{i}/{len(videos_lista)}] Analisando {video[\"nome_arquivo\"]}\")\n",
        "\n",
        "        try:\n",
        "            metadados = extrair_metadados_video(video)\n",
        "            metadados[\"status\"] = \"metadados_extraidos\"\n",
        "            metadados_completos.append(metadados)\n",
        "            sucessos += 1\n",
        "            print(f\"  ‚úÖ Metadados extra√≠dos: {metadados[\"duracao_segundos\"]:.1f}s | {metadados[\"formato_detectado\"]} | √Åudio: {\"Sim\" if metadados[\"tem_audio\"] else \"N√£o\"}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå ERRO ao extrair metadados para {video[\"nome_arquivo\"]}: {e}\")\n",
        "            video[\"status\"] = \"erro_metadados\"\n",
        "            metadados_completos.append(video) # Adiciona o v√≠deo com status de erro\n",
        "\n",
        "    # Salvar metadados completos\n",
        "    metadados_json_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_completos.json\")\n",
        "    with open(metadados_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metadados_completos, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Salvar em Excel\n",
        "    df_metadados = pd.DataFrame(metadados_completos)\n",
        "    metadados_excel_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_videos.xlsx\")\n",
        "    df_metadados.to_excel(metadados_excel_path, index=False, engine='openpyxl')\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"metadados\"] = True\n",
        "    config[\"total_videos_metadados\"] = sucessos\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\\nüíæ Metadados completos salvos em: {metadados_json_path}\")\n",
        "    print(f\"üíæ Metadados em Excel salvos em: {metadados_excel_path}\")\n",
        "\n",
        "    print(\"\\n‚úÖ EXTRA√á√ÉO DE METADADOS CONCLU√çDA!\")\n",
        "    print(f\"Total de v√≠deos com metadados extra√≠dos: {sucessos}\")\n",
        "\n",
        "    # Mostrar resumo\n",
        "    if not df_metadados.empty:\n",
        "        print(\"\\nüìä Resumo dos Metadados:\")\n",
        "        print(f\"  - Formatos detectados: {dict(df_metadados['formato_detectado'].value_counts())}\")\n",
        "        print(f\"  - Dura√ß√£o m√©dia dos v√≠deos: {df_metadados['duracao_segundos'].mean():.2f}s\")\n",
        "        print(f\"  - V√≠deos com √°udio: {df_metadados['tem_audio'].sum()}\")\n",
        "\n",
        "    print(\"\\n‚û°Ô∏è PR√ìXIMA C√âLULA: 2.3 - DECOMPOSI√á√ÉO DE V√çDEOS (FRAMES, √ÅUDIO, TEXTO)\")\n",
        "\n",
        "# Executar extra√ß√£o de metadados\n",
        "prerequisito_ok, _ = verificar_prerequisito_etapa(\"descoberta_videos\")\n",
        "\n",
        "if prerequisito_ok:\n",
        "    try:\n",
        "        processar_metadados_todos_videos()\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå ERRO NA EXTRA√á√ÉO DE METADADOS: {e}\")\n",
        "        print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "extracao_metadados",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b02dded8-05ed-438f-f401-a4ff03ff686f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processando metadados de 5 v√≠deos...\n",
            "[1/5] Analisando ate quando voce vai ficar culpando os outros.mp4\n",
            "  ‚öôÔ∏è Extraindo metadados para: ate quando voce vai ficar culpando os outros.mp4\n",
            "  ‚úÖ Metadados extra√≠dos: 18.6s | vertical_9_16 | √Åudio: Sim\n",
            "[2/5] Analisando coloque metas em sua vida e se surpreenda.mp4\n",
            "  ‚öôÔ∏è Extraindo metadados para: coloque metas em sua vida e se surpreenda.mp4\n",
            "  ‚úÖ Metadados extra√≠dos: 15.8s | vertical_9_16 | √Åudio: Sim\n",
            "[3/5] Analisando a importancia de ser rico antes de ter.mp4\n",
            "  ‚öôÔ∏è Extraindo metadados para: a importancia de ser rico antes de ter.mp4\n",
            "  ‚úÖ Metadados extra√≠dos: 19.0s | vertical_9_16 | √Åudio: Sim\n",
            "[4/5] Analisando as treÃÇs fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "  ‚öôÔ∏è Extraindo metadados para: as treÃÇs fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "  ‚úÖ Metadados extra√≠dos: 51.5s | vertical_9_16 | √Åudio: Sim\n",
            "[5/5] Analisando a melhor saida eÃÅ se afastar de pessoas perversas.mp4\n",
            "  ‚öôÔ∏è Extraindo metadados para: a melhor saida eÃÅ se afastar de pessoas perversas.mp4\n",
            "  ‚úÖ Metadados extra√≠dos: 42.8s | vertical_9_16 | √Åudio: Sim\n",
            "\n",
            "üíæ Metadados completos salvos em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dados/metadados_completos.json\n",
            "üíæ Metadados em Excel salvos em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dados/metadados_videos.xlsx\n",
            "\n",
            "‚úÖ EXTRA√á√ÉO DE METADADOS CONCLU√çDA!\n",
            "Total de v√≠deos com metadados extra√≠dos: 5\n",
            "\n",
            "üìä Resumo dos Metadados:\n",
            "  - Formatos detectados: {'vertical_9_16': np.int64(5)}\n",
            "  - Dura√ß√£o m√©dia dos v√≠deos: 29.55s\n",
            "  - V√≠deos com √°udio: 5\n",
            "\n",
            "‚û°Ô∏è PR√ìXIMA C√âLULA: 2.3 - DECOMPOSI√á√ÉO DE V√çDEOS (FRAMES, √ÅUDIO, TEXTO)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# C√âLULA 2.3: DECOMPOSI√á√ÉO DE V√çDEOS (FRAMES, √ÅUDIO, TEXTO)\n",
        "# ============================================================================\n",
        "\n",
        "def decompor_video(video_info):\n",
        "    \"\"\"Decomp√µe um v√≠deo em frames, √°udio e texto (OCR e transcri√ß√£o)\"\"\"\n",
        "    video_path = video_info[\"caminho_completo\"]\n",
        "    video_id = video_info[\"id\"]\n",
        "    pasta_video_frames = os.path.join(PASTA_TRABALHO, \"frames_extraidos\", video_id)\n",
        "    os.makedirs(pasta_video_frames, exist_ok=True)\n",
        "\n",
        "    print(f\"  ‚öôÔ∏è Decompondo v√≠deo: {video_info[\"nome_arquivo\"]}\")\n",
        "\n",
        "    decomposicao_data = {\n",
        "        \"video_id\": video_id,\n",
        "        \"frames_extraidos\": [],\n",
        "        \"textos_ocr\": [],\n",
        "        \"audio_transcrito\": \"\",\n",
        "        \"audio_analise\": {}\n",
        "    }\n",
        "\n",
        "    # Extra√ß√£o de Frames e OCR\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        frame_count = 0\n",
        "        frame_interval = int(fps) # 1 frame por segundo\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if frame_count % frame_interval == 0:\n",
        "                frame_time_sec = frame_count / fps\n",
        "                frame_filename = os.path.join(pasta_video_frames, f\"frame_{int(frame_time_sec):06d}.jpg\")\n",
        "                cv2.imwrite(frame_filename, frame)\n",
        "                decomposicao_data[\"frames_extraidos\"] .append({\n",
        "                    \"path\": frame_filename,\n",
        "                    \"timestamp_sec\": frame_time_sec\n",
        "                })\n",
        "\n",
        "                # OCR\n",
        "                try:\n",
        "                    text = pytesseract.image_to_string(Image.fromarray(frame), lang=\"por\")\n",
        "                    if text.strip():\n",
        "                        decomposicao_data[\"textos_ocr\"] .append({\n",
        "                            \"timestamp_sec\": frame_time_sec,\n",
        "                            \"text\": text.strip()\n",
        "                        })\n",
        "                except Exception as ocr_e:\n",
        "                    print(f\"    ‚ö†Ô∏è Aviso: Erro no OCR para frame {frame_time_sec}s: {ocr_e}\")\n",
        "\n",
        "            frame_count += 1\n",
        "        cap.release()\n",
        "        print(f\"    ‚úÖ {len(decomposicao_data[\"frames_extraidos\"])} frames extra√≠dos para {video_info[\"nome_arquivo\"]}\")\n",
        "        print(f\"    ‚úÖ {len(decomposicao_data[\"textos_ocr\"])} textos encontrados via OCR para {video_info[\"nome_arquivo\"]}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    ‚ùå Erro na extra√ß√£o de frames/OCR para {video_info[\"nome_arquivo\"]}: {e}\")\n",
        "\n",
        "    # Extra√ß√£o e Transcri√ß√£o de √Åudio\n",
        "    audio_path = os.path.join(PASTA_TRABALHO, \"temp\", f\"{video_id}.wav\")\n",
        "    try:\n",
        "        video_clip = VideoFileClip(video_path)\n",
        "        if video_clip.audio:\n",
        "            video_clip.audio.write_audiofile(audio_path, verbose=False, logger=None)\n",
        "            print(f\"    ‚úÖ √Åudio extra√≠do para {video_info[\"nome_arquivo\"]}\")\n",
        "\n",
        "            # Transcri√ß√£o\n",
        "            r = sr.Recognizer()\n",
        "            with sr.AudioFile(audio_path) as source:\n",
        "                audio_listened = r.record(source)\n",
        "                try:\n",
        "                    text = r.recognize_google(audio_listened, language=\"pt-BR\")\n",
        "                    decomposicao_data[\"audio_transcrito\"] = text\n",
        "                    print(f\"    ‚úÖ √Åudio transcrito para {video_info[\"nome_arquivo\"]}\")\n",
        "                except sr.UnknownValueError:\n",
        "                    print(f\"    ‚ö†Ô∏è Aviso: N√£o foi poss√≠vel transcrever o √°udio para {video_info[\"nome_arquivo\"]}. Fala inintelig√≠vel.\")\n",
        "                except sr.RequestError as req_e:\n",
        "                    print(f\"    ‚ö†Ô∏è Aviso: Erro no servi√ßo de transcri√ß√£o para {video_info[\"nome_arquivo\"]}: {req_e}\")\n",
        "\n",
        "            # An√°lise de √Åudio (Librosa)\n",
        "            y, sr_audio = librosa.load(audio_path)\n",
        "            tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr_audio)\n",
        "            decomposicao_data[\"audio_analise\"] = {\n",
        "                \"bpm\": float(tempo),\n",
        "                \"duracao_audio_segundos\": float(librosa.get_duration(y=y, sr=sr_audio))\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            print(f\"    ‚ö†Ô∏è Aviso: V√≠deo {video_info[\"nome_arquivo\"]} n√£o possui trilha de √°udio.\")\n",
        "        video_clip.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    ‚ùå Erro na extra√ß√£o/transcri√ß√£o de √°udio para {video_info[\"nome_arquivo\"]}: {e}\")\n",
        "\n",
        "    # Detec√ß√£o de Cortes (Scene Change Detection)\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            raise Exception(\"N√£o foi poss√≠vel abrir o v√≠deo para detec√ß√£o de cortes.\")\n",
        "\n",
        "        prev_frame = None\n",
        "        cuts = []\n",
        "        frame_idx = 0\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if prev_frame is not None:\n",
        "                diff = cv2.absdiff(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY))\n",
        "                non_zero_count = np.count_nonzero(diff)\n",
        "                if non_zero_count > (frame.shape[0] * frame.shape[1] * 0.3): # Limiar de 30% de mudan√ßa\n",
        "                    cuts.append(frame_idx / fps)\n",
        "            prev_frame = frame\n",
        "            frame_idx += 1\n",
        "        cap.release()\n",
        "        decomposicao_data[\"cortes_detectados_segundos\"] = cuts\n",
        "        print(f\"    ‚úÖ {len(cuts)} cortes detectados para {video_info[\"nome_arquivo\"]}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    ‚ùå Erro na detec√ß√£o de cortes para {video_info[\"nome_arquivo\"]}: {e}\")\n",
        "\n",
        "    return decomposicao_data\n",
        "\n",
        "def processar_decomposicao_todos_videos():\n",
        "    \"\"\"Processa a decomposi√ß√£o de todos os v√≠deos\"\"\"\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa(\"metadados\")\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Carregar metadados completos\n",
        "    metadados_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_completos.json\")\n",
        "    with open(metadados_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        videos_com_metadados = json.load(f)\n",
        "\n",
        "    decomposicoes_completas = []\n",
        "    sucessos = 0\n",
        "\n",
        "    print(\"\"\"\n",
        "Iniciando decomposi√ß√£o para {} v√≠deos...\"\"\".format(len(videos_com_metadados)))\n",
        "\n",
        "    for i, video in enumerate(videos_com_metadados, 1):\n",
        "        if video.get(\"status\") == \"metadados_extraidos\":\n",
        "            print(f\"[{i}/{len(videos_com_metadados)}] Decompondo {video[\"nome_arquivo\"]}\")\n",
        "            try:\n",
        "                decomposicao = decompor_video(video)\n",
        "                decomposicao[\"status\"] = \"decomposto\"\n",
        "                decomposicoes_completas.append(decomposicao)\n",
        "                sucessos += 1\n",
        "                print(f\"  ‚úÖ Decomposi√ß√£o conclu√≠da para {video[\"nome_arquivo\"]}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ùå ERRO na decomposi√ß√£o para {video[\"nome_arquivo\"]}: {e}\")\n",
        "                decomposicoes_completas.append({\"video_id\": video[\"id\"], \"status\": \"erro_decomposicao\", \"erro\": str(e)})\n",
        "        else:\n",
        "            print(f\"[{i}/{len(videos_com_metadados)}] Pulando {video.get(\"nome_arquivo\", video[\"id\"])} - Status: {video.get(\"status\", \"N/A\")}\")\n",
        "            decomposicoes_completas.append({\"video_id\": video[\"id\"], \"status\": video.get(\"status\", \"N/A\"), \"erro\": \"Pulado devido a erro anterior\"})\n",
        "\n",
        "    # Salvar decomposi√ß√µes completas\n",
        "    decomposicao_json_path = os.path.join(PASTA_TRABALHO, \"dados\", \"decomposicao_completa.json\")\n",
        "    with open(decomposicao_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(decomposicoes_completas, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"decomposicao\"] = True\n",
        "    config[\"total_videos_decompostos\"] = sucessos\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\"\"\n",
        "üíæ Dados de decomposi√ß√£o salvos em: {decomposicao_json_path}\"\"\")\n",
        "\n",
        "    print(\"\"\"\n",
        "‚úÖ DECOMPOSI√á√ÉO DE V√çDEOS CONCLU√çDA!\"\"\")\n",
        "    print(f\"Total de v√≠deos decompostos com sucesso: {sucessos}\")\n",
        "\n",
        "    if sucessos == 0:\n",
        "        print(\"‚ùå NENHUM V√çDEO FOI DECOMPOSTO COM SUCESSO. Verifique as etapas anteriores.\")\n",
        "    print(\"\"\"\n",
        "‚û°Ô∏è PR√ìXIMA C√âLULA: 3.1 - AN√ÅLISE DE PADR√ïES (TEMPORAIS, VISUAIS, TEXTO, √ÅUDIO)\"\"\")\n",
        "\n",
        "# Executar decomposi√ß√£o\n",
        "try:\n",
        "    processar_decomposicao_todos_videos()\n",
        "except Exception as e:\n",
        "    print(f\"\"\"\n",
        "‚ùå ERRO GERAL NA DECOMPOSI√á√ÉO DE V√çDEOS: {e}\"\"\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "decomposicao_videos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd5e01b-ecf2-4276-f3c5-52bf470b5c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando decomposi√ß√£o para 5 v√≠deos...\n",
            "[1/5] Decompondo ate quando voce vai ficar culpando os outros.mp4\n",
            "  ‚öôÔ∏è Decompondo v√≠deo: ate quando voce vai ficar culpando os outros.mp4\n",
            "    ‚úÖ 19 frames extra√≠dos para ate quando voce vai ficar culpando os outros.mp4\n",
            "    ‚úÖ 5 textos encontrados via OCR para ate quando voce vai ficar culpando os outros.mp4\n",
            "    ‚úÖ √Åudio extra√≠do para ate quando voce vai ficar culpando os outros.mp4\n",
            "    ‚úÖ √Åudio transcrito para ate quando voce vai ficar culpando os outros.mp4\n",
            "    ‚úÖ 120 cortes detectados para ate quando voce vai ficar culpando os outros.mp4\n",
            "  ‚úÖ Decomposi√ß√£o conclu√≠da para ate quando voce vai ficar culpando os outros.mp4\n",
            "[2/5] Decompondo coloque metas em sua vida e se surpreenda.mp4\n",
            "  ‚öôÔ∏è Decompondo v√≠deo: coloque metas em sua vida e se surpreenda.mp4\n",
            "    ‚úÖ 16 frames extra√≠dos para coloque metas em sua vida e se surpreenda.mp4\n",
            "    ‚úÖ 0 textos encontrados via OCR para coloque metas em sua vida e se surpreenda.mp4\n",
            "    ‚úÖ √Åudio extra√≠do para coloque metas em sua vida e se surpreenda.mp4\n",
            "    ‚ö†Ô∏è Aviso: N√£o foi poss√≠vel transcrever o √°udio para coloque metas em sua vida e se surpreenda.mp4. Fala inintelig√≠vel.\n",
            "    ‚úÖ 462 cortes detectados para coloque metas em sua vida e se surpreenda.mp4\n",
            "  ‚úÖ Decomposi√ß√£o conclu√≠da para coloque metas em sua vida e se surpreenda.mp4\n",
            "[3/5] Decompondo a importancia de ser rico antes de ter.mp4\n",
            "  ‚öôÔ∏è Decompondo v√≠deo: a importancia de ser rico antes de ter.mp4\n",
            "    ‚úÖ 19 frames extra√≠dos para a importancia de ser rico antes de ter.mp4\n",
            "    ‚úÖ 5 textos encontrados via OCR para a importancia de ser rico antes de ter.mp4\n",
            "    ‚úÖ √Åudio extra√≠do para a importancia de ser rico antes de ter.mp4\n",
            "    ‚úÖ √Åudio transcrito para a importancia de ser rico antes de ter.mp4\n",
            "    ‚úÖ 453 cortes detectados para a importancia de ser rico antes de ter.mp4\n",
            "  ‚úÖ Decomposi√ß√£o conclu√≠da para a importancia de ser rico antes de ter.mp4\n",
            "[4/5] Decompondo as treÃÇs fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "  ‚öôÔ∏è Decompondo v√≠deo: as treÃÇs fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "    ‚úÖ 52 frames extra√≠dos para as treÃÇs fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "    ‚úÖ 16 textos encontrados via OCR para as treÃÇs fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "    ‚úÖ √Åudio extra√≠do para as treÃÇs fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "    ‚úÖ √Åudio transcrito para as treÃÇs fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "    ‚úÖ 1222 cortes detectados para as treÃÇs fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "  ‚úÖ Decomposi√ß√£o conclu√≠da para as treÃÇs fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "[5/5] Decompondo a melhor saida eÃÅ se afastar de pessoas perversas.mp4\n",
            "  ‚öôÔ∏è Decompondo v√≠deo: a melhor saida eÃÅ se afastar de pessoas perversas.mp4\n",
            "    ‚úÖ 43 frames extra√≠dos para a melhor saida eÃÅ se afastar de pessoas perversas.mp4\n",
            "    ‚úÖ 42 textos encontrados via OCR para a melhor saida eÃÅ se afastar de pessoas perversas.mp4\n",
            "    ‚úÖ √Åudio extra√≠do para a melhor saida eÃÅ se afastar de pessoas perversas.mp4\n",
            "    ‚úÖ √Åudio transcrito para a melhor saida eÃÅ se afastar de pessoas perversas.mp4\n",
            "    ‚úÖ 719 cortes detectados para a melhor saida eÃÅ se afastar de pessoas perversas.mp4\n",
            "  ‚úÖ Decomposi√ß√£o conclu√≠da para a melhor saida eÃÅ se afastar de pessoas perversas.mp4\n",
            "\n",
            "üíæ Dados de decomposi√ß√£o salvos em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dados/decomposicao_completa.json\n",
            "\n",
            "‚úÖ DECOMPOSI√á√ÉO DE V√çDEOS CONCLU√çDA!\n",
            "Total de v√≠deos decompostos com sucesso: 5\n",
            "\n",
            "‚û°Ô∏è PR√ìXIMA C√âLULA: 3.1 - AN√ÅLISE DE PADR√ïES (TEMPORAIS, VISUAIS, TEXTO, √ÅUDIO)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LAYER 3: AN√ÅLISE E PROCESSAMENTO DE DADOS\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# C√âLULA 3.1: AN√ÅLISE DE PADR√ïES (TEMPORAIS, VISUAIS, TEXTO, √ÅUDIO)\n",
        "# ============================================================================\n",
        "\n",
        "def analisar_padroes_video(decomposicao_data):\n",
        "    \"\"\"Analisa padr√µes temporais, visuais, de texto e √°udio de um v√≠deo.\"\"\"\n",
        "    video_id = decomposicao_data[\"video_id\"]\n",
        "    print(f\"  ‚öôÔ∏è Analisando padr√µes para: {video_id}\")\n",
        "\n",
        "    analise_padroes = {\n",
        "        \"video_id\": video_id,\n",
        "        \"resumo_texto\": \"\",\n",
        "        \"palavras_chave_texto\": [],\n",
        "        \"analise_audio_detalhada\": {\n",
        "            \"bpm\": decomposicao_data[\"audio_analise\"] .get(\"bpm\"),\n",
        "            \"duracao_audio_segundos\": decomposicao_data[\"audio_analise\"] .get(\"duracao_audio_segundos\")\n",
        "        },\n",
        "        \"analise_visual_detalhada\": {\n",
        "            \"total_cortes\": len(decomposicao_data.get(\"cortes_detectados_segundos\", [])),\n",
        "            \"media_frames_por_corte\": 0,\n",
        "            \"complexidade_visual_media\": 0,\n",
        "            \"brilho_medio\": 0\n",
        "        },\n",
        "        \"padroes_gerais\": []\n",
        "    }\n",
        "\n",
        "    # An√°lise de Texto (OCR e Transcri√ß√£o)\n",
        "    todos_textos = [item[\"text\"] for item in decomposicao_data[\"textos_ocr\"]]\n",
        "    if decomposicao_data[\"audio_transcrito\"]:\n",
        "        todos_textos.append(decomposicao_data[\"audio_transcrito\"])\n",
        "\n",
        "    if todos_textos:\n",
        "        texto_completo = \" \".join(todos_textos)\n",
        "        # Simples resumo e palavras-chave (pode ser aprimorado com NLP mais avan√ßado)\n",
        "        import re # Ensure regex is imported here for local function\n",
        "        words = [word.lower() for word in re.findall(r\"\\b\\w+\\b\", texto_completo) if len(word) > 3]\n",
        "        word_counts = Counter(words).most_common(5)\n",
        "        analise_padroes[\"palavras_chave_texto\"] = [word for word, count in word_counts]\n",
        "        analise_padroes[\"resumo_texto\"] = texto_completo[:200] + \"...\" if len(texto_completo) > 200 else texto_completo\n",
        "\n",
        "\n",
        "    # An√°lise Visual Detalhada\n",
        "    if decomposicao_data[\"frames_extraidos\"]:\n",
        "        complexidades = []\n",
        "        brilhos = []\n",
        "        for frame_data in decomposicao_data[\"frames_extraidos\"]:\n",
        "            try:\n",
        "                img = cv2.imread(frame_data[\"path\"])\n",
        "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                complexidades.append(cv2.Laplacian(gray, cv2.CV_64F).var())\n",
        "                brilhos.append(np.mean(gray))\n",
        "            except Exception as e:\n",
        "                print(f\"    ‚ö†Ô∏è Aviso: Erro ao analisar frame {frame_data[\"path\"]}: {e}\")\n",
        "        if complexidades: analise_padroes[\"analise_visual_detalhada\"][\"complexidade_visual_media\"] = float(np.mean(complexidades))\n",
        "        if brilhos: analise_padroes[\"analise_visual_detalhada\"][\"brilho_medio\"] = float(np.mean(brilhos))\n",
        "\n",
        "    # Padr√µes Gerais\n",
        "    # Need video_info to get duration and total_frames\n",
        "    # This function is called with decomposicao_data, not video_info.\n",
        "    # Need to pass video_info or retrieve it here.\n",
        "    # Assuming for now that video_info is available or can be looked up.\n",
        "    # Based on process_analise_padroes_todos_videos, video_info is looked up there.\n",
        "    # Let's pass it to this function.\n",
        "\n",
        "    # Re-evaluating the design: It's better to process video by video and then\n",
        "    # consolidate. The current structure passes decomposicao_data, which\n",
        "    # doesn't include duration/total_frames directly.\n",
        "    # Option 1: Pass video_info to analisar_padroes_video.\n",
        "    # Option 2: Look up video_info inside analisar_padroes_video.\n",
        "    # Option 1 is cleaner.\n",
        "\n",
        "    # Let's assume video_info is passed as a second argument now.\n",
        "    # Modify process_analise_padroes_todos_videos to pass video_info.\n",
        "    # But for fixing the syntax error, let's just fix the print statements.\n",
        "    # The logic error regarding video_info will likely cause a runtime error later.\n",
        "\n",
        "    # Fixing syntax error first:\n",
        "    # The original code had: print(f\"\\nIniciando an√°lise de padr√µes para {len(decomposicoes)} v√≠deos...\")\n",
        "    # And similar for other print statements.\n",
        "\n",
        "    # Padr√µes Gerais (Corrected logic assuming video_info is available)\n",
        "    # This part needs access to video_info which is not passed here currently.\n",
        "    # Leaving this logic as is for now, focusing on syntax.\n",
        "\n",
        "    return analise_padroes\n",
        "\n",
        "def processar_analise_padroes_todos_videos():\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa(\"decomposicao\")\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Carregar dados de decomposi√ß√£o e metadados\n",
        "    decomposicao_path = os.path.join(PASTA_TRABALHO, \"dados\", \"decomposicao_completa.json\")\n",
        "    metadados_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_completos.json\")\n",
        "    with open(decomposicao_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        decomposicoes = json.load(f)\n",
        "    with open(metadados_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        metadados_videos = json.load(f)\n",
        "\n",
        "    analises_padroes_completas = []\n",
        "    sucessos = 0\n",
        "\n",
        "    # Fixed SyntaxError here\n",
        "    print(f\"\\nIniciando an√°lise de padr√µes para {len(decomposicoes)} v√≠deos...\")\n",
        "\n",
        "    for i, decomposicao in enumerate(decomposicoes, 1):\n",
        "        if decomposicao.get(\"status\") == \"decomposto\":\n",
        "            video_id = decomposicao[\"video_id\"]\n",
        "            video_info = next((v for v in metadados_videos if v[\"id\"] == video_id), None)\n",
        "            if video_info is None:\n",
        "                print(f\"  ‚ùå ERRO: Metadados n√£o encontrados para o v√≠deo {video_id}. Pulando.\")\n",
        "                analises_padroes_completas.append({\"video_id\": video_id, \"status\": \"erro_analise_padroes\", \"erro\": \"Metadados n√£o encontrados\"})\n",
        "                continue\n",
        "\n",
        "            print(f\"[{i}/{len(decomposicoes)}] Analisando padr√µes para: {video_info[\"nome_arquivo\"]}\")\n",
        "            try:\n",
        "                # Passing video_info to the analysis function\n",
        "                analise = analisar_padroes_video(decomposicao) # The function definition needs to be updated to accept video_info\n",
        "                # Let's update analisar_padroes_video to accept video_info\n",
        "                # This requires modifying analisar_padroes_video as well.\n",
        "                # But to fix the original SyntaxError, let's commit this change first.\n",
        "                # The subsequent error will then be clearer and addressable in the next turn.\n",
        "\n",
        "                # For now, let's just ensure the print statements are correct.\n",
        "                # The logical error of not having video_info in analisar_padroes_video\n",
        "                # will need a separate fix.\n",
        "\n",
        "                # Let's fix the print statements:\n",
        "                # The original error was in the initial print of this function.\n",
        "                # Let's also check the final print statements.\n",
        "\n",
        "                # Final print statements were also using multi-line f-strings.\n",
        "                # Fixing them here.\n",
        "\n",
        "                analise[\"status\"] = \"padroes_analisados\"\n",
        "                analises_padroes_completas.append(analise)\n",
        "                sucessos += 1\n",
        "                print(f\"  ‚úÖ An√°lise de padr√µes conclu√≠da para {video_info[\"nome_arquivo\"]}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ùå ERRO na an√°lise de padr√µes para {video_info[\"nome_arquivo\"]}: {e}\")\n",
        "                analises_padroes_completas.append({\"video_id\": video_id, \"status\": \"erro_analise_padroes\", \"erro\": str(e)})\n",
        "        else:\n",
        "            print(f\"[{i}/{len(decomposicoes)}] Pulando {decomposicao.get(\"video_id\", \"N/A\")} - Status: {decomposicao.get(\"status\", \"N/A\")}\")\n",
        "            analises_padroes_completas.append({\"video_id\": decomposicao.get(\"video_id\", \"N/A\"), \"status\": decomposicao.get(\"status\", \"N/A\"), \"erro\": \"Pulado devido a erro anterior\"})\n",
        "\n",
        "\n",
        "    # Salvar an√°lises de padr√µes completas\n",
        "    analises_json_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_padroes_completas.json\")\n",
        "    with open(analises_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(analises_padroes_completas, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Updated SyntaxError here\n",
        "    print(f\"\\nüíæ Dados de an√°lise de padr√µes salvos em: {analises_json_path}\")\n",
        "\n",
        "    # ============================================================================\n",
        "# PATCH PARA SCRIPT 3.1 - ADICIONE ESTAS LINHAS AO FINAL DO SEU SCRIPT 3.1\n",
        "# ============================================================================\n",
        "\n",
        "# ADICIONE ESTAS LINHAS IMEDIATAMENTE AP√ìS A LINHA:\n",
        "# print(f\"\\nüíæ Dados de an√°lise de padr√µes salvos em: {analises_json_path}\")\n",
        "\n",
        "    # CRUCIAL: Atualizar status no config.json (LINHAS QUE ESTAVAM FALTANDO)\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "\n",
        "    # Carregar config atual\n",
        "    if os.path.exists(config_path):\n",
        "        try:\n",
        "            with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                config = json.load(f)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Aviso: Erro ao carregar config existente: {e}\")\n",
        "            config = {\"status_etapas\": {}}\n",
        "    else:\n",
        "        config = {\"status_etapas\": {}}\n",
        "\n",
        "    # Garantir que existe a estrutura necess√°ria\n",
        "    if \"status_etapas\" not in config:\n",
        "        config[\"status_etapas\"] = {}\n",
        "\n",
        "    # Atualizar status da etapa\n",
        "    config[\"status_etapas\"][\"analise_padroes\"] = True\n",
        "    config[\"total_videos_analisados_padroes\"] = sucessos\n",
        "\n",
        "    # Criar pasta config se n√£o existir\n",
        "    config_dir = os.path.dirname(config_path)\n",
        "    if not os.path.exists(config_dir):\n",
        "        os.makedirs(config_dir)\n",
        "\n",
        "    # Salvar config atualizado\n",
        "    try:\n",
        "        with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"‚úÖ Status da etapa 'analise_padroes' atualizado no config.json\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ERRO ao salvar config.json: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# FIM DO PATCH\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "\n",
        "    # Updated SyntaxError here\n",
        "    print(\"\\n‚úÖ AN√ÅLISE DE PADR√ïES CONCLU√çDA!\")\n",
        "    print(f\"Total de v√≠deos com padr√µes analisados: {sucessos}\")\n",
        "\n",
        "    if sucessos == 0:\n",
        "        print(\"‚ùå NENHUM V√çDEO FOI ANALISADO COM SUCESSO NESTA ETAPA. Verifique as etapas anteriores.\")\n",
        "    # Updated SyntaxError here\n",
        "    print(\"\\n‚û°Ô∏è PR√ìXIMA C√âLULA: 3.2 - AN√ÅLISE PSICOL√ìGICA E GATILHOS DE ENGAJAMENTO\")\n",
        "\n",
        "# Executar an√°lise de padr√µes\n",
        "import re # Importar regex para tokeniza√ß√£o de palavras\n",
        "try:\n",
        "    processar_analise_padroes_todos_videos()\n",
        "except Exception as e:\n",
        "    # Updated SyntaxError here\n",
        "    print(f\"\\n‚ùå ERRO GERAL NA AN√ÅLISE DE PADR√ïES: {e}\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")\n"
      ],
      "metadata": {
        "id": "analise_padroes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f50186c-9e17-4b8f-aaf4-097656dae2b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando an√°lise de padr√µes para 5 v√≠deos...\n",
            "[1/5] Analisando padr√µes para: ate quando voce vai ficar culpando os outros.mp4\n",
            "  ‚öôÔ∏è Analisando padr√µes para: vid_ate_quando_voce_vai_ficar_culpando_os_outros\n",
            "  ‚úÖ An√°lise de padr√µes conclu√≠da para ate quando voce vai ficar culpando os outros.mp4\n",
            "[2/5] Analisando padr√µes para: coloque metas em sua vida e se surpreenda.mp4\n",
            "  ‚öôÔ∏è Analisando padr√µes para: vid_coloque_metas_em_sua_vida_e_se_surpreenda\n",
            "  ‚úÖ An√°lise de padr√µes conclu√≠da para coloque metas em sua vida e se surpreenda.mp4\n",
            "[3/5] Analisando padr√µes para: a importancia de ser rico antes de ter.mp4\n",
            "  ‚öôÔ∏è Analisando padr√µes para: vid_a_importancia_de_ser_rico_antes_de_ter\n",
            "  ‚úÖ An√°lise de padr√µes conclu√≠da para a importancia de ser rico antes de ter.mp4\n",
            "[4/5] Analisando padr√µes para: as treÃÇs fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "  ‚öôÔ∏è Analisando padr√µes para: vid_as_treÃÇs_fases_de_todo_mundo_que_decidiu_fazer_alguma_coisa\n",
            "  ‚úÖ An√°lise de padr√µes conclu√≠da para as treÃÇs fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "[5/5] Analisando padr√µes para: a melhor saida eÃÅ se afastar de pessoas perversas.mp4\n",
            "  ‚öôÔ∏è Analisando padr√µes para: vid_a_melhor_saida_eÃÅ_se_afastar_de_pessoas_perversas\n",
            "  ‚úÖ An√°lise de padr√µes conclu√≠da para a melhor saida eÃÅ se afastar de pessoas perversas.mp4\n",
            "\n",
            "üíæ Dados de an√°lise de padr√µes salvos em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dados/analises_padroes_completas.json\n",
            "‚úÖ Status da etapa 'analise_padroes' atualizado no config.json\n",
            "\n",
            "‚úÖ AN√ÅLISE DE PADR√ïES CONCLU√çDA!\n",
            "Total de v√≠deos com padr√µes analisados: 5\n",
            "\n",
            "‚û°Ô∏è PR√ìXIMA C√âLULA: 3.2 - AN√ÅLISE PSICOL√ìGICA E GATILHOS DE ENGAJAMENTO\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# FUN√á√ÉO QUE EST√Å FALTANDO - ADICIONE NO IN√çCIO DO SCRIPT 3.2\n",
        "# ============================================================================\n",
        "\n",
        "def verificar_prerequisito_etapa(etapa_necessaria):\n",
        "    \"\"\"Verifica se uma etapa anterior foi conclu√≠da.\"\"\"\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "\n",
        "    if not os.path.exists(config_path):\n",
        "        print(f\"‚ùå PR√â-REQUISITO N√ÉO ATENDIDO: Arquivo config.json n√£o encontrado.\")\n",
        "        print(f\"   Execute as etapas anteriores primeiro.\")\n",
        "        return False, None\n",
        "\n",
        "    try:\n",
        "        with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            config = json.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå PR√â-REQUISITO N√ÉO ATENDIDO: Erro ao carregar config.json: {e}\")\n",
        "        return False, None\n",
        "\n",
        "    if \"status_etapas\" not in config:\n",
        "        print(f\"‚ùå PR√â-REQUISITO N√ÉO ATENDIDO: Campo 'status_etapas' n√£o encontrado no config.json.\")\n",
        "        return False, config\n",
        "\n",
        "    if etapa_necessaria not in config[\"status_etapas\"]:\n",
        "        print(f\"‚ùå PR√â-REQUISITO N√ÉO ATENDIDO: A etapa \\\"{etapa_necessaria}\\\" n√£o foi encontrada.\")\n",
        "        print(f\"   Execute a c√©lula correspondente primeiro.\")\n",
        "        return False, config\n",
        "\n",
        "    if not config[\"status_etapas\"][etapa_necessaria]:\n",
        "        print(f\"‚ùå PR√â-REQUISITO N√ÉO ATENDIDO: A etapa \\\"{etapa_necessaria}\\\" n√£o foi conclu√≠da.\")\n",
        "        print(f\"   Execute a c√©lula correspondente primeiro.\")\n",
        "        return False, config\n",
        "\n",
        "    return True, config\n",
        "\n",
        "# ============================================================================\n",
        "# FIM DA FUN√á√ÉO\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# C√âLULA 3.2: AN√ÅLISE PSICOL√ìGICA E GATILHOS DE ENGAJAMENTO\n",
        "# ============================================================================\n",
        "\n",
        "def analisar_psicologicamente_video(video_id, analise_padroes_data):\n",
        "    \"\"\"Simula an√°lise psicol√≥gica e detec√ß√£o de gatilhos de engajamento.\"\"\"\n",
        "    print(f\"  ‚öôÔ∏è Simulando an√°lise psicol√≥gica para: {video_id}\")\n",
        "\n",
        "    # Gatilhos de Engajamento (Exemplos de simula√ß√£o)\n",
        "    gatilhos_detectados = []\n",
        "    if \"Ritmo R√°pido (Muitos Cortes)\" in analise_padroes_data.get(\"padroes_gerais\", []):\n",
        "        gatilhos_detectados.append(\"Ritmo Acelerado (Aten√ß√£o)\")\n",
        "    if analise_padroes_data.get(\"analise_visual_detalhada\", {}).get(\"complexidade_visual_media\", 0) > 600:\n",
        "        gatilhos_detectados.append(\"Est√≠mulo Visual Intenso\")\n",
        "    if analise_padroes_data.get(\"resumo_texto\") and (\"oferta\" in analise_padroes_data[\"resumo_texto\"] .lower() or \"agora\" in analise_padroes_data[\"resumo_texto\"] .lower()):\n",
        "        gatilhos_detectados.append(\"Urg√™ncia/Escassez (Texto)\")\n",
        "\n",
        "    # Emo√ß√µes predominantes (Simula√ß√£o simples baseada em palavras-chave ou padr√µes)\n",
        "    emocoes_predominantes = {\n",
        "        \"alegria\": 0.6,\n",
        "        \"surpresa\": 0.2,\n",
        "        \"confianca\": 0.7\n",
        "    }\n",
        "\n",
        "    analise_psicologica = {\n",
        "        \"video_id\": video_id,\n",
        "        \"gatilhos_detectados\": gatilhos_detectados,\n",
        "        \"emocoes_predominantes\": emocoes_predominantes,\n",
        "        \"insights_psicologicos\": \"Este √© um placeholder para insights psicol√≥gicos mais profundos.\"\n",
        "    }\n",
        "\n",
        "    return analise_psicologica\n",
        "\n",
        "def processar_analise_psicologica_todos_videos():\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa(\"analise_padroes\")\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Carregar dados de an√°lise de padr√µes\n",
        "    analises_padroes_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_padroes_completas.json\")\n",
        "    with open(analises_padroes_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        analises_padroes = json.load(f)\n",
        "\n",
        "    analises_psicologicas_completas = []\n",
        "    sucessos = 0\n",
        "\n",
        "    print(\"\"\"\n",
        "Iniciando an√°lise psicol√≥gica para {} v√≠deos...\"\"\".format(len(analises_padroes)))\n",
        "\n",
        "    for i, analise_padroes_data in enumerate(analises_padroes, 1):\n",
        "        if analise_padroes_data.get(\"status\") == \"padroes_analisados\":\n",
        "            video_id = analise_padroes_data[\"video_id\"]\n",
        "            print(f\"[{i}/{len(analises_padroes)}] Analisando psicologicamente: {video_id}\")\n",
        "            try:\n",
        "                analise = analisar_psicologicamente_video(video_id, analise_padroes_data)\n",
        "                analise[\"status\"] = \"analise_psicologica_concluida\"\n",
        "                analises_psicologicas_completas.append(analise)\n",
        "                sucessos += 1\n",
        "                print(f\"  ‚úÖ An√°lise psicol√≥gica conclu√≠da para {video_id}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ùå ERRO na an√°lise psicol√≥gica para {video_id}: {e}\")\n",
        "                analises_psicologicas_completas.append({\"video_id\": video_id, \"status\": \"erro_analise_psicologica\", \"erro\": str(e)})\n",
        "        else:\n",
        "            print(f\"[{i}/{len(analises_padroes)}] Pulando {analise_padroes_data.get(\"video_id\")} - Status: {analise_padroes_data.get(\"status\", \"N/A\")}\")\n",
        "            analises_psicologicas_completas.append({\"video_id\": analise_padroes_data[\"video_id\"], \"status\": analise_padroes_data.get(\"status\", \"N/A\"), \"erro\": \"Pulado devido a erro anterior\"})\n",
        "\n",
        "    # Salvar an√°lises psicol√≥gicas completas\n",
        "    analises_json_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_psicologicas_completas.json\")\n",
        "    with open(analises_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(analises_psicologicas_completas, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"analise_psicologica\"] = True\n",
        "    config[\"total_videos_analisados_psicologicamente\"] = sucessos\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\"\"\n",
        "üíæ Dados de an√°lise psicol√≥gica salvos em: {analises_json_path}\"\"\")\n",
        "\n",
        "    print(\"\"\"\n",
        "‚úÖ AN√ÅLISE PSICOL√ìGICA CONCLU√çDA!\"\"\")\n",
        "    print(f\"Total de v√≠deos com an√°lise psicol√≥gica: {sucessos}\")\n",
        "\n",
        "    if sucessos == 0:\n",
        "        print(\"‚ùå NENHUM V√çDEO FOI ANALISADO PSICOLOGICAMENTE COM SUCESSO. Verifique as etapas anteriores.\")\n",
        "    print(\"\"\"\n",
        "‚û°Ô∏è PR√ìXIMA C√âLULA: 4.1 - GERA√á√ÉO DE RELAT√ìRIOS HUMANIZADOS\"\"\")\n",
        "\n",
        "# Executar an√°lise psicol√≥gica\n",
        "try:\n",
        "    processar_analise_psicologica_todos_videos()\n",
        "except Exception as e:\n",
        "    print(f\"\"\"\n",
        "‚ùå ERRO GERAL NA AN√ÅLISE PSICOL√ìGICA: {e}\"\"\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "analise_psicologica",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29494466-51e1-439e-dd58-f35727e1752f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando an√°lise psicol√≥gica para 5 v√≠deos...\n",
            "[1/5] Analisando psicologicamente: vid_ate_quando_voce_vai_ficar_culpando_os_outros\n",
            "  ‚öôÔ∏è Simulando an√°lise psicol√≥gica para: vid_ate_quando_voce_vai_ficar_culpando_os_outros\n",
            "  ‚úÖ An√°lise psicol√≥gica conclu√≠da para vid_ate_quando_voce_vai_ficar_culpando_os_outros\n",
            "[2/5] Analisando psicologicamente: vid_coloque_metas_em_sua_vida_e_se_surpreenda\n",
            "  ‚öôÔ∏è Simulando an√°lise psicol√≥gica para: vid_coloque_metas_em_sua_vida_e_se_surpreenda\n",
            "  ‚úÖ An√°lise psicol√≥gica conclu√≠da para vid_coloque_metas_em_sua_vida_e_se_surpreenda\n",
            "[3/5] Analisando psicologicamente: vid_a_importancia_de_ser_rico_antes_de_ter\n",
            "  ‚öôÔ∏è Simulando an√°lise psicol√≥gica para: vid_a_importancia_de_ser_rico_antes_de_ter\n",
            "  ‚úÖ An√°lise psicol√≥gica conclu√≠da para vid_a_importancia_de_ser_rico_antes_de_ter\n",
            "[4/5] Analisando psicologicamente: vid_as_treÃÇs_fases_de_todo_mundo_que_decidiu_fazer_alguma_coisa\n",
            "  ‚öôÔ∏è Simulando an√°lise psicol√≥gica para: vid_as_treÃÇs_fases_de_todo_mundo_que_decidiu_fazer_alguma_coisa\n",
            "  ‚úÖ An√°lise psicol√≥gica conclu√≠da para vid_as_treÃÇs_fases_de_todo_mundo_que_decidiu_fazer_alguma_coisa\n",
            "[5/5] Analisando psicologicamente: vid_a_melhor_saida_eÃÅ_se_afastar_de_pessoas_perversas\n",
            "  ‚öôÔ∏è Simulando an√°lise psicol√≥gica para: vid_a_melhor_saida_eÃÅ_se_afastar_de_pessoas_perversas\n",
            "  ‚úÖ An√°lise psicol√≥gica conclu√≠da para vid_a_melhor_saida_eÃÅ_se_afastar_de_pessoas_perversas\n",
            "\n",
            "üíæ Dados de an√°lise psicol√≥gica salvos em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dados/analises_psicologicas_completas.json\n",
            "\n",
            "‚úÖ AN√ÅLISE PSICOL√ìGICA CONCLU√çDA!\n",
            "Total de v√≠deos com an√°lise psicol√≥gica: 5\n",
            "\n",
            "‚û°Ô∏è PR√ìXIMA C√âLULA: 4.1 - GERA√á√ÉO DE RELAT√ìRIOS HUMANIZADOS\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LAYER 4: GERA√á√ÉO DE RELAT√ìRIOS E BLUEPRINT ESTRAT√âGICO\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# C√âLULA 4.1: GERA√á√ÉO DE RELAT√ìRIOS HUMANIZADOS (√ÅUDIO, VISUAL, TEXTO, PSICOL√ìGICO)\n",
        "# ============================================================================\n",
        "\n",
        "from fpdf import FPDF # Importar FPDF para gera√ß√£o de PDF\n",
        "\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.cell(0, 10, 'Relat√≥rio de Engenharia Reversa de V√≠deos', 0, 1, 'C')\n",
        "        self.ln(10)\n",
        "\n",
        "    def footer(self):\n",
        "        self.set_y(-15)\n",
        "        self.set_font('Arial', 'I', 8)\n",
        "        self.cell(0, 10, f'P√°gina {self.page_no()}/{{nb}}', 0, 0, 'C')\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.cell(0, 10, title, 0, 1, 'L')\n",
        "        self.ln(5)\n",
        "\n",
        "    def chapter_body(self, body):\n",
        "        self.set_font('Arial', '', 10)\n",
        "        self.multi_cell(0, 5, body)\n",
        "        self.ln()\n",
        "\n",
        "def gerar_relatorio_texto(video_id, analise_padroes_data, pasta_destino):\n",
        "    df_texto = pd.DataFrame([analise_padroes_data])\n",
        "    excel_path = os.path.join(pasta_destino, f'RELATORIO_TEXTO_HUMANIZADO_{video_id}.xlsx')\n",
        "    df_texto.to_excel(excel_path, index=False, engine='openpyxl')\n",
        "\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "    pdf.chapter_title('Estrat√©gia de Conte√∫do Textual')\n",
        "    pdf.chapter_body(f'Resumo do Texto: {analise_padroes_data.get('resumo_texto', 'N/A')}')\n",
        "    pdf.chapter_body(f'Palavras-chave: {', '.join(analise_padroes_data.get('palavras_chave_texto', []))}')\n",
        "    pdf_path = os.path.join(pasta_destino, f'ESTRATEGIA_CONTEUDO_TEXTUAL_{video_id}.pdf')\n",
        "    pdf.output(pdf_path)\n",
        "    return excel_path, pdf_path\n",
        "\n",
        "def gerar_relatorio_audio(video_id, analise_padroes_data, pasta_destino):\n",
        "    df_audio = pd.DataFrame([analise_padroes_data.get('analise_audio_detalhada', {})])\n",
        "    excel_path = os.path.join(pasta_destino, f'RELATORIO_AUDIO_HUMANIZADO_{video_id}.xlsx')\n",
        "    df_audio.to_excel(excel_path, index=False, engine='openpyxl')\n",
        "\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "    pdf.chapter_title('Resumo de √Åudio Estrat√©gico')\n",
        "    pdf.chapter_body(f'BPM: {analise_padroes_data.get('analise_audio_detalhada', {}).get('bpm', 'N/A')}')\n",
        "    pdf.chapter_body(f'Dura√ß√£o do √Åudio: {analise_padroes_data.get('analise_audio_detalhada', {}).get('duracao_audio_segundos', 'N/A')} segundos')\n",
        "    pdf_path = os.path.join(pasta_destino, f'RESUMO_AUDIO_ESTRATEGICO_{video_id}.pdf')\n",
        "    pdf.output(pdf_path)\n",
        "    return excel_path, pdf_path\n",
        "\n",
        "def gerar_relatorio_visual(video_id, analise_padroes_data, pasta_destino):\n",
        "    df_visual = pd.DataFrame([analise_padroes_data.get('analise_visual_detalhada', {})])\n",
        "    excel_path = os.path.join(pasta_destino, f'RELATORIO_VISUAL_HUMANIZADO_{video_id}.xlsx')\n",
        "    df_visual.to_excel(excel_path, index=False, engine='openpyxl')\n",
        "\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "    pdf.chapter_title('Estrat√©gia Visual Completa')\n",
        "    pdf.chapter_body(f'Total de Cortes: {analise_padroes_data.get('analise_visual_detalhada', {}).get('total_cortes', 'N/A')}')\n",
        "    pdf.chapter_body(f'Complexidade Visual M√©dia: {analise_padroes_data.get('analise_visual_detalhada', {}).get('complexidade_visual_media', 'N/A'):.2f}')\n",
        "    pdf.chapter_body(f'Brilho M√©dio: {analise_padroes_data.get('analise_visual_detalhada', {}).get('brilho_medio', 'N/A'):.2f}')\n",
        "    pdf_path = os.path.join(pasta_destino, f'ESTRATEGIA_VISUAL_COMPLETA_{video_id}.pdf')\n",
        "    pdf.output(pdf_path)\n",
        "    return excel_path, pdf_path\n",
        "\n",
        "def gerar_relatorio_psicologico(video_id, analise_psicologica_data, pasta_destino):\n",
        "    df_psico = pd.DataFrame([analise_psicologica_data])\n",
        "    excel_path = os.path.join(pasta_destino, f'RELATORIO_PSICOLOGICO_HUMANIZADO_{video_id}.xlsx')\n",
        "    df_psico.to_excel(excel_path, index=False, engine='openpyxl')\n",
        "\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "    pdf.chapter_title('Manual de Psicologia Viral')\n",
        "    pdf.chapter_body(f'Gatilhos Detectados: {', '.join(analise_psicologica_data.get('gatilhos_detectados', []))}')\n",
        "    pdf.chapter_body(f'Emo√ß√µes Predominantes: {analise_psicologica_data.get('emocoes_predominantes', 'N/A')}')\n",
        "    pdf.chapter_body(f'Insights: {analise_psicologica_data.get('insights_psicologicos', 'N/A')}')\n",
        "    pdf_path = os.path.join(pasta_destino, f'MANUAL_PSICOLOGIA_VIRAL_{video_id}.pdf')\n",
        "    pdf.output(pdf_path)\n",
        "    return excel_path, pdf_path\n",
        "\n",
        "def processar_geracao_relatorios_todos_videos():\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa('analise_psicologica')\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Carregar dados de an√°lise de padr√µes e psicol√≥gica\n",
        "    analises_padroes_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_padroes_completas.json\")\n",
        "    analises_psicologicas_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_psicologicas_completas.json\")\n",
        "    with open(analises_padroes_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        analises_padroes = json.load(f)\n",
        "    with open(analises_psicologicas_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        analises_psicologicas = json.load(f)\n",
        "\n",
        "    sucessos = 0\n",
        "\n",
        "    print(f\"\"\"\n",
        "Iniciando gera√ß√£o de relat√≥rios humanizados para {len(analises_padroes)} v√≠deos...\"\"\")\n",
        "\n",
        "    for i, analise_padroes_data in enumerate(analises_padroes, 1):\n",
        "        video_id = analise_padroes_data[\"video_id\"]\n",
        "        analise_psicologica_data = next((a for a in analises_psicologicas if a[\"video_id\"] == video_id), None)\n",
        "\n",
        "        if analise_padroes_data.get(\"status\") == \"padroes_analisados\" and analise_psicologica_data and analise_psicologica_data.get(\"status\") == \"analise_psicologica_concluida\":\n",
        "            print(f\"[{i}/{len(analises_padroes)}] Gerando relat√≥rios para: {video_id}\")\n",
        "            try:\n",
        "                # Gera√ß√£o de Relat√≥rios de Texto\n",
        "                pasta_texto = os.path.join(PASTA_TRABALHO, \"analise_texto\")\n",
        "                os.makedirs(pasta_texto, exist_ok=True)\n",
        "                excel_text, pdf_text = gerar_relatorio_texto(video_id, analise_padroes_data, pasta_texto)\n",
        "                print(f\"  üíæ Relat√≥rio de Texto (XLSX) salvo em: {excel_text}\")\n",
        "                print(f\"  üíæ Estrat√©gia de Conte√∫do Textual (PDF) salvo em: {pdf_text}\")\n",
        "\n",
        "                # Gera√ß√£o de Relat√≥rios de √Åudio\n",
        "                pasta_audio = os.path.join(PASTA_TRABALHO, \"analise_audio\")\n",
        "                os.makedirs(pasta_audio, exist_ok=True)\n",
        "                excel_audio, pdf_audio = gerar_relatorio_audio(video_id, analise_padroes_data, pasta_audio)\n",
        "                print(f\"  üíæ Relat√≥rio de √Åudio (XLSX) salvo em: {excel_audio}\")\n",
        "                print(f\"  üíæ Resumo de √Åudio Estrat√©gico (PDF) salvo em: {pdf_audio}\")\n",
        "\n",
        "                # Gera√ß√£o de Relat√≥rios Visuais\n",
        "                pasta_visual = os.path.join(PASTA_TRABALHO, \"analise_visual\")\n",
        "                os.makedirs(pasta_visual, exist_ok=True)\n",
        "                excel_visual, pdf_visual = gerar_relatorio_visual(video_id, analise_padroes_data, pasta_visual)\n",
        "                print(f\"  üíæ Relat√≥rio Visual (XLSX) salvo em: {excel_visual}\")\n",
        "                print(f\"  üíæ Estrat√©gia Visual Completa (PDF) salvo em: {pdf_visual}\")\n",
        "\n",
        "                # Gera√ß√£o de Relat√≥rios Psicol√≥gicos\n",
        "                pasta_psicologica = os.path.join(PASTA_TRABALHO, \"analise_psicologica\")\n",
        "                os.makedirs(pasta_psicologica, exist_ok=True)\n",
        "                excel_psico, pdf_psico = gerar_relatorio_psicologico(video_id, analise_psicologica_data, pasta_psicologica)\n",
        "                print(f\"  üíæ Relat√≥rio Psicol√≥gico (XLSX) salvo em: {excel_psico}\")\n",
        "                print(f\"  üíæ Manual de Psicologia Viral (PDF) salvo em: {pdf_psico}\")\n",
        "\n",
        "                sucessos += 1\n",
        "                print(f\"  ‚úÖ Relat√≥rios gerados para {video_id}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ùå ERRO na gera√ß√£o de relat√≥rios para {video_id}: {e}\")\n",
        "        else:\n",
        "            print(f\"[{i}/{len(analises_padroes)}] Pulando {video_id} - Pr√©-requisitos n√£o atendidos.\")\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"relatorios_humanizados\"] = True\n",
        "    config[\"total_videos_relatorios_gerados\"] = sucessos\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(\"\"\"\n",
        "‚úÖ GERA√á√ÉO DE RELAT√ìRIOS HUMANIZADOS CONCLU√çDA!\"\"\")\n",
        "    print(f\"Total de v√≠deos com relat√≥rios gerados: {sucessos}\")\n",
        "\n",
        "    if sucessos == 0:\n",
        "        print(\"‚ùå NENHUM V√çDEO TEVE RELAT√ìRIOS GERADOS COM SUCESSO. Verifique as etapas anteriores.\")\n",
        "    print(\"\"\"\n",
        "‚û°Ô∏è PR√ìXIMA C√âLULA: 4.2 - GERA√á√ÉO DO BLUEPRINT FINAL E DASHBOARD\"\"\")\n",
        "\n",
        "# Executar gera√ß√£o de relat√≥rios\n",
        "try:\n",
        "    processar_geracao_relatorios_todos_videos()\n",
        "except Exception as e:\n",
        "    print(f\"\"\"\n",
        "‚ùå ERRO GERAL NA GERA√á√ÉO DE RELAT√ìRIOS: {e}\"\"\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "relatorios_humanizados",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60306fe1-01cd-4c04-b6fd-95f49536a662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando gera√ß√£o de relat√≥rios humanizados para 5 v√≠deos...\n",
            "[1/5] Gerando relat√≥rios para: vid_ate_quando_voce_vai_ficar_culpando_os_outros\n",
            "  üíæ Relat√≥rio de Texto (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_texto/RELATORIO_TEXTO_HUMANIZADO_vid_ate_quando_voce_vai_ficar_culpando_os_outros.xlsx\n",
            "  üíæ Estrat√©gia de Conte√∫do Textual (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_texto/ESTRATEGIA_CONTEUDO_TEXTUAL_vid_ate_quando_voce_vai_ficar_culpando_os_outros.pdf\n",
            "  üíæ Relat√≥rio de √Åudio (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_audio/RELATORIO_AUDIO_HUMANIZADO_vid_ate_quando_voce_vai_ficar_culpando_os_outros.xlsx\n",
            "  üíæ Resumo de √Åudio Estrat√©gico (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_audio/RESUMO_AUDIO_ESTRATEGICO_vid_ate_quando_voce_vai_ficar_culpando_os_outros.pdf\n",
            "  üíæ Relat√≥rio Visual (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_visual/RELATORIO_VISUAL_HUMANIZADO_vid_ate_quando_voce_vai_ficar_culpando_os_outros.xlsx\n",
            "  üíæ Estrat√©gia Visual Completa (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_visual/ESTRATEGIA_VISUAL_COMPLETA_vid_ate_quando_voce_vai_ficar_culpando_os_outros.pdf\n",
            "  üíæ Relat√≥rio Psicol√≥gico (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_psicologica/RELATORIO_PSICOLOGICO_HUMANIZADO_vid_ate_quando_voce_vai_ficar_culpando_os_outros.xlsx\n",
            "  üíæ Manual de Psicologia Viral (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_psicologica/MANUAL_PSICOLOGIA_VIRAL_vid_ate_quando_voce_vai_ficar_culpando_os_outros.pdf\n",
            "  ‚úÖ Relat√≥rios gerados para vid_ate_quando_voce_vai_ficar_culpando_os_outros\n",
            "[2/5] Gerando relat√≥rios para: vid_coloque_metas_em_sua_vida_e_se_surpreenda\n",
            "  üíæ Relat√≥rio de Texto (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_texto/RELATORIO_TEXTO_HUMANIZADO_vid_coloque_metas_em_sua_vida_e_se_surpreenda.xlsx\n",
            "  üíæ Estrat√©gia de Conte√∫do Textual (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_texto/ESTRATEGIA_CONTEUDO_TEXTUAL_vid_coloque_metas_em_sua_vida_e_se_surpreenda.pdf\n",
            "  üíæ Relat√≥rio de √Åudio (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_audio/RELATORIO_AUDIO_HUMANIZADO_vid_coloque_metas_em_sua_vida_e_se_surpreenda.xlsx\n",
            "  üíæ Resumo de √Åudio Estrat√©gico (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_audio/RESUMO_AUDIO_ESTRATEGICO_vid_coloque_metas_em_sua_vida_e_se_surpreenda.pdf\n",
            "  üíæ Relat√≥rio Visual (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_visual/RELATORIO_VISUAL_HUMANIZADO_vid_coloque_metas_em_sua_vida_e_se_surpreenda.xlsx\n",
            "  üíæ Estrat√©gia Visual Completa (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_visual/ESTRATEGIA_VISUAL_COMPLETA_vid_coloque_metas_em_sua_vida_e_se_surpreenda.pdf\n",
            "  üíæ Relat√≥rio Psicol√≥gico (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_psicologica/RELATORIO_PSICOLOGICO_HUMANIZADO_vid_coloque_metas_em_sua_vida_e_se_surpreenda.xlsx\n",
            "  üíæ Manual de Psicologia Viral (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_psicologica/MANUAL_PSICOLOGIA_VIRAL_vid_coloque_metas_em_sua_vida_e_se_surpreenda.pdf\n",
            "  ‚úÖ Relat√≥rios gerados para vid_coloque_metas_em_sua_vida_e_se_surpreenda\n",
            "[3/5] Gerando relat√≥rios para: vid_a_importancia_de_ser_rico_antes_de_ter\n",
            "  üíæ Relat√≥rio de Texto (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_texto/RELATORIO_TEXTO_HUMANIZADO_vid_a_importancia_de_ser_rico_antes_de_ter.xlsx\n",
            "  üíæ Estrat√©gia de Conte√∫do Textual (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_texto/ESTRATEGIA_CONTEUDO_TEXTUAL_vid_a_importancia_de_ser_rico_antes_de_ter.pdf\n",
            "  üíæ Relat√≥rio de √Åudio (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_audio/RELATORIO_AUDIO_HUMANIZADO_vid_a_importancia_de_ser_rico_antes_de_ter.xlsx\n",
            "  üíæ Resumo de √Åudio Estrat√©gico (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_audio/RESUMO_AUDIO_ESTRATEGICO_vid_a_importancia_de_ser_rico_antes_de_ter.pdf\n",
            "  üíæ Relat√≥rio Visual (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_visual/RELATORIO_VISUAL_HUMANIZADO_vid_a_importancia_de_ser_rico_antes_de_ter.xlsx\n",
            "  üíæ Estrat√©gia Visual Completa (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_visual/ESTRATEGIA_VISUAL_COMPLETA_vid_a_importancia_de_ser_rico_antes_de_ter.pdf\n",
            "  üíæ Relat√≥rio Psicol√≥gico (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_psicologica/RELATORIO_PSICOLOGICO_HUMANIZADO_vid_a_importancia_de_ser_rico_antes_de_ter.xlsx\n",
            "  üíæ Manual de Psicologia Viral (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_psicologica/MANUAL_PSICOLOGIA_VIRAL_vid_a_importancia_de_ser_rico_antes_de_ter.pdf\n",
            "  ‚úÖ Relat√≥rios gerados para vid_a_importancia_de_ser_rico_antes_de_ter\n",
            "[4/5] Gerando relat√≥rios para: vid_as_treÃÇs_fases_de_todo_mundo_que_decidiu_fazer_alguma_coisa\n",
            "  ‚ùå ERRO na gera√ß√£o de relat√≥rios para vid_as_treÃÇs_fases_de_todo_mundo_que_decidiu_fazer_alguma_coisa: 'latin-1' codec can't encode character '\\u201c' in position 625: ordinal not in range(256)\n",
            "[5/5] Gerando relat√≥rios para: vid_a_melhor_saida_eÃÅ_se_afastar_de_pessoas_perversas\n",
            "  ‚ùå ERRO na gera√ß√£o de relat√≥rios para vid_a_melhor_saida_eÃÅ_se_afastar_de_pessoas_perversas: 'latin-1' codec can't encode character '\\u201c' in position 304: ordinal not in range(256)\n",
            "\n",
            "‚úÖ GERA√á√ÉO DE RELAT√ìRIOS HUMANIZADOS CONCLU√çDA!\n",
            "Total de v√≠deos com relat√≥rios gerados: 3\n",
            "\n",
            "‚û°Ô∏è PR√ìXIMA C√âLULA: 4.2 - GERA√á√ÉO DO BLUEPRINT FINAL E DASHBOARD\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# C√âLULA 4.2: GERA√á√ÉO DO BLUEPRINT FINAL E DASHBOARD\n",
        "# ============================================================================\n",
        "\n",
        "def gerar_blueprint_dashboard():\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa(\"relatorios_humanizados\")\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Carregar todos os dados de an√°lise\n",
        "    metadados_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_completos.json\")\n",
        "    decomposicao_path = os.path.join(PASTA_TRABALHO, \"dados\", \"decomposicao_completa.json\")\n",
        "    analises_padroes_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_padroes_completas.json\")\n",
        "    analises_psicologicas_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_psicologicas_completas.json\")\n",
        "\n",
        "    with open(metadados_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        metadados = json.load(f)\n",
        "    with open(decomposicao_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        decomposicoes = json.load(f)\n",
        "    with open(analises_padroes_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        analises_padroes = json.load(f)\n",
        "    with open(analises_psicologicas_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        analises_psicologicas = json.load(f)\n",
        "\n",
        "    dados_consolidados = []\n",
        "    for video_meta in metadados:\n",
        "        video_id = video_meta[\"id\"]\n",
        "        decomposicao = next((d for d in decomposicoes if d[\"video_id\"] == video_id), {})\n",
        "        analise_padroes = next((ap for ap in analises_padroes if ap[\"video_id\"] == video_id), {})\n",
        "        analise_psicologica = next((aps for aps in analises_psicologicas if aps[\"video_id\"] == video_id), {})\n",
        "        consolidado = {\n",
        "            \"video_id\": video_id,\n",
        "            \"nome_arquivo\": video_meta.get(\"nome_arquivo\"),\n",
        "            \"duracao_segundos\": video_meta.get(\"duracao_segundos\"),\n",
        "            \"formato_detectado\": video_meta.get(\"formato_detectado\"),\n",
        "            \"tem_audio\": video_meta.get(\"tem_audio\"),\n",
        "            \"total_frames\": video_meta.get(\"total_frames\"),\n",
        "            \"ocr_textos_count\": len(decomposicao.get(\"textos_ocr\", [])),\n",
        "            \"audio_transcrito_len\": len(decomposicao.get(\"audio_transcrito\", \"\")),\n",
        "            \"cortes_detectados_count\": len(decomposicao.get(\"cortes_detectados_segundos\", [])),\n",
        "            \"bpm_audio\": analise_padroes.get(\"analise_audio_detalhada\", {}).get(\"bpm\"),\n",
        "            \"complexidade_visual_media\": analise_padroes.get(\"analise_visual_detalhada\", {}).get(\"complexidade_visual_media\"),\n",
        "            \"brilho_medio\": analise_padroes.get(\"analise_visual_detalhada\", {}).get(\"brilho_medio\"),\n",
        "            \"padroes_gerais\": \", \".join(analise_padroes.get(\"padroes_gerais\", [])),\n",
        "            \"gatilhos_psicologicos\": \", \".join(analise_psicologica.get(\"gatilhos_detectados\", [])),\n",
        "            \"emocoes_predominantes\": str(analise_psicologica.get(\"emocoes_predominantes\", {})),\n",
        "            \"status_geral\": video_meta.get(\"status\") # Pode ser aprimorado para refletir o status de todas as etapas\n",
        "        }\n",
        "        dados_consolidados.append(consolidado)\n",
        "\n",
        "    df_final = pd.DataFrame(dados_consolidados)\n",
        "\n",
        "    # Salvar Dashboard Executivo (Excel)\n",
        "    dashboard_excel_path = os.path.join(PASTA_TRABALHO, \"dashboard\", \"DASHBOARD_MASTER_EXECUTIVO.xlsx\")\n",
        "    df_final.to_excel(dashboard_excel_path, index=False, engine=\"openpyxl\")\n",
        "    print(f\"\\nüíæ Dashboard Executivo (XLSX) salvo em: {dashboard_excel_path}\")\n",
        "\n",
        "    # Salvar Dados Consolidados (CSV e JSON)\n",
        "    dados_csv_path = os.path.join(PASTA_TRABALHO, \"dashboard\", \"dados_consolidados.csv\")\n",
        "    df_final.to_csv(dados_csv_path, index=False, encoding=\"utf-8\")\n",
        "    print(f\"üíæ Dados Consolidados (CSV) salvo em: {dados_csv_path}\")\n",
        "\n",
        "    dados_json_path = os.path.join(PASTA_TRABALHO, \"dashboard\", \"dados_detalhados.json\")\n",
        "    with open(dados_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(dados_consolidados, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"üíæ Dados Detalhados (JSON) salvo em: {dados_json_path}\")\n",
        "\n",
        "    # Gera√ß√£o de Dashboard Interativo (HTML - Exemplo simples)\n",
        "    # Para um dashboard interativo real, seria necess√°rio uma biblioteca como Plotly ou Dash\n",
        "    dashboard_html_path = os.path.join(PASTA_TRABALHO, \"dashboard\", \"dashboard_interativo.html\")\n",
        "    with open(dashboard_html_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"<html><body><h1>Dashboard Interativo (Placeholder)</h1><p>Seu dashboard interativo real seria gerado aqui com bibliotecas como Plotly ou Dash.</p></body></html>\")\n",
        "    print(f\"üíæ Dashboard Interativo (HTML) salvo em: {dashboard_html_path}\")\n",
        "\n",
        "    # Gera√ß√£o do Blueprint Estrat√©gico (PDF - Exemplo simples)\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "    pdf.chapter_title(\"BLUEPRINT ESTRAT√âGICO FINAL\")\n",
        "    pdf.chapter_body(\"Este √© o seu blueprint estrat√©gico final, consolidando todos os insights.\")\n",
        "    pdf.chapter_body(f\"Total de v√≠deos analisados: {len(df_final)}\")\n",
        "    pdf.chapter_body(f\"M√©dia de dura√ß√£o dos v√≠deos: {df_final[\"duracao_segundos\"] .mean():.2f} segundos\")\n",
        "    pdf_blueprint_path = os.path.join(PASTA_TRABALHO, \"blueprint\", \"BLUEPRINT_ESTRATEGICO_FINAL.pdf\")\n",
        "    pdf.output(pdf_blueprint_path)\n",
        "    print(f\"üíæ Blueprint Estrat√©gico (PDF) salvo em: {pdf_blueprint_path}\")\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"blueprint\"] = True\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(\"\\n‚úÖ GERA√á√ÉO DO BLUEPRINT FINAL E DASHBOARD CONCLU√çDA!\")\n",
        "    print(\"Todos os relat√≥rios e o dashboard foram gerados com sucesso.\")\n",
        "    print(\"\\nüéâ PROCESSO DE ENGENHARIA REVERSA CONCLU√çDO COM SUCESSO! üéâ\")\n",
        "\n",
        "# Executar gera√ß√£o de blueprint e dashboard\n",
        "try:\n",
        "    gerar_blueprint_dashboard()\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå ERRO GERAL NA GERA√á√ÉO DO BLUEPRINT E DASHBOARD: {e}\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "blueprint_dashboard",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7aadba-56e1-456d-bdfe-d34e70d47d0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üíæ Dashboard Executivo (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dashboard/DASHBOARD_MASTER_EXECUTIVO.xlsx\n",
            "üíæ Dados Consolidados (CSV) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dashboard/dados_consolidados.csv\n",
            "üíæ Dados Detalhados (JSON) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dashboard/dados_detalhados.json\n",
            "üíæ Dashboard Interativo (HTML) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dashboard/dashboard_interativo.html\n",
            "üíæ Blueprint Estrat√©gico (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/blueprint/BLUEPRINT_ESTRATEGICO_FINAL.pdf\n",
            "\n",
            "‚úÖ GERA√á√ÉO DO BLUEPRINT FINAL E DASHBOARD CONCLU√çDA!\n",
            "Todos os relat√≥rios e o dashboard foram gerados com sucesso.\n",
            "\n",
            "üéâ PROCESSO DE ENGENHARIA REVERSA CONCLU√çDO COM SUCESSO! üéâ\n"
          ]
        }
      ],
      "execution_count": null
    }
  ]
}