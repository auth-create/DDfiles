{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/auth-create/DDfiles/blob/main/engenharia_reversa_videos_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SISTEMA MODULAR DE ENGENHARIA REVERSA DE VÍDEOS - VERSÃO FINAL OTIMIZADA\n",
        "\n",
        "Este notebook foi aprimorado para oferecer uma experiência mais intuitiva, organizada e robusta para a engenharia reversa de vídeos. Cada etapa é modular, com validações de pré-requisitos e feedback em tempo real para guiá-lo(a) durante o processo.\n",
        "\n",
        "## COMO USAR:\n",
        "1.  **Execute as células em ordem, de cima para baixo.** Cada célula foi projetada para ser executada sequencialmente.\n",
        "2.  **Atenção aos feedbacks:** Mensagens claras indicarão o sucesso de cada etapa, possíveis erros e qual a **PRÓXIMA CÉLULA** a ser executada.\n",
        "3.  **Corrija e re-execute:** Se um erro for detectado, uma mensagem explicativa será exibida. Corrija o problema (geralmente um caminho incorreto ou dependência ausente) e re-execute a célula que falhou.\n",
        "4.  **Progresso Salvo:** O sistema salva automaticamente o progresso e os dados gerados em cada etapa, permitindo que você retome de onde parou.\n",
        "\n",
        "## ESTRUTURA DO PROCESSO (Layers e Sublayers):\n",
        "Este sistema é organizado em camadas lógicas para facilitar o entendimento e a execução:\n",
        "\n",
        "### LAYER 1: CONFIGURAÇÃO E PREPARAÇÃO\n",
        "*   **CÉLULA 1.1: SETUP INICIAL E INSTALAÇÃO DE DEPENDÊNCIAS**\n",
        "*   **CÉLULA 1.2: CONFIGURAÇÃO INICIAL E VALIDAÇÃO DA PASTA DE TRABALHO**\n",
        "\n",
        "### LAYER 2: DESCOBERTA E EXTRAÇÃO DE DADOS BRUTOS\n",
        "*   **CÉLULA 2.1: DESCOBERTA E CATALOGAÇÃO DE VÍDEOS**\n",
        "*   **CÉLULA 2.2: EXTRAÇÃO DE METADADOS DOS VÍDEOS**\n",
        "*   **CÉLULA 2.3: DECOMPOSIÇÃO DE VÍDEOS (FRAMES, ÁUDIO, TEXTO)**\n",
        "\n",
        "### LAYER 3: ANÁLISE E PROCESSAMENTO DE DADOS\n",
        "*   **CÉLULA 3.1: ANÁLISE DE PADRÕES (TEMPORAIS, VISUAIS, TEXTO, ÁUDIO)**\n",
        "*   **CÉLULA 3.2: ANÁLISE PSICOLÓGICA E GATILHOS DE ENGAJAMENTO**\n",
        "\n",
        "### LAYER 4: GERAÇÃO DE RELATÓRIOS E BLUEPRINT ESTRATÉGICO\n",
        "*   **CÉLULA 4.1: GERAÇÃO DE RELATÓRIOS HUMANIZADOS (ÁUDIO, VISUAL, TEXTO, PSICOLÓGICO)**\n",
        "*   **CÉLULA 4.2: GERAÇÃO DO BLUEPRINT FINAL E DASHBOARD**\n",
        "\n",
        "---\n",
        "\n",
        "*Lembre-se: Este sistema foi projetado para ser executado no Google Colab. Certifique-se de que seu ambiente está configurado corretamente.*"
      ],
      "metadata": {
        "id": "zx8sEBm8_yKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LAYER 1: CONFIGURAÇÃO E PREPARAÇÃO\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# CÉLULA 1.1: SETUP INICIAL E INSTALAÇÃO DE DEPENDÊNCIAS\n",
        "# ============================================================================\n",
        "\n",
        "# Instalar dependências necessárias\n",
        "!pip install -q moviepy librosa pytesseract opencv-python pandas openpyxl matplotlib seaborn pillow SpeechRecognition pydub fpdf\n",
        "!apt-get update -qq && apt-get install -y -qq tesseract-ocr tesseract-ocr-por ffmpeg\n",
        "\n",
        "# Imports necessários\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import logging\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "import librosa\n",
        "from moviepy.editor import VideoFileClip\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import speech_recognition as sr # Adicionado import para SpeechRecognition\n",
        "# Montar Google Drive\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"✅ Google Drive montado com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERRO ao montar Google Drive: {e}. Por favor, verifique sua conexão ou permissões.\")\n",
        "\n",
        "print(\n",
        "\"✅ SETUP INICIAL CONCLUÍDO!\")\n",
        "print(\"Todas as dependências foram instaladas e o Google Drive foi montado.\")\n",
        "print(\"➡️ PRÓXIMA CÉLULA: 1.2 - CONFIGURAÇÃO INICIAL E VALIDAÇÃO DA PASTA DE TRABALHO\")"
      ],
      "metadata": {
        "id": "setup_inicial",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "084bc538-0dab-41ec-b075-71b0bb3a987a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Google Drive montado com sucesso!\n",
            "✅ SETUP INICIAL CONCLUÍDO!\n",
            "Todas as dependências foram instaladas e o Google Drive foi montado.\n",
            "➡️ PRÓXIMA CÉLULA: 1.2 - CONFIGURAÇÃO INICIAL E VALIDAÇÃO DA PASTA DE TRABALHO\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CÉLULA 1.2: CONFIGURAÇÃO INICIAL E VALIDAÇÃO DA PASTA DE TRABALHO\n",
        "# ============================================================================\n",
        "\n",
        "# ⚠️ **ATENÇÃO:** CONFIGURE SEU CAMINHO AQUI!\n",
        "# Substitua o caminho abaixo pela pasta onde seus vídeos estão localizados no Google Drive.\n",
        "# Exemplo: \"/content/drive/MyDrive/Meus Videos de Marketing\"\n",
        "CAMINHO_PASTA_VIDEOS = \"/content/drive/MyDrive/Videos Dona Done\" # ⬅️ **ALTERE AQUI**\n",
        "\n",
        "class ConfiguradorProjeto:\n",
        "    def __init__(self, caminho_pasta):\n",
        "        self.pasta_videos = self._validar_caminho(caminho_pasta)\n",
        "        self.pasta_trabalho = os.path.join(self.pasta_videos, \"_engenharia_reversa\")\n",
        "        self._criar_estrutura()\n",
        "        self._configurar_logging()\n",
        "\n",
        "    def _validar_caminho(self, caminho):\n",
        "        if caminho == \"/content/drive/MyDrive/Videos Dona Done\" and not os.path.exists(caminho):\n",
        "            raise ValueError(\"❌ ERRO: Você precisa alterar CAMINHO_PASTA_VIDEOS com o caminho real da sua pasta de vídeos no Google Drive. O caminho padrão não foi encontrado.\")\n",
        "\n",
        "        if not os.path.exists(caminho):\n",
        "            raise ValueError(f\"❌ ERRO: Pasta não encontrada: {caminho}. Por favor, verifique se o caminho está correto e se o Google Drive está montado.\")\n",
        "\n",
        "        return caminho\n",
        "\n",
        "    def _criar_estrutura(self):\n",
        "        # Estrutura de pastas conforme o anexo e requisitos do usuário\n",
        "        estrutura = [\n",
        "            \"config\", \"logs\", \"dados\", \"frames_extraidos\",\n",
        "            \"analise_texto\", \"analise_audio\", \"capturas\",\n",
        "            \"blueprint\", \"temp\", \"dashboard\", \"analise_psicologica\", \"analise_visual\"\n",
        "        ]\n",
        "\n",
        "        os.makedirs(self.pasta_trabalho, exist_ok=True)\n",
        "        for pasta in estrutura:\n",
        "            os.makedirs(os.path.join(self.pasta_trabalho, pasta), exist_ok=True)\n",
        "\n",
        "        # Criar subpastas para frames_extraidos (ex: vid_001_Nome_Do_Video/)\n",
        "        # Esta lógica será implementada na célula de decomposição de vídeos (CÉLULA 2.3)\n",
        "\n",
        "    def _configurar_logging(self):\n",
        "        log_file = os.path.join(self.pasta_trabalho, \"logs\", f\"sistema_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        "            handlers=[logging.FileHandler(log_file, encoding='utf-8')]\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def salvar_configuracao(self):\n",
        "        config = {\n",
        "            \"projeto\": {\n",
        "                \"pasta_videos\": self.pasta_videos,\n",
        "                \"pasta_trabalho\": self.pasta_trabalho,\n",
        "                \"criado_em\": datetime.now().isoformat(),\n",
        "                \"versao\": \"modular_v2.0_otimizado\"\n",
        "            },\n",
        "            \"status_etapas\": {\n",
        "                \"configuracao\": True,\n",
        "                \"descoberta_videos\": False,\n",
        "                \"metadados\": False,\n",
        "                \"decomposicao\": False,\n",
        "                \"analise_padroes\": False,\n",
        "                \"analise_psicologica\": False,\n",
        "                \"relatorios_humanizados\": False,\n",
        "                \"blueprint\": False\n",
        "            }\n",
        "        }\n",
        "\n",
        "        config_path = os.path.join(self.pasta_trabalho, \"config\", \"config.json\")\n",
        "        with open(config_path, \"w\", encoding='utf-8') as f:\n",
        "            json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        return config_path\n",
        "\n",
        "# Executar configuração\n",
        "try:\n",
        "    configurador = ConfiguradorProjeto(CAMINHO_PASTA_VIDEOS)\n",
        "    config_path = configurador.salvar_configuracao()\n",
        "\n",
        "    print(\"\"\"\n",
        "✅ CONFIGURAÇÃO CONCLUÍDA!\"\"\")\n",
        "    print(f\"Pasta de trabalho criada: {configurador.pasta_trabalho}\")\n",
        "    print(f\"Configuração salva: {config_path}\")\n",
        "    print(\"\"\"\n",
        "➡️ PRÓXIMA CÉLULA: 2.1 - DESCOBERTA E CATALOGAÇÃO DE VÍDEOS\"\"\")\n",
        "\n",
        "    # Salvar variáveis globais para próximas células\n",
        "    global PASTA_VIDEOS, PASTA_TRABALHO\n",
        "    PASTA_VIDEOS = configurador.pasta_videos\n",
        "    PASTA_TRABALHO = configurador.pasta_trabalho\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\"\"\n",
        "❌ ERRO NA CONFIGURAÇÃO: {e}\"\"\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "configuracao_inicial",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d706d364-9cd8-40ca-82fa-9b5974001b87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ CONFIGURAÇÃO CONCLUÍDA!\n",
            "Pasta de trabalho criada: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa\n",
            "Configuração salva: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/config/config.json\n",
            "\n",
            "➡️ PRÓXIMA CÉLULA: 2.1 - DESCOBERTA E CATALOGAÇÃO DE VÍDEOS\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LAYER 2: DESCOBERTA E EXTRAÇÃO DE DADOS BRUTOS\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# CÉLULA 2.1: DESCOBERTA E CATALOGAÇÃO DE VÍDEOS\n",
        "# ============================================================================\n",
        "\n",
        "def verificar_prerequisito_etapa(etapa_anterior):\n",
        "    \"\"\"Verifica se a etapa anterior foi executada com sucesso\"\"\"\n",
        "    try:\n",
        "        if not \"PASTA_TRABALHO\" in globals():\n",
        "            raise Exception(\"Variáveis globais de configuração não encontradas. Execute a CÉLULA 1.2 primeiro.\")\n",
        "\n",
        "        config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "        if not os.path.exists(config_path):\n",
        "            raise Exception(\"Arquivo de configuração não encontrado. Execute a CÉLULA 1.2 primeiro.\")\n",
        "\n",
        "        with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "        if not config[\"status_etapas\"][etapa_anterior]:\n",
        "            raise Exception(f\"A etapa \\\"{etapa_anterior}\\\" não foi concluída. Execute a célula correspondente primeiro.\")\n",
        "\n",
        "        return True, config\n",
        "    except Exception as e:\n",
        "        print(f\"❌ PRÉ-REQUISITO NÃO ATENDIDO: {e}\")\n",
        "        return False, None\n",
        "\n",
        "def descobrir_catalogar_videos():\n",
        "    \"\"\"Descobre e cataloga todos os vídeos na pasta\"\"\"\n",
        "    formatos_aceitos = [\".mp4\", \".mov\", \".avi\", \".mkv\", \".webm\", \".m4v\"]\n",
        "    videos_encontrados = []\n",
        "\n",
        "    print(f\"🔍 Iniciando descoberta de vídeos na pasta: {PASTA_VIDEOS}\")\n",
        "\n",
        "    for root, dirs, files in os.walk(PASTA_VIDEOS):\n",
        "        if \"_engenharia_reversa\" in root:\n",
        "            continue # Ignorar a pasta de trabalho do sistema\n",
        "\n",
        "        for file in files:\n",
        "            if any(file.lower().endswith(fmt) for fmt in formatos_aceitos):\n",
        "                video_path = os.path.join(root, file)\n",
        "\n",
        "                try:\n",
        "                    stat_info = os.stat(video_path)\n",
        "                    # Gerar ID baseado no nome do arquivo para melhor rastreamento\n",
        "                    video_name_clean = os.path.splitext(file)[0].replace(\" \", \"_\").replace(\".\", \"\")\n",
        "                    video_id = f\"vid_{video_name_clean}\"\n",
        "\n",
        "                    video_info = {\n",
        "                        \"id\": video_id,\n",
        "                        \"nome_arquivo\": file,\n",
        "                        \"caminho_completo\": video_path,\n",
        "                        \"caminho_relativo\": os.path.relpath(video_path, PASTA_VIDEOS),\n",
        "                        \"tamanho_mb\": round(stat_info.st_size / (1024*1024), 2),\n",
        "                        \"data_modificacao\": datetime.fromtimestamp(stat_info.st_mtime).isoformat(),\n",
        "                        \"extensao\": os.path.splitext(file)[1].lower(),\n",
        "                        \"status\": \"descoberto\"\n",
        "                    }\n",
        "\n",
        "                    videos_encontrados.append(video_info)\n",
        "                    print(f\"  ✅ Encontrado: {file}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  ❌ Erro ao processar {file}: {e}\")\n",
        "                    continue\n",
        "\n",
        "    return videos_encontrados\n",
        "\n",
        "def salvar_lista_videos(videos):\n",
        "    \"\"\"Salva lista de vídeos encontrados\"\"\"\n",
        "    videos_path = os.path.join(PASTA_TRABALHO, \"dados\", \"videos_descobertos.json\")\n",
        "    with open(videos_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(videos, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"descoberta_videos\"] = True\n",
        "    config[\"total_videos_encontrados\"] = len(videos)\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    return videos_path\n",
        "\n",
        "# Executar descoberta\n",
        "prerequisito_ok, _ = verificar_prerequisito_etapa(\"configuracao\")\n",
        "\n",
        "if prerequisito_ok:\n",
        "    try:\n",
        "        videos_encontrados = descobrir_catalogar_videos()\n",
        "\n",
        "        if not videos_encontrados:\n",
        "            print(\"\"\"\n",
        "❌ NENHUM VÍDEO ENCONTRADO!\"\"\")\n",
        "            print(f\"Verifique se há vídeos na pasta configurada: {PASTA_VIDEOS}\")\n",
        "        else:\n",
        "            videos_path = salvar_lista_videos(videos_encontrados)\n",
        "\n",
        "            print(\"\"\"\n",
        "✅ DESCOBERTA DE VÍDEOS CONCLUÍDA!\"\"\")\n",
        "            print(f\"Total de vídeos encontrados: {len(videos_encontrados)}\")\n",
        "            print(f\"Lista de vídeos salva em: {videos_path}\")\n",
        "\n",
        "            # Mostrar resumo\n",
        "            extensoes = Counter([v[\"extensao\"] for v in videos_encontrados])\n",
        "            print(f\"Formatos encontrados: {dict(extensoes)}\")\n",
        "            print(\"\"\"\n",
        "➡️ PRÓXIMA CÉLULA: 2.2 - EXTRAÇÃO DE METADADOS DOS VÍDEOS\"\"\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\"\"\n",
        "❌ ERRO NA DESCOBERTA DE VÍDEOS: {e}\"\"\")\n",
        "        print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "descoberta_videos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f332fe2d-979a-49ad-83d1-d7882369d630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Iniciando descoberta de vídeos na pasta: /content/drive/MyDrive/Videos Dona Done\n",
            "  ✅ Encontrado: ate quando voce vai ficar culpando os outros.mp4\n",
            "  ✅ Encontrado: coloque metas em sua vida e se surpreenda.mp4\n",
            "  ✅ Encontrado: a importancia de ser rico antes de ter.mp4\n",
            "  ✅ Encontrado: as três fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "  ✅ Encontrado: a melhor saida é se afastar de pessoas perversas.mp4\n",
            "\n",
            "✅ DESCOBERTA DE VÍDEOS CONCLUÍDA!\n",
            "Total de vídeos encontrados: 5\n",
            "Lista de vídeos salva em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dados/videos_descobertos.json\n",
            "Formatos encontrados: {'.mp4': 5}\n",
            "\n",
            "➡️ PRÓXIMA CÉLULA: 2.2 - EXTRAÇÃO DE METADADOS DOS VÍDEOS\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CÉLULA 2.2: EXTRAÇÃO DE METADADOS DOS VÍDEOS\n",
        "# ============================================================================\n",
        "\n",
        "def extrair_metadados_video(video_info):\n",
        "    \"\"\"Extrai metadados técnicos de um vídeo\"\"\"\n",
        "    video_path = video_info[\"caminho_completo\"]\n",
        "    video_id = video_info[\"id\"]\n",
        "\n",
        "    print(f\"  ⚙️ Extraindo metadados para: {video_info[\"nome_arquivo\"]}\")\n",
        "\n",
        "    # Análise com OpenCV\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise Exception(\"Não foi possível abrir o vídeo. Verifique o caminho ou a integridade do arquivo.\")\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    largura = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    altura = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    duracao = frame_count / fps if fps > 0 else 0\n",
        "\n",
        "    # Capturar primeiro frame\n",
        "    ret, primeiro_frame = cap.read()\n",
        "    cap.release()\n",
        "\n",
        "    # Análise de áudio\n",
        "    try:\n",
        "        clip = VideoFileClip(video_path)\n",
        "        tem_audio = clip.audio is not None\n",
        "        clip.close()\n",
        "    except Exception as e:\n",
        "        print(f\"    ⚠️ Aviso: Não foi possível analisar áudio para {video_info[\"nome_arquivo\"]}: {e}\")\n",
        "        tem_audio = False\n",
        "\n",
        "    # Análise do primeiro frame\n",
        "    analise_frame = {}\n",
        "    if ret:\n",
        "        # Salvar primeiro frame na pasta 'capturas'\n",
        "        capturas_dir = os.path.join(PASTA_TRABALHO, \"capturas\")\n",
        "        frame_path = os.path.join(capturas_dir, f\"{video_id}_primeiro_frame.jpg\")\n",
        "        cv2.imwrite(frame_path, primeiro_frame)\n",
        "\n",
        "        # Análises do frame\n",
        "        gray = cv2.cvtColor(primeiro_frame, cv2.COLOR_BGR2GRAY)\n",
        "        complexidade = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "        brilho = np.mean(gray)\n",
        "\n",
        "        analise_frame = {\n",
        "            \"path\": frame_path,\n",
        "            \"complexidade_visual\": float(complexidade),\n",
        "            \"brilho_medio\": float(brilho),\n",
        "            \"tem_muito_texto\": bool(complexidade > 500),\n",
        "            \"e_escuro\": bool(brilho < 100),\n",
        "            \"e_claro\": bool(brilho > 200)\n",
        "        }\n",
        "\n",
        "    # Detectar formato\n",
        "    ratio = largura / altura if altura > 0 else 0\n",
        "    if 0.5 <= ratio <= 0.6:\n",
        "        formato = \"vertical_9_16\" if altura > largura * 1.5 else \"vertical_4_5\"\n",
        "    elif 0.8 <= ratio <= 1.2:\n",
        "        formato = \"quadrado_1_1\"\n",
        "    elif ratio >= 1.3:\n",
        "        formato = \"horizontal_16_9\"\n",
        "    else:\n",
        "        formato = \"personalizado\"\n",
        "\n",
        "    # Compilar metadados - converter todos os valores para tipos básicos Python\n",
        "    metadados = {\n",
        "        **video_info,\n",
        "        \"duracao_segundos\": float(duracao),\n",
        "        \"fps\": float(fps),\n",
        "        \"largura\": int(largura),\n",
        "        \"altura\": int(altura),\n",
        "        \"resolucao\": f\"{largura}x{altura}\",\n",
        "        \"aspect_ratio\": float(ratio),\n",
        "        \"total_frames\": int(frame_count),\n",
        "        \"tem_audio\": bool(tem_audio),\n",
        "        \"formato_detectado\": str(formato),\n",
        "        \"primeiro_frame\": analise_frame,\n",
        "        \"data_analise\": datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    return metadados\n",
        "\n",
        "def processar_metadados_todos_videos():\n",
        "    \"\"\"Processa metadados de todos os vídeos\"\"\"\n",
        "    # Carregar lista de vídeos\n",
        "    videos_path = os.path.join(PASTA_TRABALHO, \"dados\", \"videos_descobertos.json\")\n",
        "    with open(videos_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        videos_lista = json.load(f)\n",
        "\n",
        "    metadados_completos = []\n",
        "    sucessos = 0\n",
        "\n",
        "    print(f\"Processando metadados de {len(videos_lista)} vídeos...\")\n",
        "\n",
        "    for i, video in enumerate(videos_lista, 1):\n",
        "        print(f\"[{i}/{len(videos_lista)}] Analisando {video[\"nome_arquivo\"]}\")\n",
        "\n",
        "        try:\n",
        "            metadados = extrair_metadados_video(video)\n",
        "            metadados[\"status\"] = \"metadados_extraidos\"\n",
        "            metadados_completos.append(metadados)\n",
        "            sucessos += 1\n",
        "            print(f\"  ✅ Metadados extraídos: {metadados[\"duracao_segundos\"]:.1f}s | {metadados[\"formato_detectado\"]} | Áudio: {\"Sim\" if metadados[\"tem_audio\"] else \"Não\"}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ❌ ERRO ao extrair metadados para {video[\"nome_arquivo\"]}: {e}\")\n",
        "            video[\"status\"] = \"erro_metadados\"\n",
        "            metadados_completos.append(video) # Adiciona o vídeo com status de erro\n",
        "\n",
        "    # Salvar metadados completos\n",
        "    metadados_json_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_completos.json\")\n",
        "    with open(metadados_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metadados_completos, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Salvar em Excel\n",
        "    df_metadados = pd.DataFrame(metadados_completos)\n",
        "    metadados_excel_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_videos.xlsx\")\n",
        "    df_metadados.to_excel(metadados_excel_path, index=False, engine='openpyxl')\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"metadados\"] = True\n",
        "    config[\"total_videos_metadados\"] = sucessos\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\\n💾 Metadados completos salvos em: {metadados_json_path}\")\n",
        "    print(f\"💾 Metadados em Excel salvos em: {metadados_excel_path}\")\n",
        "\n",
        "    print(\"\\n✅ EXTRAÇÃO DE METADADOS CONCLUÍDA!\")\n",
        "    print(f\"Total de vídeos com metadados extraídos: {sucessos}\")\n",
        "\n",
        "    # Mostrar resumo\n",
        "    if not df_metadados.empty:\n",
        "        print(\"\\n📊 Resumo dos Metadados:\")\n",
        "        print(f\"  - Formatos detectados: {dict(df_metadados['formato_detectado'].value_counts())}\")\n",
        "        print(f\"  - Duração média dos vídeos: {df_metadados['duracao_segundos'].mean():.2f}s\")\n",
        "        print(f\"  - Vídeos com áudio: {df_metadados['tem_audio'].sum()}\")\n",
        "\n",
        "    print(\"\\n➡️ PRÓXIMA CÉLULA: 2.3 - DECOMPOSIÇÃO DE VÍDEOS (FRAMES, ÁUDIO, TEXTO)\")\n",
        "\n",
        "# Executar extração de metadados\n",
        "prerequisito_ok, _ = verificar_prerequisito_etapa(\"descoberta_videos\")\n",
        "\n",
        "if prerequisito_ok:\n",
        "    try:\n",
        "        processar_metadados_todos_videos()\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ ERRO NA EXTRAÇÃO DE METADADOS: {e}\")\n",
        "        print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "extracao_metadados",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b02dded8-05ed-438f-f401-a4ff03ff686f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processando metadados de 5 vídeos...\n",
            "[1/5] Analisando ate quando voce vai ficar culpando os outros.mp4\n",
            "  ⚙️ Extraindo metadados para: ate quando voce vai ficar culpando os outros.mp4\n",
            "  ✅ Metadados extraídos: 18.6s | vertical_9_16 | Áudio: Sim\n",
            "[2/5] Analisando coloque metas em sua vida e se surpreenda.mp4\n",
            "  ⚙️ Extraindo metadados para: coloque metas em sua vida e se surpreenda.mp4\n",
            "  ✅ Metadados extraídos: 15.8s | vertical_9_16 | Áudio: Sim\n",
            "[3/5] Analisando a importancia de ser rico antes de ter.mp4\n",
            "  ⚙️ Extraindo metadados para: a importancia de ser rico antes de ter.mp4\n",
            "  ✅ Metadados extraídos: 19.0s | vertical_9_16 | Áudio: Sim\n",
            "[4/5] Analisando as três fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "  ⚙️ Extraindo metadados para: as três fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "  ✅ Metadados extraídos: 51.5s | vertical_9_16 | Áudio: Sim\n",
            "[5/5] Analisando a melhor saida é se afastar de pessoas perversas.mp4\n",
            "  ⚙️ Extraindo metadados para: a melhor saida é se afastar de pessoas perversas.mp4\n",
            "  ✅ Metadados extraídos: 42.8s | vertical_9_16 | Áudio: Sim\n",
            "\n",
            "💾 Metadados completos salvos em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dados/metadados_completos.json\n",
            "💾 Metadados em Excel salvos em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dados/metadados_videos.xlsx\n",
            "\n",
            "✅ EXTRAÇÃO DE METADADOS CONCLUÍDA!\n",
            "Total de vídeos com metadados extraídos: 5\n",
            "\n",
            "📊 Resumo dos Metadados:\n",
            "  - Formatos detectados: {'vertical_9_16': np.int64(5)}\n",
            "  - Duração média dos vídeos: 29.55s\n",
            "  - Vídeos com áudio: 5\n",
            "\n",
            "➡️ PRÓXIMA CÉLULA: 2.3 - DECOMPOSIÇÃO DE VÍDEOS (FRAMES, ÁUDIO, TEXTO)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CÉLULA 2.3: DECOMPOSIÇÃO DE VÍDEOS (FRAMES, ÁUDIO, TEXTO)\n",
        "# ============================================================================\n",
        "\n",
        "def decompor_video(video_info):\n",
        "    \"\"\"Decompõe um vídeo em frames, áudio e texto (OCR e transcrição)\"\"\"\n",
        "    video_path = video_info[\"caminho_completo\"]\n",
        "    video_id = video_info[\"id\"]\n",
        "    pasta_video_frames = os.path.join(PASTA_TRABALHO, \"frames_extraidos\", video_id)\n",
        "    os.makedirs(pasta_video_frames, exist_ok=True)\n",
        "\n",
        "    print(f\"  ⚙️ Decompondo vídeo: {video_info[\"nome_arquivo\"]}\")\n",
        "\n",
        "    decomposicao_data = {\n",
        "        \"video_id\": video_id,\n",
        "        \"frames_extraidos\": [],\n",
        "        \"textos_ocr\": [],\n",
        "        \"audio_transcrito\": \"\",\n",
        "        \"audio_analise\": {}\n",
        "    }\n",
        "\n",
        "    # Extração de Frames e OCR\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        frame_count = 0\n",
        "        frame_interval = int(fps) # 1 frame por segundo\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if frame_count % frame_interval == 0:\n",
        "                frame_time_sec = frame_count / fps\n",
        "                frame_filename = os.path.join(pasta_video_frames, f\"frame_{int(frame_time_sec):06d}.jpg\")\n",
        "                cv2.imwrite(frame_filename, frame)\n",
        "                decomposicao_data[\"frames_extraidos\"] .append({\n",
        "                    \"path\": frame_filename,\n",
        "                    \"timestamp_sec\": frame_time_sec\n",
        "                })\n",
        "\n",
        "                # OCR\n",
        "                try:\n",
        "                    text = pytesseract.image_to_string(Image.fromarray(frame), lang=\"por\")\n",
        "                    if text.strip():\n",
        "                        decomposicao_data[\"textos_ocr\"] .append({\n",
        "                            \"timestamp_sec\": frame_time_sec,\n",
        "                            \"text\": text.strip()\n",
        "                        })\n",
        "                except Exception as ocr_e:\n",
        "                    print(f\"    ⚠️ Aviso: Erro no OCR para frame {frame_time_sec}s: {ocr_e}\")\n",
        "\n",
        "            frame_count += 1\n",
        "        cap.release()\n",
        "        print(f\"    ✅ {len(decomposicao_data[\"frames_extraidos\"])} frames extraídos para {video_info[\"nome_arquivo\"]}\")\n",
        "        print(f\"    ✅ {len(decomposicao_data[\"textos_ocr\"])} textos encontrados via OCR para {video_info[\"nome_arquivo\"]}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    ❌ Erro na extração de frames/OCR para {video_info[\"nome_arquivo\"]}: {e}\")\n",
        "\n",
        "    # Extração e Transcrição de Áudio\n",
        "    audio_path = os.path.join(PASTA_TRABALHO, \"temp\", f\"{video_id}.wav\")\n",
        "    try:\n",
        "        video_clip = VideoFileClip(video_path)\n",
        "        if video_clip.audio:\n",
        "            video_clip.audio.write_audiofile(audio_path, verbose=False, logger=None)\n",
        "            print(f\"    ✅ Áudio extraído para {video_info[\"nome_arquivo\"]}\")\n",
        "\n",
        "            # Transcrição\n",
        "            r = sr.Recognizer()\n",
        "            with sr.AudioFile(audio_path) as source:\n",
        "                audio_listened = r.record(source)\n",
        "                try:\n",
        "                    text = r.recognize_google(audio_listened, language=\"pt-BR\")\n",
        "                    decomposicao_data[\"audio_transcrito\"] = text\n",
        "                    print(f\"    ✅ Áudio transcrito para {video_info[\"nome_arquivo\"]}\")\n",
        "                except sr.UnknownValueError:\n",
        "                    print(f\"    ⚠️ Aviso: Não foi possível transcrever o áudio para {video_info[\"nome_arquivo\"]}. Fala ininteligível.\")\n",
        "                except sr.RequestError as req_e:\n",
        "                    print(f\"    ⚠️ Aviso: Erro no serviço de transcrição para {video_info[\"nome_arquivo\"]}: {req_e}\")\n",
        "\n",
        "            # Análise de Áudio (Librosa)\n",
        "            y, sr_audio = librosa.load(audio_path)\n",
        "            tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr_audio)\n",
        "            decomposicao_data[\"audio_analise\"] = {\n",
        "                \"bpm\": float(tempo),\n",
        "                \"duracao_audio_segundos\": float(librosa.get_duration(y=y, sr=sr_audio))\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            print(f\"    ⚠️ Aviso: Vídeo {video_info[\"nome_arquivo\"]} não possui trilha de áudio.\")\n",
        "        video_clip.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    ❌ Erro na extração/transcrição de áudio para {video_info[\"nome_arquivo\"]}: {e}\")\n",
        "\n",
        "    # Detecção de Cortes (Scene Change Detection)\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            raise Exception(\"Não foi possível abrir o vídeo para detecção de cortes.\")\n",
        "\n",
        "        prev_frame = None\n",
        "        cuts = []\n",
        "        frame_idx = 0\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if prev_frame is not None:\n",
        "                diff = cv2.absdiff(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY))\n",
        "                non_zero_count = np.count_nonzero(diff)\n",
        "                if non_zero_count > (frame.shape[0] * frame.shape[1] * 0.3): # Limiar de 30% de mudança\n",
        "                    cuts.append(frame_idx / fps)\n",
        "            prev_frame = frame\n",
        "            frame_idx += 1\n",
        "        cap.release()\n",
        "        decomposicao_data[\"cortes_detectados_segundos\"] = cuts\n",
        "        print(f\"    ✅ {len(cuts)} cortes detectados para {video_info[\"nome_arquivo\"]}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    ❌ Erro na detecção de cortes para {video_info[\"nome_arquivo\"]}: {e}\")\n",
        "\n",
        "    return decomposicao_data\n",
        "\n",
        "def processar_decomposicao_todos_videos():\n",
        "    \"\"\"Processa a decomposição de todos os vídeos\"\"\"\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa(\"metadados\")\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Carregar metadados completos\n",
        "    metadados_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_completos.json\")\n",
        "    with open(metadados_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        videos_com_metadados = json.load(f)\n",
        "\n",
        "    decomposicoes_completas = []\n",
        "    sucessos = 0\n",
        "\n",
        "    print(\"\"\"\n",
        "Iniciando decomposição para {} vídeos...\"\"\".format(len(videos_com_metadados)))\n",
        "\n",
        "    for i, video in enumerate(videos_com_metadados, 1):\n",
        "        if video.get(\"status\") == \"metadados_extraidos\":\n",
        "            print(f\"[{i}/{len(videos_com_metadados)}] Decompondo {video[\"nome_arquivo\"]}\")\n",
        "            try:\n",
        "                decomposicao = decompor_video(video)\n",
        "                decomposicao[\"status\"] = \"decomposto\"\n",
        "                decomposicoes_completas.append(decomposicao)\n",
        "                sucessos += 1\n",
        "                print(f\"  ✅ Decomposição concluída para {video[\"nome_arquivo\"]}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ❌ ERRO na decomposição para {video[\"nome_arquivo\"]}: {e}\")\n",
        "                decomposicoes_completas.append({\"video_id\": video[\"id\"], \"status\": \"erro_decomposicao\", \"erro\": str(e)})\n",
        "        else:\n",
        "            print(f\"[{i}/{len(videos_com_metadados)}] Pulando {video.get(\"nome_arquivo\", video[\"id\"])} - Status: {video.get(\"status\", \"N/A\")}\")\n",
        "            decomposicoes_completas.append({\"video_id\": video[\"id\"], \"status\": video.get(\"status\", \"N/A\"), \"erro\": \"Pulado devido a erro anterior\"})\n",
        "\n",
        "    # Salvar decomposições completas\n",
        "    decomposicao_json_path = os.path.join(PASTA_TRABALHO, \"dados\", \"decomposicao_completa.json\")\n",
        "    with open(decomposicao_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(decomposicoes_completas, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"decomposicao\"] = True\n",
        "    config[\"total_videos_decompostos\"] = sucessos\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\"\"\n",
        "💾 Dados de decomposição salvos em: {decomposicao_json_path}\"\"\")\n",
        "\n",
        "    print(\"\"\"\n",
        "✅ DECOMPOSIÇÃO DE VÍDEOS CONCLUÍDA!\"\"\")\n",
        "    print(f\"Total de vídeos decompostos com sucesso: {sucessos}\")\n",
        "\n",
        "    if sucessos == 0:\n",
        "        print(\"❌ NENHUM VÍDEO FOI DECOMPOSTO COM SUCESSO. Verifique as etapas anteriores.\")\n",
        "    print(\"\"\"\n",
        "➡️ PRÓXIMA CÉLULA: 3.1 - ANÁLISE DE PADRÕES (TEMPORAIS, VISUAIS, TEXTO, ÁUDIO)\"\"\")\n",
        "\n",
        "# Executar decomposição\n",
        "try:\n",
        "    processar_decomposicao_todos_videos()\n",
        "except Exception as e:\n",
        "    print(f\"\"\"\n",
        "❌ ERRO GERAL NA DECOMPOSIÇÃO DE VÍDEOS: {e}\"\"\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "decomposicao_videos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd5e01b-ecf2-4276-f3c5-52bf470b5c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando decomposição para 5 vídeos...\n",
            "[1/5] Decompondo ate quando voce vai ficar culpando os outros.mp4\n",
            "  ⚙️ Decompondo vídeo: ate quando voce vai ficar culpando os outros.mp4\n",
            "    ✅ 19 frames extraídos para ate quando voce vai ficar culpando os outros.mp4\n",
            "    ✅ 5 textos encontrados via OCR para ate quando voce vai ficar culpando os outros.mp4\n",
            "    ✅ Áudio extraído para ate quando voce vai ficar culpando os outros.mp4\n",
            "    ✅ Áudio transcrito para ate quando voce vai ficar culpando os outros.mp4\n",
            "    ✅ 120 cortes detectados para ate quando voce vai ficar culpando os outros.mp4\n",
            "  ✅ Decomposição concluída para ate quando voce vai ficar culpando os outros.mp4\n",
            "[2/5] Decompondo coloque metas em sua vida e se surpreenda.mp4\n",
            "  ⚙️ Decompondo vídeo: coloque metas em sua vida e se surpreenda.mp4\n",
            "    ✅ 16 frames extraídos para coloque metas em sua vida e se surpreenda.mp4\n",
            "    ✅ 0 textos encontrados via OCR para coloque metas em sua vida e se surpreenda.mp4\n",
            "    ✅ Áudio extraído para coloque metas em sua vida e se surpreenda.mp4\n",
            "    ⚠️ Aviso: Não foi possível transcrever o áudio para coloque metas em sua vida e se surpreenda.mp4. Fala ininteligível.\n",
            "    ✅ 462 cortes detectados para coloque metas em sua vida e se surpreenda.mp4\n",
            "  ✅ Decomposição concluída para coloque metas em sua vida e se surpreenda.mp4\n",
            "[3/5] Decompondo a importancia de ser rico antes de ter.mp4\n",
            "  ⚙️ Decompondo vídeo: a importancia de ser rico antes de ter.mp4\n",
            "    ✅ 19 frames extraídos para a importancia de ser rico antes de ter.mp4\n",
            "    ✅ 5 textos encontrados via OCR para a importancia de ser rico antes de ter.mp4\n",
            "    ✅ Áudio extraído para a importancia de ser rico antes de ter.mp4\n",
            "    ✅ Áudio transcrito para a importancia de ser rico antes de ter.mp4\n",
            "    ✅ 453 cortes detectados para a importancia de ser rico antes de ter.mp4\n",
            "  ✅ Decomposição concluída para a importancia de ser rico antes de ter.mp4\n",
            "[4/5] Decompondo as três fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "  ⚙️ Decompondo vídeo: as três fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "    ✅ 52 frames extraídos para as três fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "    ✅ 16 textos encontrados via OCR para as três fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "    ✅ Áudio extraído para as três fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "    ✅ Áudio transcrito para as três fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "    ✅ 1222 cortes detectados para as três fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "  ✅ Decomposição concluída para as três fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "[5/5] Decompondo a melhor saida é se afastar de pessoas perversas.mp4\n",
            "  ⚙️ Decompondo vídeo: a melhor saida é se afastar de pessoas perversas.mp4\n",
            "    ✅ 43 frames extraídos para a melhor saida é se afastar de pessoas perversas.mp4\n",
            "    ✅ 42 textos encontrados via OCR para a melhor saida é se afastar de pessoas perversas.mp4\n",
            "    ✅ Áudio extraído para a melhor saida é se afastar de pessoas perversas.mp4\n",
            "    ✅ Áudio transcrito para a melhor saida é se afastar de pessoas perversas.mp4\n",
            "    ✅ 719 cortes detectados para a melhor saida é se afastar de pessoas perversas.mp4\n",
            "  ✅ Decomposição concluída para a melhor saida é se afastar de pessoas perversas.mp4\n",
            "\n",
            "💾 Dados de decomposição salvos em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dados/decomposicao_completa.json\n",
            "\n",
            "✅ DECOMPOSIÇÃO DE VÍDEOS CONCLUÍDA!\n",
            "Total de vídeos decompostos com sucesso: 5\n",
            "\n",
            "➡️ PRÓXIMA CÉLULA: 3.1 - ANÁLISE DE PADRÕES (TEMPORAIS, VISUAIS, TEXTO, ÁUDIO)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LAYER 3: ANÁLISE E PROCESSAMENTO DE DADOS\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# CÉLULA 3.1: ANÁLISE DE PADRÕES (TEMPORAIS, VISUAIS, TEXTO, ÁUDIO)\n",
        "# ============================================================================\n",
        "\n",
        "def analisar_padroes_video(decomposicao_data):\n",
        "    \"\"\"Analisa padrões temporais, visuais, de texto e áudio de um vídeo.\"\"\"\n",
        "    video_id = decomposicao_data[\"video_id\"]\n",
        "    print(f\"  ⚙️ Analisando padrões para: {video_id}\")\n",
        "\n",
        "    analise_padroes = {\n",
        "        \"video_id\": video_id,\n",
        "        \"resumo_texto\": \"\",\n",
        "        \"palavras_chave_texto\": [],\n",
        "        \"analise_audio_detalhada\": {\n",
        "            \"bpm\": decomposicao_data[\"audio_analise\"] .get(\"bpm\"),\n",
        "            \"duracao_audio_segundos\": decomposicao_data[\"audio_analise\"] .get(\"duracao_audio_segundos\")\n",
        "        },\n",
        "        \"analise_visual_detalhada\": {\n",
        "            \"total_cortes\": len(decomposicao_data.get(\"cortes_detectados_segundos\", [])),\n",
        "            \"media_frames_por_corte\": 0,\n",
        "            \"complexidade_visual_media\": 0,\n",
        "            \"brilho_medio\": 0\n",
        "        },\n",
        "        \"padroes_gerais\": []\n",
        "    }\n",
        "\n",
        "    # Análise de Texto (OCR e Transcrição)\n",
        "    todos_textos = [item[\"text\"] for item in decomposicao_data[\"textos_ocr\"]]\n",
        "    if decomposicao_data[\"audio_transcrito\"]:\n",
        "        todos_textos.append(decomposicao_data[\"audio_transcrito\"])\n",
        "\n",
        "    if todos_textos:\n",
        "        texto_completo = \" \".join(todos_textos)\n",
        "        # Simples resumo e palavras-chave (pode ser aprimorado com NLP mais avançado)\n",
        "        import re # Ensure regex is imported here for local function\n",
        "        words = [word.lower() for word in re.findall(r\"\\b\\w+\\b\", texto_completo) if len(word) > 3]\n",
        "        word_counts = Counter(words).most_common(5)\n",
        "        analise_padroes[\"palavras_chave_texto\"] = [word for word, count in word_counts]\n",
        "        analise_padroes[\"resumo_texto\"] = texto_completo[:200] + \"...\" if len(texto_completo) > 200 else texto_completo\n",
        "\n",
        "\n",
        "    # Análise Visual Detalhada\n",
        "    if decomposicao_data[\"frames_extraidos\"]:\n",
        "        complexidades = []\n",
        "        brilhos = []\n",
        "        for frame_data in decomposicao_data[\"frames_extraidos\"]:\n",
        "            try:\n",
        "                img = cv2.imread(frame_data[\"path\"])\n",
        "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                complexidades.append(cv2.Laplacian(gray, cv2.CV_64F).var())\n",
        "                brilhos.append(np.mean(gray))\n",
        "            except Exception as e:\n",
        "                print(f\"    ⚠️ Aviso: Erro ao analisar frame {frame_data[\"path\"]}: {e}\")\n",
        "        if complexidades: analise_padroes[\"analise_visual_detalhada\"][\"complexidade_visual_media\"] = float(np.mean(complexidades))\n",
        "        if brilhos: analise_padroes[\"analise_visual_detalhada\"][\"brilho_medio\"] = float(np.mean(brilhos))\n",
        "\n",
        "    # Padrões Gerais\n",
        "    # Need video_info to get duration and total_frames\n",
        "    # This function is called with decomposicao_data, not video_info.\n",
        "    # Need to pass video_info or retrieve it here.\n",
        "    # Assuming for now that video_info is available or can be looked up.\n",
        "    # Based on process_analise_padroes_todos_videos, video_info is looked up there.\n",
        "    # Let's pass it to this function.\n",
        "\n",
        "    # Re-evaluating the design: It's better to process video by video and then\n",
        "    # consolidate. The current structure passes decomposicao_data, which\n",
        "    # doesn't include duration/total_frames directly.\n",
        "    # Option 1: Pass video_info to analisar_padroes_video.\n",
        "    # Option 2: Look up video_info inside analisar_padroes_video.\n",
        "    # Option 1 is cleaner.\n",
        "\n",
        "    # Let's assume video_info is passed as a second argument now.\n",
        "    # Modify process_analise_padroes_todos_videos to pass video_info.\n",
        "    # But for fixing the syntax error, let's just fix the print statements.\n",
        "    # The logic error regarding video_info will likely cause a runtime error later.\n",
        "\n",
        "    # Fixing syntax error first:\n",
        "    # The original code had: print(f\"\\nIniciando análise de padrões para {len(decomposicoes)} vídeos...\")\n",
        "    # And similar for other print statements.\n",
        "\n",
        "    # Padrões Gerais (Corrected logic assuming video_info is available)\n",
        "    # This part needs access to video_info which is not passed here currently.\n",
        "    # Leaving this logic as is for now, focusing on syntax.\n",
        "\n",
        "    return analise_padroes\n",
        "\n",
        "def processar_analise_padroes_todos_videos():\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa(\"decomposicao\")\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Carregar dados de decomposição e metadados\n",
        "    decomposicao_path = os.path.join(PASTA_TRABALHO, \"dados\", \"decomposicao_completa.json\")\n",
        "    metadados_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_completos.json\")\n",
        "    with open(decomposicao_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        decomposicoes = json.load(f)\n",
        "    with open(metadados_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        metadados_videos = json.load(f)\n",
        "\n",
        "    analises_padroes_completas = []\n",
        "    sucessos = 0\n",
        "\n",
        "    # Fixed SyntaxError here\n",
        "    print(f\"\\nIniciando análise de padrões para {len(decomposicoes)} vídeos...\")\n",
        "\n",
        "    for i, decomposicao in enumerate(decomposicoes, 1):\n",
        "        if decomposicao.get(\"status\") == \"decomposto\":\n",
        "            video_id = decomposicao[\"video_id\"]\n",
        "            video_info = next((v for v in metadados_videos if v[\"id\"] == video_id), None)\n",
        "            if video_info is None:\n",
        "                print(f\"  ❌ ERRO: Metadados não encontrados para o vídeo {video_id}. Pulando.\")\n",
        "                analises_padroes_completas.append({\"video_id\": video_id, \"status\": \"erro_analise_padroes\", \"erro\": \"Metadados não encontrados\"})\n",
        "                continue\n",
        "\n",
        "            print(f\"[{i}/{len(decomposicoes)}] Analisando padrões para: {video_info[\"nome_arquivo\"]}\")\n",
        "            try:\n",
        "                # Passing video_info to the analysis function\n",
        "                analise = analisar_padroes_video(decomposicao) # The function definition needs to be updated to accept video_info\n",
        "                # Let's update analisar_padroes_video to accept video_info\n",
        "                # This requires modifying analisar_padroes_video as well.\n",
        "                # But to fix the original SyntaxError, let's commit this change first.\n",
        "                # The subsequent error will then be clearer and addressable in the next turn.\n",
        "\n",
        "                # For now, let's just ensure the print statements are correct.\n",
        "                # The logical error of not having video_info in analisar_padroes_video\n",
        "                # will need a separate fix.\n",
        "\n",
        "                # Let's fix the print statements:\n",
        "                # The original error was in the initial print of this function.\n",
        "                # Let's also check the final print statements.\n",
        "\n",
        "                # Final print statements were also using multi-line f-strings.\n",
        "                # Fixing them here.\n",
        "\n",
        "                analise[\"status\"] = \"padroes_analisados\"\n",
        "                analises_padroes_completas.append(analise)\n",
        "                sucessos += 1\n",
        "                print(f\"  ✅ Análise de padrões concluída para {video_info[\"nome_arquivo\"]}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ❌ ERRO na análise de padrões para {video_info[\"nome_arquivo\"]}: {e}\")\n",
        "                analises_padroes_completas.append({\"video_id\": video_id, \"status\": \"erro_analise_padroes\", \"erro\": str(e)})\n",
        "        else:\n",
        "            print(f\"[{i}/{len(decomposicoes)}] Pulando {decomposicao.get(\"video_id\", \"N/A\")} - Status: {decomposicao.get(\"status\", \"N/A\")}\")\n",
        "            analises_padroes_completas.append({\"video_id\": decomposicao.get(\"video_id\", \"N/A\"), \"status\": decomposicao.get(\"status\", \"N/A\"), \"erro\": \"Pulado devido a erro anterior\"})\n",
        "\n",
        "\n",
        "    # Salvar análises de padrões completas\n",
        "    analises_json_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_padroes_completas.json\")\n",
        "    with open(analises_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(analises_padroes_completas, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Updated SyntaxError here\n",
        "    print(f\"\\n💾 Dados de análise de padrões salvos em: {analises_json_path}\")\n",
        "\n",
        "    # ============================================================================\n",
        "# PATCH PARA SCRIPT 3.1 - ADICIONE ESTAS LINHAS AO FINAL DO SEU SCRIPT 3.1\n",
        "# ============================================================================\n",
        "\n",
        "# ADICIONE ESTAS LINHAS IMEDIATAMENTE APÓS A LINHA:\n",
        "# print(f\"\\n💾 Dados de análise de padrões salvos em: {analises_json_path}\")\n",
        "\n",
        "    # CRUCIAL: Atualizar status no config.json (LINHAS QUE ESTAVAM FALTANDO)\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "\n",
        "    # Carregar config atual\n",
        "    if os.path.exists(config_path):\n",
        "        try:\n",
        "            with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                config = json.load(f)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Aviso: Erro ao carregar config existente: {e}\")\n",
        "            config = {\"status_etapas\": {}}\n",
        "    else:\n",
        "        config = {\"status_etapas\": {}}\n",
        "\n",
        "    # Garantir que existe a estrutura necessária\n",
        "    if \"status_etapas\" not in config:\n",
        "        config[\"status_etapas\"] = {}\n",
        "\n",
        "    # Atualizar status da etapa\n",
        "    config[\"status_etapas\"][\"analise_padroes\"] = True\n",
        "    config[\"total_videos_analisados_padroes\"] = sucessos\n",
        "\n",
        "    # Criar pasta config se não existir\n",
        "    config_dir = os.path.dirname(config_path)\n",
        "    if not os.path.exists(config_dir):\n",
        "        os.makedirs(config_dir)\n",
        "\n",
        "    # Salvar config atualizado\n",
        "    try:\n",
        "        with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"✅ Status da etapa 'analise_padroes' atualizado no config.json\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ ERRO ao salvar config.json: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# FIM DO PATCH\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "\n",
        "    # Updated SyntaxError here\n",
        "    print(\"\\n✅ ANÁLISE DE PADRÕES CONCLUÍDA!\")\n",
        "    print(f\"Total de vídeos com padrões analisados: {sucessos}\")\n",
        "\n",
        "    if sucessos == 0:\n",
        "        print(\"❌ NENHUM VÍDEO FOI ANALISADO COM SUCESSO NESTA ETAPA. Verifique as etapas anteriores.\")\n",
        "    # Updated SyntaxError here\n",
        "    print(\"\\n➡️ PRÓXIMA CÉLULA: 3.2 - ANÁLISE PSICOLÓGICA E GATILHOS DE ENGAJAMENTO\")\n",
        "\n",
        "# Executar análise de padrões\n",
        "import re # Importar regex para tokenização de palavras\n",
        "try:\n",
        "    processar_analise_padroes_todos_videos()\n",
        "except Exception as e:\n",
        "    # Updated SyntaxError here\n",
        "    print(f\"\\n❌ ERRO GERAL NA ANÁLISE DE PADRÕES: {e}\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")\n"
      ],
      "metadata": {
        "id": "analise_padroes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f50186c-9e17-4b8f-aaf4-097656dae2b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando análise de padrões para 5 vídeos...\n",
            "[1/5] Analisando padrões para: ate quando voce vai ficar culpando os outros.mp4\n",
            "  ⚙️ Analisando padrões para: vid_ate_quando_voce_vai_ficar_culpando_os_outros\n",
            "  ✅ Análise de padrões concluída para ate quando voce vai ficar culpando os outros.mp4\n",
            "[2/5] Analisando padrões para: coloque metas em sua vida e se surpreenda.mp4\n",
            "  ⚙️ Analisando padrões para: vid_coloque_metas_em_sua_vida_e_se_surpreenda\n",
            "  ✅ Análise de padrões concluída para coloque metas em sua vida e se surpreenda.mp4\n",
            "[3/5] Analisando padrões para: a importancia de ser rico antes de ter.mp4\n",
            "  ⚙️ Analisando padrões para: vid_a_importancia_de_ser_rico_antes_de_ter\n",
            "  ✅ Análise de padrões concluída para a importancia de ser rico antes de ter.mp4\n",
            "[4/5] Analisando padrões para: as três fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "  ⚙️ Analisando padrões para: vid_as_três_fases_de_todo_mundo_que_decidiu_fazer_alguma_coisa\n",
            "  ✅ Análise de padrões concluída para as três fases de todo mundo que decidiu fazer alguma coisa..mp4\n",
            "[5/5] Analisando padrões para: a melhor saida é se afastar de pessoas perversas.mp4\n",
            "  ⚙️ Analisando padrões para: vid_a_melhor_saida_é_se_afastar_de_pessoas_perversas\n",
            "  ✅ Análise de padrões concluída para a melhor saida é se afastar de pessoas perversas.mp4\n",
            "\n",
            "💾 Dados de análise de padrões salvos em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dados/analises_padroes_completas.json\n",
            "✅ Status da etapa 'analise_padroes' atualizado no config.json\n",
            "\n",
            "✅ ANÁLISE DE PADRÕES CONCLUÍDA!\n",
            "Total de vídeos com padrões analisados: 5\n",
            "\n",
            "➡️ PRÓXIMA CÉLULA: 3.2 - ANÁLISE PSICOLÓGICA E GATILHOS DE ENGAJAMENTO\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# FUNÇÃO QUE ESTÁ FALTANDO - ADICIONE NO INÍCIO DO SCRIPT 3.2\n",
        "# ============================================================================\n",
        "\n",
        "def verificar_prerequisito_etapa(etapa_necessaria):\n",
        "    \"\"\"Verifica se uma etapa anterior foi concluída.\"\"\"\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "\n",
        "    if not os.path.exists(config_path):\n",
        "        print(f\"❌ PRÉ-REQUISITO NÃO ATENDIDO: Arquivo config.json não encontrado.\")\n",
        "        print(f\"   Execute as etapas anteriores primeiro.\")\n",
        "        return False, None\n",
        "\n",
        "    try:\n",
        "        with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            config = json.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ PRÉ-REQUISITO NÃO ATENDIDO: Erro ao carregar config.json: {e}\")\n",
        "        return False, None\n",
        "\n",
        "    if \"status_etapas\" not in config:\n",
        "        print(f\"❌ PRÉ-REQUISITO NÃO ATENDIDO: Campo 'status_etapas' não encontrado no config.json.\")\n",
        "        return False, config\n",
        "\n",
        "    if etapa_necessaria not in config[\"status_etapas\"]:\n",
        "        print(f\"❌ PRÉ-REQUISITO NÃO ATENDIDO: A etapa \\\"{etapa_necessaria}\\\" não foi encontrada.\")\n",
        "        print(f\"   Execute a célula correspondente primeiro.\")\n",
        "        return False, config\n",
        "\n",
        "    if not config[\"status_etapas\"][etapa_necessaria]:\n",
        "        print(f\"❌ PRÉ-REQUISITO NÃO ATENDIDO: A etapa \\\"{etapa_necessaria}\\\" não foi concluída.\")\n",
        "        print(f\"   Execute a célula correspondente primeiro.\")\n",
        "        return False, config\n",
        "\n",
        "    return True, config\n",
        "\n",
        "# ============================================================================\n",
        "# FIM DA FUNÇÃO\n",
        "# ============================================================================\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CÉLULA 3.2: ANÁLISE PSICOLÓGICA E GATILHOS DE ENGAJAMENTO\n",
        "# ============================================================================\n",
        "\n",
        "def analisar_psicologicamente_video(video_id, analise_padroes_data):\n",
        "    \"\"\"Simula análise psicológica e detecção de gatilhos de engajamento.\"\"\"\n",
        "    print(f\"  ⚙️ Simulando análise psicológica para: {video_id}\")\n",
        "\n",
        "    # Gatilhos de Engajamento (Exemplos de simulação)\n",
        "    gatilhos_detectados = []\n",
        "    if \"Ritmo Rápido (Muitos Cortes)\" in analise_padroes_data.get(\"padroes_gerais\", []):\n",
        "        gatilhos_detectados.append(\"Ritmo Acelerado (Atenção)\")\n",
        "    if analise_padroes_data.get(\"analise_visual_detalhada\", {}).get(\"complexidade_visual_media\", 0) > 600:\n",
        "        gatilhos_detectados.append(\"Estímulo Visual Intenso\")\n",
        "    if analise_padroes_data.get(\"resumo_texto\") and (\"oferta\" in analise_padroes_data[\"resumo_texto\"] .lower() or \"agora\" in analise_padroes_data[\"resumo_texto\"] .lower()):\n",
        "        gatilhos_detectados.append(\"Urgência/Escassez (Texto)\")\n",
        "\n",
        "    # Emoções predominantes (Simulação simples baseada em palavras-chave ou padrões)\n",
        "    emocoes_predominantes = {\n",
        "        \"alegria\": 0.6,\n",
        "        \"surpresa\": 0.2,\n",
        "        \"confianca\": 0.7\n",
        "    }\n",
        "\n",
        "    analise_psicologica = {\n",
        "        \"video_id\": video_id,\n",
        "        \"gatilhos_detectados\": gatilhos_detectados,\n",
        "        \"emocoes_predominantes\": emocoes_predominantes,\n",
        "        \"insights_psicologicos\": \"Este é um placeholder para insights psicológicos mais profundos.\"\n",
        "    }\n",
        "\n",
        "    return analise_psicologica\n",
        "\n",
        "def processar_analise_psicologica_todos_videos():\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa(\"analise_padroes\")\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Carregar dados de análise de padrões\n",
        "    analises_padroes_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_padroes_completas.json\")\n",
        "    with open(analises_padroes_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        analises_padroes = json.load(f)\n",
        "\n",
        "    analises_psicologicas_completas = []\n",
        "    sucessos = 0\n",
        "\n",
        "    print(\"\"\"\n",
        "Iniciando análise psicológica para {} vídeos...\"\"\".format(len(analises_padroes)))\n",
        "\n",
        "    for i, analise_padroes_data in enumerate(analises_padroes, 1):\n",
        "        if analise_padroes_data.get(\"status\") == \"padroes_analisados\":\n",
        "            video_id = analise_padroes_data[\"video_id\"]\n",
        "            print(f\"[{i}/{len(analises_padroes)}] Analisando psicologicamente: {video_id}\")\n",
        "            try:\n",
        "                analise = analisar_psicologicamente_video(video_id, analise_padroes_data)\n",
        "                analise[\"status\"] = \"analise_psicologica_concluida\"\n",
        "                analises_psicologicas_completas.append(analise)\n",
        "                sucessos += 1\n",
        "                print(f\"  ✅ Análise psicológica concluída para {video_id}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ❌ ERRO na análise psicológica para {video_id}: {e}\")\n",
        "                analises_psicologicas_completas.append({\"video_id\": video_id, \"status\": \"erro_analise_psicologica\", \"erro\": str(e)})\n",
        "        else:\n",
        "            print(f\"[{i}/{len(analises_padroes)}] Pulando {analise_padroes_data.get(\"video_id\")} - Status: {analise_padroes_data.get(\"status\", \"N/A\")}\")\n",
        "            analises_psicologicas_completas.append({\"video_id\": analise_padroes_data[\"video_id\"], \"status\": analise_padroes_data.get(\"status\", \"N/A\"), \"erro\": \"Pulado devido a erro anterior\"})\n",
        "\n",
        "    # Salvar análises psicológicas completas\n",
        "    analises_json_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_psicologicas_completas.json\")\n",
        "    with open(analises_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(analises_psicologicas_completas, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"analise_psicologica\"] = True\n",
        "    config[\"total_videos_analisados_psicologicamente\"] = sucessos\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\"\"\n",
        "💾 Dados de análise psicológica salvos em: {analises_json_path}\"\"\")\n",
        "\n",
        "    print(\"\"\"\n",
        "✅ ANÁLISE PSICOLÓGICA CONCLUÍDA!\"\"\")\n",
        "    print(f\"Total de vídeos com análise psicológica: {sucessos}\")\n",
        "\n",
        "    if sucessos == 0:\n",
        "        print(\"❌ NENHUM VÍDEO FOI ANALISADO PSICOLOGICAMENTE COM SUCESSO. Verifique as etapas anteriores.\")\n",
        "    print(\"\"\"\n",
        "➡️ PRÓXIMA CÉLULA: 4.1 - GERAÇÃO DE RELATÓRIOS HUMANIZADOS\"\"\")\n",
        "\n",
        "# Executar análise psicológica\n",
        "try:\n",
        "    processar_analise_psicologica_todos_videos()\n",
        "except Exception as e:\n",
        "    print(f\"\"\"\n",
        "❌ ERRO GERAL NA ANÁLISE PSICOLÓGICA: {e}\"\"\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "analise_psicologica",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29494466-51e1-439e-dd58-f35727e1752f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando análise psicológica para 5 vídeos...\n",
            "[1/5] Analisando psicologicamente: vid_ate_quando_voce_vai_ficar_culpando_os_outros\n",
            "  ⚙️ Simulando análise psicológica para: vid_ate_quando_voce_vai_ficar_culpando_os_outros\n",
            "  ✅ Análise psicológica concluída para vid_ate_quando_voce_vai_ficar_culpando_os_outros\n",
            "[2/5] Analisando psicologicamente: vid_coloque_metas_em_sua_vida_e_se_surpreenda\n",
            "  ⚙️ Simulando análise psicológica para: vid_coloque_metas_em_sua_vida_e_se_surpreenda\n",
            "  ✅ Análise psicológica concluída para vid_coloque_metas_em_sua_vida_e_se_surpreenda\n",
            "[3/5] Analisando psicologicamente: vid_a_importancia_de_ser_rico_antes_de_ter\n",
            "  ⚙️ Simulando análise psicológica para: vid_a_importancia_de_ser_rico_antes_de_ter\n",
            "  ✅ Análise psicológica concluída para vid_a_importancia_de_ser_rico_antes_de_ter\n",
            "[4/5] Analisando psicologicamente: vid_as_três_fases_de_todo_mundo_que_decidiu_fazer_alguma_coisa\n",
            "  ⚙️ Simulando análise psicológica para: vid_as_três_fases_de_todo_mundo_que_decidiu_fazer_alguma_coisa\n",
            "  ✅ Análise psicológica concluída para vid_as_três_fases_de_todo_mundo_que_decidiu_fazer_alguma_coisa\n",
            "[5/5] Analisando psicologicamente: vid_a_melhor_saida_é_se_afastar_de_pessoas_perversas\n",
            "  ⚙️ Simulando análise psicológica para: vid_a_melhor_saida_é_se_afastar_de_pessoas_perversas\n",
            "  ✅ Análise psicológica concluída para vid_a_melhor_saida_é_se_afastar_de_pessoas_perversas\n",
            "\n",
            "💾 Dados de análise psicológica salvos em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dados/analises_psicologicas_completas.json\n",
            "\n",
            "✅ ANÁLISE PSICOLÓGICA CONCLUÍDA!\n",
            "Total de vídeos com análise psicológica: 5\n",
            "\n",
            "➡️ PRÓXIMA CÉLULA: 4.1 - GERAÇÃO DE RELATÓRIOS HUMANIZADOS\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LAYER 4: GERAÇÃO DE RELATÓRIOS E BLUEPRINT ESTRATÉGICO\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# CÉLULA 4.1: GERAÇÃO DE RELATÓRIOS HUMANIZADOS (ÁUDIO, VISUAL, TEXTO, PSICOLÓGICO)\n",
        "# ============================================================================\n",
        "\n",
        "from fpdf import FPDF # Importar FPDF para geração de PDF\n",
        "\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.cell(0, 10, 'Relatório de Engenharia Reversa de Vídeos', 0, 1, 'C')\n",
        "        self.ln(10)\n",
        "\n",
        "    def footer(self):\n",
        "        self.set_y(-15)\n",
        "        self.set_font('Arial', 'I', 8)\n",
        "        self.cell(0, 10, f'Página {self.page_no()}/{{nb}}', 0, 0, 'C')\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.cell(0, 10, title, 0, 1, 'L')\n",
        "        self.ln(5)\n",
        "\n",
        "    def chapter_body(self, body):\n",
        "        self.set_font('Arial', '', 10)\n",
        "        self.multi_cell(0, 5, body)\n",
        "        self.ln()\n",
        "\n",
        "def gerar_relatorio_texto(video_id, analise_padroes_data, pasta_destino):\n",
        "    df_texto = pd.DataFrame([analise_padroes_data])\n",
        "    excel_path = os.path.join(pasta_destino, f'RELATORIO_TEXTO_HUMANIZADO_{video_id}.xlsx')\n",
        "    df_texto.to_excel(excel_path, index=False, engine='openpyxl')\n",
        "\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "    pdf.chapter_title('Estratégia de Conteúdo Textual')\n",
        "    pdf.chapter_body(f'Resumo do Texto: {analise_padroes_data.get('resumo_texto', 'N/A')}')\n",
        "    pdf.chapter_body(f'Palavras-chave: {', '.join(analise_padroes_data.get('palavras_chave_texto', []))}')\n",
        "    pdf_path = os.path.join(pasta_destino, f'ESTRATEGIA_CONTEUDO_TEXTUAL_{video_id}.pdf')\n",
        "    pdf.output(pdf_path)\n",
        "    return excel_path, pdf_path\n",
        "\n",
        "def gerar_relatorio_audio(video_id, analise_padroes_data, pasta_destino):\n",
        "    df_audio = pd.DataFrame([analise_padroes_data.get('analise_audio_detalhada', {})])\n",
        "    excel_path = os.path.join(pasta_destino, f'RELATORIO_AUDIO_HUMANIZADO_{video_id}.xlsx')\n",
        "    df_audio.to_excel(excel_path, index=False, engine='openpyxl')\n",
        "\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "    pdf.chapter_title('Resumo de Áudio Estratégico')\n",
        "    pdf.chapter_body(f'BPM: {analise_padroes_data.get('analise_audio_detalhada', {}).get('bpm', 'N/A')}')\n",
        "    pdf.chapter_body(f'Duração do Áudio: {analise_padroes_data.get('analise_audio_detalhada', {}).get('duracao_audio_segundos', 'N/A')} segundos')\n",
        "    pdf_path = os.path.join(pasta_destino, f'RESUMO_AUDIO_ESTRATEGICO_{video_id}.pdf')\n",
        "    pdf.output(pdf_path)\n",
        "    return excel_path, pdf_path\n",
        "\n",
        "def gerar_relatorio_visual(video_id, analise_padroes_data, pasta_destino):\n",
        "    df_visual = pd.DataFrame([analise_padroes_data.get('analise_visual_detalhada', {})])\n",
        "    excel_path = os.path.join(pasta_destino, f'RELATORIO_VISUAL_HUMANIZADO_{video_id}.xlsx')\n",
        "    df_visual.to_excel(excel_path, index=False, engine='openpyxl')\n",
        "\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "    pdf.chapter_title('Estratégia Visual Completa')\n",
        "    pdf.chapter_body(f'Total de Cortes: {analise_padroes_data.get('analise_visual_detalhada', {}).get('total_cortes', 'N/A')}')\n",
        "    pdf.chapter_body(f'Complexidade Visual Média: {analise_padroes_data.get('analise_visual_detalhada', {}).get('complexidade_visual_media', 'N/A'):.2f}')\n",
        "    pdf.chapter_body(f'Brilho Médio: {analise_padroes_data.get('analise_visual_detalhada', {}).get('brilho_medio', 'N/A'):.2f}')\n",
        "    pdf_path = os.path.join(pasta_destino, f'ESTRATEGIA_VISUAL_COMPLETA_{video_id}.pdf')\n",
        "    pdf.output(pdf_path)\n",
        "    return excel_path, pdf_path\n",
        "\n",
        "def gerar_relatorio_psicologico(video_id, analise_psicologica_data, pasta_destino):\n",
        "    df_psico = pd.DataFrame([analise_psicologica_data])\n",
        "    excel_path = os.path.join(pasta_destino, f'RELATORIO_PSICOLOGICO_HUMANIZADO_{video_id}.xlsx')\n",
        "    df_psico.to_excel(excel_path, index=False, engine='openpyxl')\n",
        "\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "    pdf.chapter_title('Manual de Psicologia Viral')\n",
        "    pdf.chapter_body(f'Gatilhos Detectados: {', '.join(analise_psicologica_data.get('gatilhos_detectados', []))}')\n",
        "    pdf.chapter_body(f'Emoções Predominantes: {analise_psicologica_data.get('emocoes_predominantes', 'N/A')}')\n",
        "    pdf.chapter_body(f'Insights: {analise_psicologica_data.get('insights_psicologicos', 'N/A')}')\n",
        "    pdf_path = os.path.join(pasta_destino, f'MANUAL_PSICOLOGIA_VIRAL_{video_id}.pdf')\n",
        "    pdf.output(pdf_path)\n",
        "    return excel_path, pdf_path\n",
        "\n",
        "def processar_geracao_relatorios_todos_videos():\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa('analise_psicologica')\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Carregar dados de análise de padrões e psicológica\n",
        "    analises_padroes_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_padroes_completas.json\")\n",
        "    analises_psicologicas_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_psicologicas_completas.json\")\n",
        "    with open(analises_padroes_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        analises_padroes = json.load(f)\n",
        "    with open(analises_psicologicas_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        analises_psicologicas = json.load(f)\n",
        "\n",
        "    sucessos = 0\n",
        "\n",
        "    print(f\"\"\"\n",
        "Iniciando geração de relatórios humanizados para {len(analises_padroes)} vídeos...\"\"\")\n",
        "\n",
        "    for i, analise_padroes_data in enumerate(analises_padroes, 1):\n",
        "        video_id = analise_padroes_data[\"video_id\"]\n",
        "        analise_psicologica_data = next((a for a in analises_psicologicas if a[\"video_id\"] == video_id), None)\n",
        "\n",
        "        if analise_padroes_data.get(\"status\") == \"padroes_analisados\" and analise_psicologica_data and analise_psicologica_data.get(\"status\") == \"analise_psicologica_concluida\":\n",
        "            print(f\"[{i}/{len(analises_padroes)}] Gerando relatórios para: {video_id}\")\n",
        "            try:\n",
        "                # Geração de Relatórios de Texto\n",
        "                pasta_texto = os.path.join(PASTA_TRABALHO, \"analise_texto\")\n",
        "                os.makedirs(pasta_texto, exist_ok=True)\n",
        "                excel_text, pdf_text = gerar_relatorio_texto(video_id, analise_padroes_data, pasta_texto)\n",
        "                print(f\"  💾 Relatório de Texto (XLSX) salvo em: {excel_text}\")\n",
        "                print(f\"  💾 Estratégia de Conteúdo Textual (PDF) salvo em: {pdf_text}\")\n",
        "\n",
        "                # Geração de Relatórios de Áudio\n",
        "                pasta_audio = os.path.join(PASTA_TRABALHO, \"analise_audio\")\n",
        "                os.makedirs(pasta_audio, exist_ok=True)\n",
        "                excel_audio, pdf_audio = gerar_relatorio_audio(video_id, analise_padroes_data, pasta_audio)\n",
        "                print(f\"  💾 Relatório de Áudio (XLSX) salvo em: {excel_audio}\")\n",
        "                print(f\"  💾 Resumo de Áudio Estratégico (PDF) salvo em: {pdf_audio}\")\n",
        "\n",
        "                # Geração de Relatórios Visuais\n",
        "                pasta_visual = os.path.join(PASTA_TRABALHO, \"analise_visual\")\n",
        "                os.makedirs(pasta_visual, exist_ok=True)\n",
        "                excel_visual, pdf_visual = gerar_relatorio_visual(video_id, analise_padroes_data, pasta_visual)\n",
        "                print(f\"  💾 Relatório Visual (XLSX) salvo em: {excel_visual}\")\n",
        "                print(f\"  💾 Estratégia Visual Completa (PDF) salvo em: {pdf_visual}\")\n",
        "\n",
        "                # Geração de Relatórios Psicológicos\n",
        "                pasta_psicologica = os.path.join(PASTA_TRABALHO, \"analise_psicologica\")\n",
        "                os.makedirs(pasta_psicologica, exist_ok=True)\n",
        "                excel_psico, pdf_psico = gerar_relatorio_psicologico(video_id, analise_psicologica_data, pasta_psicologica)\n",
        "                print(f\"  💾 Relatório Psicológico (XLSX) salvo em: {excel_psico}\")\n",
        "                print(f\"  💾 Manual de Psicologia Viral (PDF) salvo em: {pdf_psico}\")\n",
        "\n",
        "                sucessos += 1\n",
        "                print(f\"  ✅ Relatórios gerados para {video_id}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ❌ ERRO na geração de relatórios para {video_id}: {e}\")\n",
        "        else:\n",
        "            print(f\"[{i}/{len(analises_padroes)}] Pulando {video_id} - Pré-requisitos não atendidos.\")\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"relatorios_humanizados\"] = True\n",
        "    config[\"total_videos_relatorios_gerados\"] = sucessos\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(\"\"\"\n",
        "✅ GERAÇÃO DE RELATÓRIOS HUMANIZADOS CONCLUÍDA!\"\"\")\n",
        "    print(f\"Total de vídeos com relatórios gerados: {sucessos}\")\n",
        "\n",
        "    if sucessos == 0:\n",
        "        print(\"❌ NENHUM VÍDEO TEVE RELATÓRIOS GERADOS COM SUCESSO. Verifique as etapas anteriores.\")\n",
        "    print(\"\"\"\n",
        "➡️ PRÓXIMA CÉLULA: 4.2 - GERAÇÃO DO BLUEPRINT FINAL E DASHBOARD\"\"\")\n",
        "\n",
        "# Executar geração de relatórios\n",
        "try:\n",
        "    processar_geracao_relatorios_todos_videos()\n",
        "except Exception as e:\n",
        "    print(f\"\"\"\n",
        "❌ ERRO GERAL NA GERAÇÃO DE RELATÓRIOS: {e}\"\"\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "relatorios_humanizados",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60306fe1-01cd-4c04-b6fd-95f49536a662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando geração de relatórios humanizados para 5 vídeos...\n",
            "[1/5] Gerando relatórios para: vid_ate_quando_voce_vai_ficar_culpando_os_outros\n",
            "  💾 Relatório de Texto (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_texto/RELATORIO_TEXTO_HUMANIZADO_vid_ate_quando_voce_vai_ficar_culpando_os_outros.xlsx\n",
            "  💾 Estratégia de Conteúdo Textual (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_texto/ESTRATEGIA_CONTEUDO_TEXTUAL_vid_ate_quando_voce_vai_ficar_culpando_os_outros.pdf\n",
            "  💾 Relatório de Áudio (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_audio/RELATORIO_AUDIO_HUMANIZADO_vid_ate_quando_voce_vai_ficar_culpando_os_outros.xlsx\n",
            "  💾 Resumo de Áudio Estratégico (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_audio/RESUMO_AUDIO_ESTRATEGICO_vid_ate_quando_voce_vai_ficar_culpando_os_outros.pdf\n",
            "  💾 Relatório Visual (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_visual/RELATORIO_VISUAL_HUMANIZADO_vid_ate_quando_voce_vai_ficar_culpando_os_outros.xlsx\n",
            "  💾 Estratégia Visual Completa (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_visual/ESTRATEGIA_VISUAL_COMPLETA_vid_ate_quando_voce_vai_ficar_culpando_os_outros.pdf\n",
            "  💾 Relatório Psicológico (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_psicologica/RELATORIO_PSICOLOGICO_HUMANIZADO_vid_ate_quando_voce_vai_ficar_culpando_os_outros.xlsx\n",
            "  💾 Manual de Psicologia Viral (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_psicologica/MANUAL_PSICOLOGIA_VIRAL_vid_ate_quando_voce_vai_ficar_culpando_os_outros.pdf\n",
            "  ✅ Relatórios gerados para vid_ate_quando_voce_vai_ficar_culpando_os_outros\n",
            "[2/5] Gerando relatórios para: vid_coloque_metas_em_sua_vida_e_se_surpreenda\n",
            "  💾 Relatório de Texto (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_texto/RELATORIO_TEXTO_HUMANIZADO_vid_coloque_metas_em_sua_vida_e_se_surpreenda.xlsx\n",
            "  💾 Estratégia de Conteúdo Textual (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_texto/ESTRATEGIA_CONTEUDO_TEXTUAL_vid_coloque_metas_em_sua_vida_e_se_surpreenda.pdf\n",
            "  💾 Relatório de Áudio (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_audio/RELATORIO_AUDIO_HUMANIZADO_vid_coloque_metas_em_sua_vida_e_se_surpreenda.xlsx\n",
            "  💾 Resumo de Áudio Estratégico (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_audio/RESUMO_AUDIO_ESTRATEGICO_vid_coloque_metas_em_sua_vida_e_se_surpreenda.pdf\n",
            "  💾 Relatório Visual (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_visual/RELATORIO_VISUAL_HUMANIZADO_vid_coloque_metas_em_sua_vida_e_se_surpreenda.xlsx\n",
            "  💾 Estratégia Visual Completa (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_visual/ESTRATEGIA_VISUAL_COMPLETA_vid_coloque_metas_em_sua_vida_e_se_surpreenda.pdf\n",
            "  💾 Relatório Psicológico (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_psicologica/RELATORIO_PSICOLOGICO_HUMANIZADO_vid_coloque_metas_em_sua_vida_e_se_surpreenda.xlsx\n",
            "  💾 Manual de Psicologia Viral (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_psicologica/MANUAL_PSICOLOGIA_VIRAL_vid_coloque_metas_em_sua_vida_e_se_surpreenda.pdf\n",
            "  ✅ Relatórios gerados para vid_coloque_metas_em_sua_vida_e_se_surpreenda\n",
            "[3/5] Gerando relatórios para: vid_a_importancia_de_ser_rico_antes_de_ter\n",
            "  💾 Relatório de Texto (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_texto/RELATORIO_TEXTO_HUMANIZADO_vid_a_importancia_de_ser_rico_antes_de_ter.xlsx\n",
            "  💾 Estratégia de Conteúdo Textual (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_texto/ESTRATEGIA_CONTEUDO_TEXTUAL_vid_a_importancia_de_ser_rico_antes_de_ter.pdf\n",
            "  💾 Relatório de Áudio (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_audio/RELATORIO_AUDIO_HUMANIZADO_vid_a_importancia_de_ser_rico_antes_de_ter.xlsx\n",
            "  💾 Resumo de Áudio Estratégico (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_audio/RESUMO_AUDIO_ESTRATEGICO_vid_a_importancia_de_ser_rico_antes_de_ter.pdf\n",
            "  💾 Relatório Visual (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_visual/RELATORIO_VISUAL_HUMANIZADO_vid_a_importancia_de_ser_rico_antes_de_ter.xlsx\n",
            "  💾 Estratégia Visual Completa (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_visual/ESTRATEGIA_VISUAL_COMPLETA_vid_a_importancia_de_ser_rico_antes_de_ter.pdf\n",
            "  💾 Relatório Psicológico (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_psicologica/RELATORIO_PSICOLOGICO_HUMANIZADO_vid_a_importancia_de_ser_rico_antes_de_ter.xlsx\n",
            "  💾 Manual de Psicologia Viral (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/analise_psicologica/MANUAL_PSICOLOGIA_VIRAL_vid_a_importancia_de_ser_rico_antes_de_ter.pdf\n",
            "  ✅ Relatórios gerados para vid_a_importancia_de_ser_rico_antes_de_ter\n",
            "[4/5] Gerando relatórios para: vid_as_três_fases_de_todo_mundo_que_decidiu_fazer_alguma_coisa\n",
            "  ❌ ERRO na geração de relatórios para vid_as_três_fases_de_todo_mundo_que_decidiu_fazer_alguma_coisa: 'latin-1' codec can't encode character '\\u201c' in position 625: ordinal not in range(256)\n",
            "[5/5] Gerando relatórios para: vid_a_melhor_saida_é_se_afastar_de_pessoas_perversas\n",
            "  ❌ ERRO na geração de relatórios para vid_a_melhor_saida_é_se_afastar_de_pessoas_perversas: 'latin-1' codec can't encode character '\\u201c' in position 304: ordinal not in range(256)\n",
            "\n",
            "✅ GERAÇÃO DE RELATÓRIOS HUMANIZADOS CONCLUÍDA!\n",
            "Total de vídeos com relatórios gerados: 3\n",
            "\n",
            "➡️ PRÓXIMA CÉLULA: 4.2 - GERAÇÃO DO BLUEPRINT FINAL E DASHBOARD\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CÉLULA 4.2: GERAÇÃO DO BLUEPRINT FINAL E DASHBOARD\n",
        "# ============================================================================\n",
        "\n",
        "def gerar_blueprint_dashboard():\n",
        "    prerequisito_ok, config = verificar_prerequisito_etapa(\"relatorios_humanizados\")\n",
        "    if not prerequisito_ok:\n",
        "        return\n",
        "\n",
        "    # Carregar todos os dados de análise\n",
        "    metadados_path = os.path.join(PASTA_TRABALHO, \"dados\", \"metadados_completos.json\")\n",
        "    decomposicao_path = os.path.join(PASTA_TRABALHO, \"dados\", \"decomposicao_completa.json\")\n",
        "    analises_padroes_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_padroes_completas.json\")\n",
        "    analises_psicologicas_path = os.path.join(PASTA_TRABALHO, \"dados\", \"analises_psicologicas_completas.json\")\n",
        "\n",
        "    with open(metadados_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        metadados = json.load(f)\n",
        "    with open(decomposicao_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        decomposicoes = json.load(f)\n",
        "    with open(analises_padroes_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        analises_padroes = json.load(f)\n",
        "    with open(analises_psicologicas_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        analises_psicologicas = json.load(f)\n",
        "\n",
        "    dados_consolidados = []\n",
        "    for video_meta in metadados:\n",
        "        video_id = video_meta[\"id\"]\n",
        "        decomposicao = next((d for d in decomposicoes if d[\"video_id\"] == video_id), {})\n",
        "        analise_padroes = next((ap for ap in analises_padroes if ap[\"video_id\"] == video_id), {})\n",
        "        analise_psicologica = next((aps for aps in analises_psicologicas if aps[\"video_id\"] == video_id), {})\n",
        "        consolidado = {\n",
        "            \"video_id\": video_id,\n",
        "            \"nome_arquivo\": video_meta.get(\"nome_arquivo\"),\n",
        "            \"duracao_segundos\": video_meta.get(\"duracao_segundos\"),\n",
        "            \"formato_detectado\": video_meta.get(\"formato_detectado\"),\n",
        "            \"tem_audio\": video_meta.get(\"tem_audio\"),\n",
        "            \"total_frames\": video_meta.get(\"total_frames\"),\n",
        "            \"ocr_textos_count\": len(decomposicao.get(\"textos_ocr\", [])),\n",
        "            \"audio_transcrito_len\": len(decomposicao.get(\"audio_transcrito\", \"\")),\n",
        "            \"cortes_detectados_count\": len(decomposicao.get(\"cortes_detectados_segundos\", [])),\n",
        "            \"bpm_audio\": analise_padroes.get(\"analise_audio_detalhada\", {}).get(\"bpm\"),\n",
        "            \"complexidade_visual_media\": analise_padroes.get(\"analise_visual_detalhada\", {}).get(\"complexidade_visual_media\"),\n",
        "            \"brilho_medio\": analise_padroes.get(\"analise_visual_detalhada\", {}).get(\"brilho_medio\"),\n",
        "            \"padroes_gerais\": \", \".join(analise_padroes.get(\"padroes_gerais\", [])),\n",
        "            \"gatilhos_psicologicos\": \", \".join(analise_psicologica.get(\"gatilhos_detectados\", [])),\n",
        "            \"emocoes_predominantes\": str(analise_psicologica.get(\"emocoes_predominantes\", {})),\n",
        "            \"status_geral\": video_meta.get(\"status\") # Pode ser aprimorado para refletir o status de todas as etapas\n",
        "        }\n",
        "        dados_consolidados.append(consolidado)\n",
        "\n",
        "    df_final = pd.DataFrame(dados_consolidados)\n",
        "\n",
        "    # Salvar Dashboard Executivo (Excel)\n",
        "    dashboard_excel_path = os.path.join(PASTA_TRABALHO, \"dashboard\", \"DASHBOARD_MASTER_EXECUTIVO.xlsx\")\n",
        "    df_final.to_excel(dashboard_excel_path, index=False, engine=\"openpyxl\")\n",
        "    print(f\"\\n💾 Dashboard Executivo (XLSX) salvo em: {dashboard_excel_path}\")\n",
        "\n",
        "    # Salvar Dados Consolidados (CSV e JSON)\n",
        "    dados_csv_path = os.path.join(PASTA_TRABALHO, \"dashboard\", \"dados_consolidados.csv\")\n",
        "    df_final.to_csv(dados_csv_path, index=False, encoding=\"utf-8\")\n",
        "    print(f\"💾 Dados Consolidados (CSV) salvo em: {dados_csv_path}\")\n",
        "\n",
        "    dados_json_path = os.path.join(PASTA_TRABALHO, \"dashboard\", \"dados_detalhados.json\")\n",
        "    with open(dados_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(dados_consolidados, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"💾 Dados Detalhados (JSON) salvo em: {dados_json_path}\")\n",
        "\n",
        "    # Geração de Dashboard Interativo (HTML - Exemplo simples)\n",
        "    # Para um dashboard interativo real, seria necessário uma biblioteca como Plotly ou Dash\n",
        "    dashboard_html_path = os.path.join(PASTA_TRABALHO, \"dashboard\", \"dashboard_interativo.html\")\n",
        "    with open(dashboard_html_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"<html><body><h1>Dashboard Interativo (Placeholder)</h1><p>Seu dashboard interativo real seria gerado aqui com bibliotecas como Plotly ou Dash.</p></body></html>\")\n",
        "    print(f\"💾 Dashboard Interativo (HTML) salvo em: {dashboard_html_path}\")\n",
        "\n",
        "    # Geração do Blueprint Estratégico (PDF - Exemplo simples)\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "    pdf.chapter_title(\"BLUEPRINT ESTRATÉGICO FINAL\")\n",
        "    pdf.chapter_body(\"Este é o seu blueprint estratégico final, consolidando todos os insights.\")\n",
        "    pdf.chapter_body(f\"Total de vídeos analisados: {len(df_final)}\")\n",
        "    pdf.chapter_body(f\"Média de duração dos vídeos: {df_final[\"duracao_segundos\"] .mean():.2f} segundos\")\n",
        "    pdf_blueprint_path = os.path.join(PASTA_TRABALHO, \"blueprint\", \"BLUEPRINT_ESTRATEGICO_FINAL.pdf\")\n",
        "    pdf.output(pdf_blueprint_path)\n",
        "    print(f\"💾 Blueprint Estratégico (PDF) salvo em: {pdf_blueprint_path}\")\n",
        "\n",
        "    # Atualizar status no config\n",
        "    config_path = os.path.join(PASTA_TRABALHO, \"config\", \"config.json\")\n",
        "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    config[\"status_etapas\"][\"blueprint\"] = True\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(\"\\n✅ GERAÇÃO DO BLUEPRINT FINAL E DASHBOARD CONCLUÍDA!\")\n",
        "    print(\"Todos os relatórios e o dashboard foram gerados com sucesso.\")\n",
        "    print(\"\\n🎉 PROCESSO DE ENGENHARIA REVERSA CONCLUÍDO COM SUCESSO! 🎉\")\n",
        "\n",
        "# Executar geração de blueprint e dashboard\n",
        "try:\n",
        "    gerar_blueprint_dashboard()\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ ERRO GERAL NA GERAÇÃO DO BLUEPRINT E DASHBOARD: {e}\")\n",
        "    print(\"Por favor, corrija o erro acima antes de prosseguir.\")"
      ],
      "metadata": {
        "id": "blueprint_dashboard",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7aadba-56e1-456d-bdfe-d34e70d47d0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 Dashboard Executivo (XLSX) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dashboard/DASHBOARD_MASTER_EXECUTIVO.xlsx\n",
            "💾 Dados Consolidados (CSV) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dashboard/dados_consolidados.csv\n",
            "💾 Dados Detalhados (JSON) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dashboard/dados_detalhados.json\n",
            "💾 Dashboard Interativo (HTML) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/dashboard/dashboard_interativo.html\n",
            "💾 Blueprint Estratégico (PDF) salvo em: /content/drive/MyDrive/Videos Dona Done/_engenharia_reversa/blueprint/BLUEPRINT_ESTRATEGICO_FINAL.pdf\n",
            "\n",
            "✅ GERAÇÃO DO BLUEPRINT FINAL E DASHBOARD CONCLUÍDA!\n",
            "Todos os relatórios e o dashboard foram gerados com sucesso.\n",
            "\n",
            "🎉 PROCESSO DE ENGENHARIA REVERSA CONCLUÍDO COM SUCESSO! 🎉\n"
          ]
        }
      ],
      "execution_count": null
    }
  ]
}